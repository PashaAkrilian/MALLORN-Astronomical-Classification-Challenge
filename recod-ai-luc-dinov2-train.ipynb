{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":113558,"databundleVersionId":14878066,"sourceType":"competition"},{"sourceId":14476636,"sourceType":"datasetVersion","datasetId":9171323},{"sourceId":4534,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":3326,"modelId":986}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Set Paths & Select Config (CFG)","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE — Set Paths & Select Config (CFG)  (ONE CELL) — REVISI FULL\n# - Robust: find token cache even when /kaggle/working cache empty\n# - No if/else (uses try/except)\n# ============================================================\n\nimport os, json, random, hashlib\nfrom pathlib import Path\nfrom dataclasses import dataclass, asdict\n\n# ----------------------------\n# Helpers\n# ----------------------------\ndef first_existing(paths):\n    return next(Path(p) for p in paths if Path(p).exists())\n\ndef jhash(obj) -> str:\n    s = json.dumps(obj, sort_keys=True, ensure_ascii=True, separators=(\",\", \":\"))\n    return hashlib.md5(s.encode(\"utf-8\")).hexdigest()[:12]\n\ndef newest_token_cache_anywhere(parents):\n    cands = []\n    for parent in parents:\n        parent = Path(parent)\n        for d in parent.glob(\"dinov2_base_518_cfg_*\"):\n            try:\n                _ = next((d / \"train\").glob(\"*.npz\"))\n                _ = (d / \"tokens_manifest_train.parquet\").exists()\n                cands.append(d)\n            except Exception:\n                pass\n    cands = sorted(cands, key=lambda d: d.stat().st_mtime, reverse=True)\n    return cands[0]\n\ndef newest_match_cache_anywhere(parents):\n    cands = []\n    for parent in parents:\n        parent = Path(parent)\n        for d in parent.glob(\"match_cfg_*\"):\n            try:\n                _ = (d / \"match_manifest_train.parquet\").exists()\n                cands.append(d)\n            except Exception:\n                pass\n    cands = sorted(cands, key=lambda d: d.stat().st_mtime, reverse=True)\n    return cands[0]\n\n# ----------------------------\n# Core Paths (Competition + DINO)\n# ----------------------------\nCOMP_ROOT = Path(\"/kaggle/input/recodai-luc-scientific-image-forgery-detection\")\nDINO_DIR  = Path(\"/kaggle/input/dinov2/pytorch/base/1\")\n\n# Prefer working bundle if exists; fallback to input dataset bundle\nBUNDLE_ROOT = first_existing([\n    \"/kaggle/working/recodai_luc\",\n    \"/kaggle/input/recod-ailuc-dinov2-base/recodai_luc\",\n])\n\nPROF_DIR = first_existing([\n    \"/kaggle/working/recodai_luc_prof\",\n    \"/kaggle/input/recod-ailuc-dinov2-base/recodai_luc_prof\",\n])\n\nCACHE_ROOT = Path(BUNDLE_ROOT) / \"cache\"\n\n# ----------------------------\n# Existing Artifacts (from PROF)\n# ----------------------------\nTRAIN_MANIFEST = Path(PROF_DIR) / \"train_manifest.parquet\"\nTEST_MANIFEST  = Path(PROF_DIR) / \"test_manifest.parquet\"\nFOLDS_PATH     = Path(PROF_DIR) / \"folds.parquet\"\n\n# ----------------------------\n# Find VALID token/match caches (search working + input bundle cache)\n# ----------------------------\nCACHE_PARENTS = [\n    CACHE_ROOT,\n    Path(\"/kaggle/input/recod-ailuc-dinov2-base/recodai_luc/cache\"),\n    Path(\"/kaggle/working/recodai_luc/cache\"),\n]\n\nTOKEN_CACHE_ROOT = newest_token_cache_anywhere(CACHE_PARENTS)\nTOKEN_MANIFEST_TRAIN = TOKEN_CACHE_ROOT / \"tokens_manifest_train.parquet\"\nTOKEN_MANIFEST_TEST  = TOKEN_CACHE_ROOT / \"tokens_manifest_test.parquet\"\nTOK_TRAIN_DIR = TOKEN_CACHE_ROOT / \"train\"\nTOK_TEST_DIR  = TOKEN_CACHE_ROOT / \"test\"\n\nMATCH_CACHE_ROOT = newest_match_cache_anywhere(CACHE_PARENTS)\nMATCH_MANIFEST_TRAIN = MATCH_CACHE_ROOT / \"match_manifest_train.parquet\"\nMATCH_MANIFEST_TEST  = MATCH_CACHE_ROOT / \"match_manifest_test.parquet\"\n\n# Pred ensemble dir (features)\nPRED_DIR = Path(\"/kaggle/input/recod-ailuc-dinov2-base/recodai_luc/cache/pred_ens\")\nPRED_FEATS_TRAIN = PRED_DIR / \"pred_features_train.csv\"\nPRED_FEATS_TEST  = PRED_DIR / \"pred_features_test.csv\"\n\n# ----------------------------\n# SEG CFG (UNet+ASPP on token grid)\n# ----------------------------\n@dataclass\nclass SegCFG:\n    run_name: str = \"seg_unet_aspp_tok37_dinov2b\"\n    seed: int = 42\n    img_size: int = 518\n    patch: int = 14\n    htok: int = 37\n    wtok: int = 37\n    dim: int = 768\n    save_dtype: str = \"float16\"\n    cv_n_splits: int = 5\n    epochs: int = 35\n    batch_size: int = 16\n    lr: float = 3e-4\n    base_ch: int = 128\n\nSEG_CFG = SegCFG()\nSEG_CFG_ID = jhash(asdict(SEG_CFG))\n\n# ----------------------------\n# Gate CFG (for later stages)\n# ----------------------------\n@dataclass\nclass GateCFG:\n    run_name: str = \"gate_lgbm_v1\"\n    seed: int = 42\n    cv_n_splits: int = 5\n    model_type: str = \"lgbm\"\n    use_calibration: bool = True\n    calibration_method: str = \"sigmoid\"\n    threshold_strategy: str = \"stability_f1\"\n    lgbm_params: dict = None\n\nGATE_CFG = GateCFG(\n    lgbm_params=dict(\n        objective=\"binary\",\n        learning_rate=0.03,\n        n_estimators=2500,\n        num_leaves=63,\n        max_depth=-1,\n        min_data_in_leaf=80,\n        feature_fraction=0.8,\n        bagging_fraction=0.8,\n        bagging_freq=1,\n        lambda_l1=0.0,\n        lambda_l2=1.0,\n        random_state=42,\n        n_jobs=-1,\n    )\n)\nGATE_CFG_ID = jhash(asdict(GATE_CFG))\n\n# ----------------------------\n# Output dirs (new artifacts go here)\n# ----------------------------\nWORK_ROOT = Path(\"/kaggle/working/recodai_luc\")\nSEG_RUN_DIR  = WORK_ROOT / \"seg_runs\"  / f\"{SEG_CFG.run_name}_{SEG_CFG_ID}\"\nGATE_OUT_DIR = WORK_ROOT / \"gate_runs\" / f\"{GATE_CFG.run_name}_{GATE_CFG_ID}\"\nSEG_RUN_DIR.mkdir(parents=True, exist_ok=True)\nGATE_OUT_DIR.mkdir(parents=True, exist_ok=True)\n\n# ----------------------------\n# Seeds\n# ----------------------------\nos.environ[\"PYTHONHASHSEED\"] = str(SEG_CFG.seed)\nrandom.seed(SEG_CFG.seed)\n\n# ----------------------------\n# Print summary\n# ----------------------------\nprint(\"COMP_ROOT:\", COMP_ROOT)\nprint(\"DINO_DIR :\", DINO_DIR)\nprint(\"BUNDLE_ROOT:\", BUNDLE_ROOT)\nprint(\"PROF_DIR  :\", PROF_DIR)\nprint(\"CACHE_ROOT :\", CACHE_ROOT)\n\nprint(\"\\nTOKEN_CACHE_ROOT:\", TOKEN_CACHE_ROOT)\nprint(\"TOK_TRAIN_DIR   :\", TOK_TRAIN_DIR)\nprint(\"TOK_TEST_DIR    :\", TOK_TEST_DIR)\nprint(\"TOKEN_MANIFEST_TRAIN:\", TOKEN_MANIFEST_TRAIN.name)\n\nprint(\"\\nMATCH_CACHE_ROOT:\", MATCH_CACHE_ROOT)\nprint(\"MATCH_MANIFEST_TRAIN:\", MATCH_MANIFEST_TRAIN.name)\n\nprint(\"\\nPRED_DIR        :\", PRED_DIR)\nprint(\"PRED_FEATS_TRAIN:\", PRED_FEATS_TRAIN.name)\nprint(\"PRED_FEATS_TEST :\", PRED_FEATS_TEST.name)\n\nprint(\"\\nSEG_CFG_ID :\", SEG_CFG_ID)\nprint(\"GATE_CFG_ID:\", GATE_CFG_ID)\nprint(\"\\nSEG_CFG:\", json.dumps(asdict(SEG_CFG), indent=2))\nprint(\"\\nGATE_CFG:\", json.dumps(asdict(GATE_CFG), indent=2))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T10:10:49.217298Z","iopub.execute_input":"2026-01-17T10:10:49.217649Z","iopub.status.idle":"2026-01-17T10:10:49.282155Z","shell.execute_reply.started":"2026-01-17T10:10:49.217619Z","shell.execute_reply":"2026-01-17T10:10:49.281355Z"}},"outputs":[{"name":"stdout","text":"COMP_ROOT: /kaggle/input/recodai-luc-scientific-image-forgery-detection\nDINO_DIR : /kaggle/input/dinov2/pytorch/base/1\nBUNDLE_ROOT: /kaggle/working/recodai_luc\nPROF_DIR  : /kaggle/input/recod-ailuc-dinov2-base/recodai_luc_prof\nCACHE_ROOT : /kaggle/working/recodai_luc/cache\n\nTOKEN_CACHE_ROOT: /kaggle/input/recod-ailuc-dinov2-base/recodai_luc/cache/dinov2_base_518_cfg_543289469500\nTOK_TRAIN_DIR   : /kaggle/input/recod-ailuc-dinov2-base/recodai_luc/cache/dinov2_base_518_cfg_543289469500/train\nTOK_TEST_DIR    : /kaggle/input/recod-ailuc-dinov2-base/recodai_luc/cache/dinov2_base_518_cfg_543289469500/test\nTOKEN_MANIFEST_TRAIN: tokens_manifest_train.parquet\n\nMATCH_CACHE_ROOT: /kaggle/input/recod-ailuc-dinov2-base/recodai_luc/cache/match_cfg_2ed747746f9c\nMATCH_MANIFEST_TRAIN: match_manifest_train.parquet\n\nPRED_DIR        : /kaggle/input/recod-ailuc-dinov2-base/recodai_luc/cache/pred_ens\nPRED_FEATS_TRAIN: pred_features_train.csv\nPRED_FEATS_TEST : pred_features_test.csv\n\nSEG_CFG_ID : 898cfeeba43a\nGATE_CFG_ID: 716be4694cc8\n\nSEG_CFG: {\n  \"run_name\": \"seg_unet_aspp_tok37_dinov2b\",\n  \"seed\": 42,\n  \"img_size\": 518,\n  \"patch\": 14,\n  \"htok\": 37,\n  \"wtok\": 37,\n  \"dim\": 768,\n  \"save_dtype\": \"float16\",\n  \"cv_n_splits\": 5,\n  \"epochs\": 35,\n  \"batch_size\": 16,\n  \"lr\": 0.0003,\n  \"base_ch\": 128\n}\n\nGATE_CFG: {\n  \"run_name\": \"gate_lgbm_v1\",\n  \"seed\": 42,\n  \"cv_n_splits\": 5,\n  \"model_type\": \"lgbm\",\n  \"use_calibration\": true,\n  \"calibration_method\": \"sigmoid\",\n  \"threshold_strategy\": \"stability_f1\",\n  \"lgbm_params\": {\n    \"objective\": \"binary\",\n    \"learning_rate\": 0.03,\n    \"n_estimators\": 2500,\n    \"num_leaves\": 63,\n    \"max_depth\": -1,\n    \"min_data_in_leaf\": 80,\n    \"feature_fraction\": 0.8,\n    \"bagging_fraction\": 0.8,\n    \"bagging_freq\": 1,\n    \"lambda_l1\": 0.0,\n    \"lambda_l2\": 1.0,\n    \"random_state\": 42,\n    \"n_jobs\": -1\n  }\n}\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"# Train Segmentation Decoder (UNet+ASPP)","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE — Train Segmentation Decoder (UNet + ASPP)  [ONE CELL] — REVISI FULL\n# Fix: mask .npy can be (H,W) or (1,H,W) or (K,H,W) -> force to (H,W) before interpolate\n# ============================================================\n\nimport os, gc, json, math, random\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nfrom dataclasses import asdict\nfrom tqdm.auto import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\n# ----------------------------\n# Device / seed\n# ----------------------------\ntry:\n    _ = torch.zeros(1).cuda()\n    DEVICE = torch.device(\"cuda\")\nexcept Exception:\n    DEVICE = torch.device(\"cpu\")\n\ntorch.manual_seed(SEG_CFG.seed)\nrandom.seed(SEG_CFG.seed)\nnp.random.seed(SEG_CFG.seed)\n\nprint(\"DEVICE:\", DEVICE)\nprint(\"TOK_TRAIN_DIR:\", TOK_TRAIN_DIR)\nprint(\"SEG_RUN_DIR  :\", SEG_RUN_DIR)\n\n# ----------------------------\n# Build df_seg: (case_id, mask_path, npz_path, fold)\n# ----------------------------\nmask_train = sorted((Path(COMP_ROOT) / \"train_masks\").glob(\"*.npy\"))\nmask_supp  = sorted((Path(COMP_ROOT) / \"supplemental_masks\").glob(\"*.npy\"))\nmask_paths = mask_train + mask_supp\n\ndf_mask = pd.DataFrame({\n    \"case_id\": [p.stem for p in mask_paths],\n    \"mask_path\": [str(p) for p in mask_paths],\n})\ndf_mask[\"case_id\"] = df_mask[\"case_id\"].astype(str)\n\ndf_folds = pd.read_parquet(FOLDS_PATH).copy()\ndf_folds[\"case_id\"] = df_folds[\"case_id\"].astype(str)\ndf_folds[\"fold\"] = df_folds[\"fold\"].astype(int)\n\ndf_seg = df_mask.merge(df_folds[[\"case_id\",\"fold\"]], on=\"case_id\", how=\"inner\")\ndf_seg[\"npz_path\"] = df_seg[\"case_id\"].map(lambda s: str(Path(TOK_TRAIN_DIR) / f\"{s}.npz\"))\n\ndf_seg[\"npz_exists\"] = df_seg[\"npz_path\"].map(lambda s: Path(s).exists())\ndf_seg = df_seg[df_seg[\"npz_exists\"]].drop(columns=[\"npz_exists\"]).drop_duplicates(\"case_id\").reset_index(drop=True)\n\nprint(\"masks(train):\", len(mask_train), \"| masks(supp):\", len(mask_supp))\nprint(\"df_seg:\", df_seg.shape)\nprint(\"folds:\", sorted(df_seg[\"fold\"].unique().tolist()))\ndisplay(df_seg.head(3))\n\n# ----------------------------\n# Model: UNet decoder + ASPP (token-grid)\n# ----------------------------\nclass ConvGNAct(nn.Module):\n    def __init__(self, in_ch, out_ch, k=3, s=1, p=1, g=16):\n        super().__init__()\n        self.conv = nn.Conv2d(in_ch, out_ch, k, s, p, bias=False)\n        self.gn = nn.GroupNorm(num_groups=min(g, out_ch), num_channels=out_ch)\n        self.act = nn.SiLU(inplace=True)\n    def forward(self, x):\n        return self.act(self.gn(self.conv(x)))\n\nclass ASPP(nn.Module):\n    def __init__(self, in_ch, out_ch, rates=(1, 4, 8, 12)):\n        super().__init__()\n        self.branches = nn.ModuleList()\n        for r in rates:\n            if r == 1:\n                self.branches.append(nn.Sequential(\n                    nn.Conv2d(in_ch, out_ch, 1, bias=False),\n                    nn.GroupNorm(num_groups=min(16, out_ch), num_channels=out_ch),\n                    nn.SiLU(inplace=True),\n                ))\n            else:\n                self.branches.append(nn.Sequential(\n                    nn.Conv2d(in_ch, out_ch, 3, padding=r, dilation=r, bias=False),\n                    nn.GroupNorm(num_groups=min(16, out_ch), num_channels=out_ch),\n                    nn.SiLU(inplace=True),\n                ))\n        self.proj = nn.Sequential(\n            nn.Conv2d(out_ch * len(rates), out_ch, 1, bias=False),\n            nn.GroupNorm(num_groups=min(16, out_ch), num_channels=out_ch),\n            nn.SiLU(inplace=True),\n        )\n    def forward(self, x):\n        ys = [b(x) for b in self.branches]\n        return self.proj(torch.cat(ys, dim=1))\n\nclass UNetASPP(nn.Module):\n    def __init__(self, in_ch=768, base_ch=128):\n        super().__init__()\n        c1, c2, c3 = base_ch, base_ch*2, base_ch*4\n\n        self.enc1 = nn.Sequential(ConvGNAct(in_ch, c1), ConvGNAct(c1, c1))\n        self.down1 = nn.Conv2d(c1, c1, 3, stride=2, padding=1)\n\n        self.enc2 = nn.Sequential(ConvGNAct(c1, c2), ConvGNAct(c2, c2))\n        self.down2 = nn.Conv2d(c2, c2, 3, stride=2, padding=1)\n\n        self.enc3 = nn.Sequential(ConvGNAct(c2, c3), ConvGNAct(c3, c3))\n        self.aspp = ASPP(c3, c3)\n\n        self.up2 = nn.ConvTranspose2d(c3, c2, 2, stride=2)\n        self.dec2 = nn.Sequential(ConvGNAct(c2+c2, c2), ConvGNAct(c2, c2))\n\n        self.up1 = nn.ConvTranspose2d(c2, c1, 2, stride=2)\n        self.dec1 = nn.Sequential(ConvGNAct(c1+c1, c1), ConvGNAct(c1, c1))\n\n        self.head = nn.Conv2d(c1, 1, 1)\n\n    def forward(self, x):\n        e1 = self.enc1(x)                 # (B,c1,37,37)\n        d1 = self.down1(e1)               # (B,c1,19,19)\n        e2 = self.enc2(d1)                # (B,c2,19,19)\n        d2 = self.down2(e2)               # (B,c2,10,10)\n        e3 = self.enc3(d2)                # (B,c3,10,10)\n        b  = self.aspp(e3)                # (B,c3,10,10)\n\n        u2 = self.up2(b)                  # (B,c2,20,20)\n        u2 = u2[:, :, :e2.shape[2], :e2.shape[3]]\n        x2 = self.dec2(torch.cat([u2, e2], dim=1))\n\n        u1 = self.up1(x2)                 # (B,c1,38,38)\n        u1 = u1[:, :, :e1.shape[2], :e1.shape[3]]\n        x1 = self.dec1(torch.cat([u1, e1], dim=1))\n\n        return self.head(x1)              # (B,1,37,37)\n\n# ----------------------------\n# Dataset: token npz + mask npy -> y_tok (37x37)\n# ----------------------------\nclass TokMaskDS(Dataset):\n    def __init__(self, df: pd.DataFrame, htok=37, wtok=37, dim=768, aug=False):\n        self.case_id = df[\"case_id\"].astype(str).tolist()\n        self.npz_path = df[\"npz_path\"].astype(str).tolist()\n        self.mask_path = df[\"mask_path\"].astype(str).tolist()\n        self.htok, self.wtok, self.dim = int(htok), int(wtok), int(dim)\n        self.aug = bool(aug)\n\n    def __len__(self):\n        return len(self.case_id)\n\n    def __getitem__(self, i):\n        # tokens\n        with np.load(self.npz_path[i]) as z:\n            a = z[z.files[0]]\n        a = np.asarray(a)\n\n        # robust to (H,W,C) or (C,H,W)\n        try:\n            x = np.moveaxis(a, -1, 0)\n            assert x.shape[0] == self.dim\n        except Exception:\n            x = a\n        x = torch.from_numpy(np.asarray(x, dtype=np.float32))  # (768,37,37)\n\n        # mask: robust to (H,W) or (1,H,W) or (K,H,W)\n        m = np.load(self.mask_path[i])\n        m = np.asarray(m)\n        m = np.squeeze(m)\n        if m.ndim == 3:\n            m = m.max(axis=0)\n        m = np.asarray(m, dtype=np.float32)\n\n        y = torch.from_numpy(m).unsqueeze(0).unsqueeze(0)      # (1,1,H,W)\n        y = F.interpolate(y, size=(self.htok, self.wtok), mode=\"nearest\")[0, 0]  # (37,37)\n\n        if self.aug:\n            r = random.random()\n            if r < 0.25:\n                x = torch.flip(x, dims=[2]); y = torch.flip(y, dims=[1])\n            elif r < 0.50:\n                x = torch.flip(x, dims=[1]); y = torch.flip(y, dims=[0])\n            elif r < 0.75:\n                x = torch.flip(x, dims=[1,2]); y = torch.flip(y, dims=[0,1])\n\n        return x, y\n\n# ----------------------------\n# Loss (BCE + soft-dice)\n# ----------------------------\ndef soft_dice_loss(logits, targets, eps=1e-6):\n    probs = torch.sigmoid(logits)\n    num = 2.0 * (probs * targets).sum(dim=(2,3)) + eps\n    den = (probs + targets).sum(dim=(2,3)) + eps\n    return (1.0 - (num / den)).mean()\n\nbce = nn.BCEWithLogitsLoss()\n\n# ----------------------------\n# Train one fold\n# ----------------------------\ndef train_one_fold(df_all, fold):\n    df_tr = df_all[df_all[\"fold\"] != int(fold)].reset_index(drop=True)\n    df_va = df_all[df_all[\"fold\"] == int(fold)].reset_index(drop=True)\n\n    ds_tr = TokMaskDS(df_tr, htok=SEG_CFG.htok, wtok=SEG_CFG.wtok, dim=SEG_CFG.dim, aug=True)\n    ds_va = TokMaskDS(df_va, htok=SEG_CFG.htok, wtok=SEG_CFG.wtok, dim=SEG_CFG.dim, aug=False)\n\n    dl_tr = DataLoader(ds_tr, batch_size=SEG_CFG.batch_size, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n    dl_va = DataLoader(ds_va, batch_size=SEG_CFG.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n\n    model = UNetASPP(in_ch=SEG_CFG.dim, base_ch=SEG_CFG.base_ch).to(DEVICE)\n    opt = torch.optim.AdamW(model.parameters(), lr=SEG_CFG.lr, weight_decay=1e-4)\n\n    best = float(\"inf\")\n    best_state = None\n    patience = 6\n    bad = 0\n    hist = {\"train_loss\": [], \"val_loss\": []}\n\n    for epoch in range(1, SEG_CFG.epochs + 1):\n        model.train()\n        tr_loss = 0.0\n        n_tr = 0\n\n        for x, y in tqdm(dl_tr, desc=f\"fold{fold} train ep{epoch}\", leave=False):\n            x = x.to(DEVICE, non_blocking=True)\n            y = y.to(DEVICE, non_blocking=True).unsqueeze(1)   # (B,1,37,37)\n\n            opt.zero_grad(set_to_none=True)\n            logits = model(x)\n            loss = bce(logits, y) + 0.5 * soft_dice_loss(logits, y)\n            loss.backward()\n            opt.step()\n\n            bs = x.size(0)\n            tr_loss += loss.item() * bs\n            n_tr += bs\n\n        model.eval()\n        va_loss = 0.0\n        n_va = 0\n        with torch.inference_mode():\n            for x, y in dl_va:\n                x = x.to(DEVICE, non_blocking=True)\n                y = y.to(DEVICE, non_blocking=True).unsqueeze(1)\n                logits = model(x)\n                loss = bce(logits, y) + 0.5 * soft_dice_loss(logits, y)\n                bs = x.size(0)\n                va_loss += loss.item() * bs\n                n_va += bs\n\n        tr = tr_loss / max(1, n_tr)\n        va = va_loss / max(1, n_va)\n        hist[\"train_loss\"].append(tr)\n        hist[\"val_loss\"].append(va)\n\n        print(f\"[fold {fold}] ep{epoch:02d} train={tr:.5f} val={va:.5f}\")\n\n        if va < best:\n            best = va\n            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n            bad = 0\n        else:\n            bad += 1\n            if bad >= patience:\n                break\n\n    model.load_state_dict(best_state, strict=True)\n    return model, hist\n\n# ----------------------------\n# Train CV + Save\n# ----------------------------\nuniq_folds = sorted(df_seg[\"fold\"].unique().tolist())\n\nall_hist = {}\nmodel_paths = []\n\nfor f in uniq_folds:\n    model, hist = train_one_fold(df_seg, f)\n\n    out_path = Path(SEG_RUN_DIR) / f\"seg_unet_aspp_fold{int(f)}.pt\"\n    torch.save(\n        {\n            \"state_dict\": model.state_dict(),\n            \"seg_cfg\": asdict(SEG_CFG),\n            \"seg_cfg_id\": SEG_CFG_ID,\n            \"fold\": int(f),\n            \"token_grid\": {\"htok\": SEG_CFG.htok, \"wtok\": SEG_CFG.wtok, \"dim\": SEG_CFG.dim},\n        },\n        out_path\n    )\n\n    all_hist[str(int(f))] = hist\n    model_paths.append(str(out_path))\n    print(\"SAVED:\", out_path)\n\nsummary_path = Path(SEG_RUN_DIR) / \"seg_cv_history.json\"\nsummary_path.write_text(json.dumps(\n    {\"seg_cfg\": asdict(SEG_CFG), \"seg_cfg_id\": SEG_CFG_ID, \"models\": model_paths, \"history\": all_hist},\n    indent=2\n))\nprint(\"SAVED:\", summary_path)\n\ngc.collect()\ntry:\n    torch.cuda.empty_cache()\nexcept Exception:\n    pass\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T10:20:00.433307Z","iopub.execute_input":"2026-01-17T10:20:00.434485Z"}},"outputs":[{"name":"stdout","text":"DEVICE: cpu\nTOK_TRAIN_DIR: /kaggle/input/recod-ailuc-dinov2-base/recodai_luc/cache/dinov2_base_518_cfg_543289469500/train\nSEG_RUN_DIR  : /kaggle/working/recodai_luc/seg_runs/seg_unet_aspp_tok37_dinov2b_898cfeeba43a\nmasks(train): 2751 | masks(supp): 48\ndf_seg: (2795, 4)\nfolds: [0, 1, 2, 3, 4]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  case_id                                          mask_path  fold  \\\n0      10  /kaggle/input/recodai-luc-scientific-image-for...     3   \n1   10015  /kaggle/input/recodai-luc-scientific-image-for...     4   \n2   10017  /kaggle/input/recodai-luc-scientific-image-for...     2   \n\n                                            npz_path  \n0  /kaggle/input/recod-ailuc-dinov2-base/recodai_...  \n1  /kaggle/input/recod-ailuc-dinov2-base/recodai_...  \n2  /kaggle/input/recod-ailuc-dinov2-base/recodai_...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>case_id</th>\n      <th>mask_path</th>\n      <th>fold</th>\n      <th>npz_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10</td>\n      <td>/kaggle/input/recodai-luc-scientific-image-for...</td>\n      <td>3</td>\n      <td>/kaggle/input/recod-ailuc-dinov2-base/recodai_...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10015</td>\n      <td>/kaggle/input/recodai-luc-scientific-image-for...</td>\n      <td>4</td>\n      <td>/kaggle/input/recod-ailuc-dinov2-base/recodai_...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10017</td>\n      <td>/kaggle/input/recodai-luc-scientific-image-for...</td>\n      <td>2</td>\n      <td>/kaggle/input/recod-ailuc-dinov2-base/recodai_...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n  warnings.warn(warn_msg)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"fold0 train ep1:   0%|          | 0/139 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"[fold 0] ep01 train=0.56343 val=0.50878\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"fold0 train ep2:   0%|          | 0/139 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"[fold 0] ep02 train=0.49327 val=0.46714\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"fold0 train ep3:   0%|          | 0/139 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"[fold 0] ep03 train=0.45646 val=0.44441\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"fold0 train ep4:   0%|          | 0/139 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"[fold 0] ep04 train=0.43185 val=0.43497\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"fold0 train ep5:   0%|          | 0/139 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"[fold 0] ep05 train=0.41134 val=0.42622\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"fold0 train ep6:   0%|          | 0/139 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"[fold 0] ep06 train=0.39456 val=0.41172\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"fold0 train ep7:   0%|          | 0/139 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^Exception ignored in: ^\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>AssertionError\n: Traceback (most recent call last):\ncan only test a child process  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n\n    Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>self._shutdown_workers()\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n        self._shutdown_workers()if w.is_alive():\n\n   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n      if w.is_alive(): \n       ^ ^ ^ ^^^^^^^^^^^^^^^^^^\n^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^^    \nassert self._parent_pid == os.getpid(), 'can only test a child process'\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n       assert self._parent_pid == os.getpid(), 'can only test a child process'  \n             ^^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^^AssertionError: ^can only test a child process^\n^\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>AssertionError: \ncan only test a child processTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\nException ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>self._shutdown_workers()\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n        self._shutdown_workers()\nif w.is_alive():  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n\n      if w.is_alive(): \n          ^ ^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n      File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\nassert self._parent_pid == os.getpid(), 'can only test a child process'\n       assert self._parent_pid == os.getpid(), 'can only test a child process'  \n            ^ ^ ^  ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError: ^can only test a child process^\n\nException ignored in: AssertionError<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>: \ncan only test a child processTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    \nself._shutdown_workers()\nException ignored in:   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>    \nif w.is_alive():Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n\n     self._shutdown_workers()\n    File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n     if w.is_alive():\n        ^^ ^ ^^^^^^^^^^^^^^^^^^\n^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process' \n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^AssertionError^: ^can only test a child process^\n^\nAssertionErrorException ignored in: : <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>can only test a child process\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>    \nself._shutdown_workers()Traceback (most recent call last):\n\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n        if w.is_alive():\nself._shutdown_workers()  \n   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n        ^if w.is_alive():^\n^ ^ ^ ^ ^^ ^ ^ ^^^^^\n^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n^  ^  ^ ^ \n    File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n      assert self._parent_pid == os.getpid(), 'can only test a child process' ^\n ^^ ^^  ^^ ^^ ^  ^ ^^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError: ^can only test a child process^^\n^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>^\n^^Traceback (most recent call last):\n^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^    ^self._shutdown_workers()\n^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    ^if w.is_alive():^\n^  ^  ^ ^ \n AssertionError^: ^^^can only test a child process\n^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>^^\n^Traceback (most recent call last):\n^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    \n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\nself._shutdown_workers()    \nassert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n\n       if w.is_alive():\n             ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n ^^ ^  ^^ ^ ^  ^ ^ \nAssertionError : ^can only test a child process\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\n^^Traceback (most recent call last):\n^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    ^^self._shutdown_workers()^\n^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    ^^^if w.is_alive():\n^ ^   ^ ^ ^ ^^^^^^^^^^^^^^^^\n^AssertionError^^: ^can only test a child process\n\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    Exception ignored in: assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\n\nTraceback (most recent call last):\n   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n      self._shutdown_workers()  \n    File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n       if w.is_alive(): \n^ ^^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^\n^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^ ^ ^ ^ ^ ^ \n AssertionError :  can only test a child process \n ^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\n^Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^^    ^self._shutdown_workers()^\n^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^    ^if w.is_alive():^\n ^ ^^ ^ ^ ^^ ^ ^^^^^^^^^^^^^^^^^^^^^\n^AssertionError\n: can only test a child process  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n  Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>  \n Traceback (most recent call last):\n   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n         self._shutdown_workers()^\n^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^^    if w.is_alive():^\n^ ^ ^^ ^ ^^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^\n^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    ^^^assert self._parent_pid == os.getpid(), 'can only test a child process'\n\nAssertionError :  can only test a child process  \n Exception ignored in:   <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680> \nTraceback (most recent call last):\n    File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n     ^self._shutdown_workers()^\n^^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^    ^if w.is_alive():^\n^ ^^ ^  ^  ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nAssertionError  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\ncan only test a child process:     assert self._parent_pid == os.getpid(), 'can only test a child process'\n\n Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\n  Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n      self._shutdown_workers() \n   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n       ^^if w.is_alive():^\n^ ^^ ^ ^ ^^ ^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^\n^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n ^\n AssertionError : can only test a child process \n Exception ignored in:   <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680> \n  Traceback (most recent call last):\n   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^    ^self._shutdown_workers()^\n^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^    ^if w.is_alive():^^\n^ ^ ^  ^ ^  ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n\nAssertionError :  can only test a child process \n  Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680> \n Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n       self._shutdown_workers()^\n^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^    if w.is_alive():^\n^  ^ ^ ^^ ^  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^\n AssertionError :   can only test a child process  \n    Exception ignored in:  ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>^\n^^Traceback (most recent call last):\n^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^    ^self._shutdown_workers()^\n^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^    if w.is_alive():\n^ ^ ^ ^^ ^  ^^ ^^^^^^^^^^^^^^^^^^\n^^AssertionError: ^can only test a child process\n^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    Exception ignored in: assert self._parent_pid == os.getpid(), 'can only test a child process'\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>  \n Traceback (most recent call last):\n   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n       self._shutdown_workers() \n   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n      ^if w.is_alive():^^\n^^ ^^ ^^^   ^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^    assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^  ^ ^^ ^\n AssertionError : can only test a child process\n  Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680> \n Traceback (most recent call last):\n^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^    ^self._shutdown_workers()^\n^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    ^if w.is_alive():^^\n^ ^^ ^^^ ^ ^  ^ ^^^^^^^^^^^^^^^^^^^^^^^^\n^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^    \nAssertionError: assert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child process\n \n  Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680> \n Traceback (most recent call last):\n   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n      self._shutdown_workers() \n  ^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^    ^^if w.is_alive():^\n^ ^ ^^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^\n^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'\n^^ ^  \n  AssertionError  :  can only test a child process  \n ^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>^\n^Traceback (most recent call last):\n^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^    ^^self._shutdown_workers()\n^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^^    ^if w.is_alive():^\n ^ ^  ^ ^ ^^^ ^^^^^^^^^^^^^^^^^\n^^AssertionError^: can only test a child process^\n\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"[fold 0] ep07 train=0.38021 val=0.40858\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"fold0 train ep8:   0%|          | 0/139 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>^^\n^^Traceback (most recent call last):\n^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^^    ^self._shutdown_workers()^\n^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^    \nif w.is_alive():\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n      assert self._parent_pid == os.getpid(), 'can only test a child process'  \n     ^  ^^ ^ ^ ^  ^  ^^^^^^^^^\n^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^\n^^ ^   ^^ ^^^ ^^^ ^ ^ ^ ^ ^^^^^^^\n^AssertionError^: can only test a child process^\n^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>^\nTraceback (most recent call last):\n^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^    ^^self._shutdown_workers()\n^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^    ^if w.is_alive():^^^\n^ ^ ^ ^ ^ ^ ^^ ^^^^^^^^^^\n^^AssertionError^: ^can only test a child process^\n^Exception ignored in: ^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\n      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\nassert self._parent_pid == os.getpid(), 'can only test a child process'    \nself._shutdown_workers()\n    File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n      if w.is_alive(): \n            ^^ ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n ^ ^ ^^ ^^ ^ ^ ^^ ^ ^ ^ ^^^^^^\n^AssertionError^: ^can only test a child process^\n^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>^\n^Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^    ^self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^^    if w.is_alive():^^\n^ ^ ^  ^ ^  ^^^^^^^^^^^^^\n^AssertionError^: can only test a child process^^\n^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\n\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    Exception ignored in: assert self._parent_pid == os.getpid(), 'can only test a child process'    <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>self._shutdown_workers()\n\n \n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n Traceback (most recent call last):\n       File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\nif w.is_alive():     \nself._shutdown_workers()Exception ignored in:  \n  <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n  \nTraceback (most recent call last):\n       File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n  if w.is_alive(): \n         self._shutdown_workers()  \n^^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^^ ^    ^ ^ ^if w.is_alive(): ^^\n ^^ ^^ ^^^^^ ^ ^^ ^^^  ^^^^^^^^^^^^^^^\n^^^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^^^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^\n^^ \n^^ ^ ^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n ^^ ^     ^ ^assert self._parent_pid == os.getpid(), 'can only test a child process' ^^\n\n\nAssertionError    File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n:   can only test a child process\n ^    Exception ignored in: ^ assert self._parent_pid == os.getpid(), 'can only test a child process'^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680> ^ \n\n  ^Traceback (most recent call last):\n    File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^      self._shutdown_workers()^^  ^ \n^ ^ ^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n ^^ ^^ ^    ^ if w.is_alive():^^ \n^^  ^^^ ^^^ ^^^^ ^^^^^^ ^^^ ^^^^^^^ ^^^^^^^^^^^^^^^^^\n^^^AssertionError^: ^^^can only test a child process^^^^\n^^^^^Exception ignored in: ^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>^\n^Traceback (most recent call last):\n^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^^^    ^\nself._shutdown_workers()\n^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^    ^    if w.is_alive():^^\nassert self._parent_pid == os.getpid(), 'can only test a child process' ^^ \n \n^ ^ AssertionError   ^: ^   ^^can only test a child process\n^ \n ^AssertionError^Exception ignored in: :  ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680> ^can only test a child process\n\n^ Traceback (most recent call last):\n ^Exception ignored in:   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>^    ^\n^^^Traceback (most recent call last):\nself._shutdown_workers()^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^\n\n      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    self._shutdown_workers()    ^\nassert self._parent_pid == os.getpid(), 'can only test a child process'^if w.is_alive():\n\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^      ^  if w.is_alive():  \n^   ^^     ^   ^^  ^^^  ^^^  ^^^ ^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^\n^^^^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^    ^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^^\n\n\n^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\nAssertionError ^:      ^can only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'\n^\n   ^^ Exception ignored in:  ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>  ^\n  ^ Traceback (most recent call last):\n  ^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n  ^       ^ self._shutdown_workers()^ \n ^^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^^^    ^^^^^if w.is_alive():^^^\n^^^\n ^^AssertionError^ ^: ^^can only test a child process ^^^\n ^ ^ ^^Exception ignored in:  ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>^^^\n^^^Traceback (most recent call last):\n^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^^^^^^    ^^^^^self._shutdown_workers()^^^^^\n^^^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^^^^^    ^^^^if w.is_alive():^\n\n^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n ^^    ^^ ^assert self._parent_pid == os.getpid(), 'can only test a child process' ^^^ \n^^ \n AssertionError^   : \n  can only test a child process^ AssertionError: ^\n can only test a child process^Exception ignored in:  \n ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>^ \nTraceback (most recent call last):\n^Exception ignored in:  ^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>^\n     self._shutdown_workers()^^Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^    ^    ^self._shutdown_workers()^if w.is_alive():\n^\n\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^     ^    assert self._parent_pid == os.getpid(), 'can only test a child process' \n if w.is_alive():^  \n^     ^    ^ ^  ^ ^ ^ ^  ^^^^ ^^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^\n^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^^^\n^^ \n^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n ^     ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^ ^\n^ ^ ^^  ^ ^ ^^ ^  \n^ AssertionError^  ^:  can only test a child process ^\n  ^^ Exception ignored in: ^^ ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>^^^^^\n^^^Traceback (most recent call last):\n^^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^^^^    ^^^^self._shutdown_workers()^\n^\n^^AssertionError^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^^    ^^: if w.is_alive():^^can only test a child process^\n^\n^ ^Exception ignored in:  ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>^^\n ^Traceback (most recent call last):\n^ ^   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^^ ^     ^^^^self._shutdown_workers()^^^^\n^^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^^^^^    ^^if w.is_alive():^^^^\n^^ \n^^ AssertionError^^: ^ ^can only test a child process^\n \n^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n ^     Exception ignored in: assert self._parent_pid == os.getpid(), 'can only test a child process'^ <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\n^\n\n AssertionError^Traceback (most recent call last):\n :   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^ can only test a child process     \nself._shutdown_workers()^ ^\nException ignored in:    File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>^\n     ^ Traceback (most recent call last):\nif w.is_alive():   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^\n^      ^ self._shutdown_workers()^\n^ ^ ^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n\n^       File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^if w.is_alive(): ^ \n     ^^^assert self._parent_pid == os.getpid(), 'can only test a child process' ^^\n ^^   ^^  ^ ^^^  ^^ ^ ^ ^^^^^ ^ ^^ ^^ ^^^^^ \n^^^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^^^^^    ^^^^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^^^^\n^^ ^^ ^^^ ^\n^^   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n     ^\n ^assert self._parent_pid == os.getpid(), 'can only test a child process' AssertionError^\n  :   ^can only test a child process  ^\n^  ^ ^^ Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680> \n^^ Traceback (most recent call last):\n^^^ ^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^     ^^^self._shutdown_workers() \n^^^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^^^    ^^^if w.is_alive():^\n^^^ ^^ ^\n^ ^AssertionError ^^^ ^: ^^  ^^^can only test a child process^^^^\n^^^^^^^^^Exception ignored in: ^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>^^^^\n^^^^Traceback (most recent call last):\n^^^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^^^^    ^^^self._shutdown_workers()\n^\n\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^AssertionError        : if w.is_alive():^assert self._parent_pid == os.getpid(), 'can only test a child process'^^can only test a child process\n\n^\n^  ^  Exception ignored in: \n  <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>AssertionError \n:  can only test a child process Traceback (most recent call last):\n  \n   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n  Exception ignored in:      ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>self._shutdown_workers() ^ \n\n^ Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    ^^    ^^if w.is_alive():^self._shutdown_workers()\n^^ \n^^^   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^^     ^^  ^^if w.is_alive():^\n \n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^      ^assert self._parent_pid == os.getpid(), 'can only test a child process'^ ^^ \n ^^ ^^^   ^ ^^^ ^^^  ^^ ^^^ ^  ^^^^ ^^^^^ ^\n^^^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^^    ^^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^^\n\n^^ ^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^     ^^ assert self._parent_pid == os.getpid(), 'can only test a child process'\n\n^  AssertionError^  : ^ can only test a child process  ^\n  ^ ^ ^  ^ ^  ^ ^^^^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^AssertionError^^: ^^^can only test a child process^^^\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError: ^can only test a child process\n\nAssertionError: can only test a child processException ignored in: \n<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>\nTraceback (most recent call last):\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n\n    self._shutdown_workers()\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n        if w.is_alive():self._shutdown_workers()\n\n    File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n       if w.is_alive():  \n^  ^^ ^ ^ ^ ^^ ^^^^^^^^\n^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'\n ^  ^ ^ ^  \n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n       assert self._parent_pid == os.getpid(), 'can only test a child process'\n  ^^  ^ ^ ^ ^ ^ ^  ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError^^: can only test a child process^\n^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>^\n^Traceback (most recent call last):\n^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^^    ^self._shutdown_workers()^\n\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\nAssertionError    : if w.is_alive():can only test a child process\n\n   Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7cf50570c680>  \n Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^    ^self._shutdown_workers()^\n^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    ^if w.is_alive():^\n^  ^ ^ ^  ^ \n^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^^ ^ ^^ ^ ^ ^ ^\n    File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n      assert self._parent_pid == os.getpid(), 'can only test a child process' \n^^^ ^ ^^ ^^ ^ ^ ^ ^ ^^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: can only test a child process^\n^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"[fold 0] ep08 train=0.36798 val=0.40896\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"fold0 train ep9:   0%|          | 0/139 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dad5b3800fe4873a61ee95a81b159e3"}},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":"# Seg OOF/Test Inference + Post-Process + Export pred_features","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE — Seg OOF/Test Inference + Post-Process + Export pred_features  [ONE CELL]\n# - Load fold models from SEG_RUN_DIR\n# - Inference on TRAIN (OOF by fold) + TEST (ensemble)\n# - Save prob token-grid as .npz in CACHE_ROOT/pred_ens/{train,test}/{case_id}.npz\n# - Build pred_features_{train,test}.csv (schema compatible with your gate stage)\n#\n# REQUIRE globals:\n#   COMP_ROOT, CACHE_ROOT, TRAIN_MANIFEST, TEST_MANIFEST, FOLDS_PATH\n#   TOKEN_CACHE_ROOT or TOK_TRAIN_DIR/TOK_TEST_DIR\n#   SEG_RUN_DIR, SEG_CFG, SEG_CFG_ID\n# ============================================================\n\nimport os, re, gc, json, math\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\nimport torch\nimport torch.nn.functional as F\n\n# ----------------------------\n# Device\n# ----------------------------\ntry:\n    _ = torch.zeros(1).cuda()\n    DEVICE = torch.device(\"cuda\")\nexcept Exception:\n    DEVICE = torch.device(\"cpu\")\n\nprint(\"DEVICE:\", DEVICE)\nprint(\"SEG_RUN_DIR:\", SEG_RUN_DIR)\n\n# ----------------------------\n# Minimal model definition (must match training cell)\n# ----------------------------\nimport torch.nn as nn\n\nclass ConvGNAct(nn.Module):\n    def __init__(self, in_ch, out_ch, k=3, s=1, p=1, g=16):\n        super().__init__()\n        self.conv = nn.Conv2d(in_ch, out_ch, k, s, p, bias=False)\n        self.gn = nn.GroupNorm(num_groups=min(g, out_ch), num_channels=out_ch)\n        self.act = nn.SiLU(inplace=True)\n    def forward(self, x):\n        return self.act(self.gn(self.conv(x)))\n\nclass ASPP(nn.Module):\n    def __init__(self, in_ch, out_ch, rates=(1, 4, 8, 12)):\n        super().__init__()\n        self.branches = nn.ModuleList()\n        for r in rates:\n            if r == 1:\n                self.branches.append(nn.Sequential(\n                    nn.Conv2d(in_ch, out_ch, 1, bias=False),\n                    nn.GroupNorm(num_groups=min(16, out_ch), num_channels=out_ch),\n                    nn.SiLU(inplace=True),\n                ))\n            else:\n                self.branches.append(nn.Sequential(\n                    nn.Conv2d(in_ch, out_ch, 3, padding=r, dilation=r, bias=False),\n                    nn.GroupNorm(num_groups=min(16, out_ch), num_channels=out_ch),\n                    nn.SiLU(inplace=True),\n                ))\n        self.proj = nn.Sequential(\n            nn.Conv2d(out_ch * len(rates), out_ch, 1, bias=False),\n            nn.GroupNorm(num_groups=min(16, out_ch), num_channels=out_ch),\n            nn.SiLU(inplace=True),\n        )\n    def forward(self, x):\n        ys = [b(x) for b in self.branches]\n        return self.proj(torch.cat(ys, dim=1))\n\nclass UNetASPP(nn.Module):\n    def __init__(self, in_ch=768, base_ch=128):\n        super().__init__()\n        c1, c2, c3 = base_ch, base_ch*2, base_ch*4\n\n        self.enc1 = nn.Sequential(ConvGNAct(in_ch, c1), ConvGNAct(c1, c1))\n        self.down1 = nn.Conv2d(c1, c1, 3, stride=2, padding=1)\n\n        self.enc2 = nn.Sequential(ConvGNAct(c1, c2), ConvGNAct(c2, c2))\n        self.down2 = nn.Conv2d(c2, c2, 3, stride=2, padding=1)\n\n        self.enc3 = nn.Sequential(ConvGNAct(c2, c3), ConvGNAct(c3, c3))\n        self.aspp = ASPP(c3, c3)\n\n        self.up2 = nn.ConvTranspose2d(c3, c2, 2, stride=2)\n        self.dec2 = nn.Sequential(ConvGNAct(c2+c2, c2), ConvGNAct(c2, c2))\n\n        self.up1 = nn.ConvTranspose2d(c2, c1, 2, stride=2)\n        self.dec1 = nn.Sequential(ConvGNAct(c1+c1, c1), ConvGNAct(c1, c1))\n\n        self.head = nn.Conv2d(c1, 1, 1)\n\n    def forward(self, x):\n        e1 = self.enc1(x)\n        d1 = self.down1(e1)\n        e2 = self.enc2(d1)\n        d2 = self.down2(e2)\n        e3 = self.enc3(d2)\n        b  = self.aspp(e3)\n\n        u2 = self.up2(b)\n        u2 = u2[:, :, :e2.shape[2], :e2.shape[3]]\n        x2 = self.dec2(torch.cat([u2, e2], dim=1))\n\n        u1 = self.up1(x2)\n        u1 = u1[:, :, :e1.shape[2], :e1.shape[3]]\n        x1 = self.dec1(torch.cat([u1, e1], dim=1))\n\n        return self.head(x1)\n\n# ----------------------------\n# Load fold models\n# ----------------------------\nckpts = sorted(Path(SEG_RUN_DIR).glob(\"seg_unet_aspp_fold*.pt\"))\nprint(\"Found ckpts:\", len(ckpts))\nfold_models = {}\nfor p in ckpts:\n    m = re.search(r\"fold(\\d+)\", p.name)\n    fold = int(m.group(1))\n    pack = torch.load(p, map_location=\"cpu\")\n    model = UNetASPP(in_ch=SEG_CFG.dim, base_ch=SEG_CFG.base_ch)\n    model.load_state_dict(pack[\"state_dict\"], strict=True)\n    model.eval().to(DEVICE)\n    fold_models[fold] = model\n\nfold_list = sorted(fold_models.keys())\nprint(\"Folds:\", fold_list)\n\n# ----------------------------\n# Token loader (from token cache train/test dirs)\n# - expects npz contains array (37,37,768) or (768,37,37)\n# ----------------------------\nTOK_TRAIN_DIR = Path(TOKEN_CACHE_ROOT) / \"train\" if \"TOKEN_CACHE_ROOT\" in globals() else Path(TOK_TRAIN_DIR)\nTOK_TEST_DIR  = Path(TOKEN_CACHE_ROOT) / \"test\"  if \"TOKEN_CACHE_ROOT\" in globals() else Path(TOK_TEST_DIR)\n\ndef load_token_npz(npz_path: str):\n    with np.load(npz_path) as z:\n        a = z[z.files[0]]\n    a = np.asarray(a)\n    try:\n        x = np.moveaxis(a, -1, 0)  # (C,H,W)\n        _ = x.shape[0]\n        return x\n    except Exception:\n        return a\n\n# ----------------------------\n# Inference helper\n# ----------------------------\n@torch.inference_mode()\ndef infer_probs(model, x):\n    x = x.to(DEVICE, non_blocking=True)\n    logits = model(x)\n    probs = torch.sigmoid(logits).squeeze(1)  # (B,37,37)\n    return probs.detach().cpu().numpy().astype(np.float32)\n\ndef save_prob_tok(out_dir: Path, case_id: str, prob_tok: np.ndarray):\n    out_dir.mkdir(parents=True, exist_ok=True)\n    p = out_dir / f\"{case_id}.npz\"\n    np.savez_compressed(p, prob_tok=prob_tok.astype(np.float16))\n    return str(p)\n\n# ----------------------------\n# Feature extraction from token-prob map\n# ----------------------------\ndef feats_from_prob_tok(prob_tok: np.ndarray, thr_tok=0.5):\n    m = (prob_tok >= thr_tok).astype(np.uint8)\n    area_frac_tok = float(m.mean())\n    mean_prob_tok = float(prob_tok.mean())\n    has_prob = int(area_frac_tok > 0.0)\n    n_inst = int(has_prob)  # simple proxy (no CC to keep fast + stable)\n    return mean_prob_tok, area_frac_tok, has_prob, n_inst\n\n# ----------------------------\n# Load manifests + folds + labels\n# ----------------------------\ndf_train = pd.read_parquet(TRAIN_MANIFEST).copy()\ndf_test  = pd.read_parquet(TEST_MANIFEST).copy()\ndf_folds = pd.read_parquet(FOLDS_PATH).copy()\n\ndf_train[\"case_id\"] = df_train[\"case_id\"].astype(str)\ndf_test[\"case_id\"]  = df_test[\"case_id\"].astype(str)\ndf_folds[\"case_id\"] = df_folds[\"case_id\"].astype(str)\n\ndf_train = df_train.merge(df_folds[[\"case_id\",\"fold\"]], on=\"case_id\", how=\"left\")\ndf_train[\"fold\"] = df_train[\"fold\"].astype(int)\n\n# label y: forged=1, authentic=0; train_manifest already has y in your pipeline\nif \"y\" not in df_train.columns:\n    df_train[\"y\"] = (df_train[\"label\"].astype(str).str.lower() == \"forged\").astype(int)\n\n# ----------------------------\n# Output dirs (pred_ens)\n# ----------------------------\nPRED_DIR = Path(CACHE_ROOT) / \"pred_ens\"\nPRED_TRAIN_DIR = PRED_DIR / \"train\"\nPRED_TEST_DIR  = PRED_DIR / \"test\"\nPRED_DIR.mkdir(parents=True, exist_ok=True)\nPRED_TRAIN_DIR.mkdir(parents=True, exist_ok=True)\nPRED_TEST_DIR.mkdir(parents=True, exist_ok=True)\n\n# ----------------------------\n# OOF inference (train): use model of that fold only\n# ----------------------------\nrows_train = []\nBATCH = 32\n\ntrain_case = df_train[\"case_id\"].tolist()\ntrain_fold = df_train[\"fold\"].tolist()\n\nfor i0 in tqdm(range(0, len(df_train), BATCH), desc=\"TRAIN OOF\"):\n    sl = slice(i0, min(len(df_train), i0 + BATCH))\n    cids = train_case[sl]\n    folds = train_fold[sl]\n\n    # group by fold inside batch (simple)\n    for fold in sorted(set(folds)):\n        idxs = [k for k, ff in enumerate(folds) if ff == fold]\n        if len(idxs) == 0:\n            continue\n\n        grids = []\n        cid_sub = []\n        for k in idxs:\n            cid = cids[k]\n            npz_path = str(TOK_TRAIN_DIR / f\"{cid}.npz\")\n            g = load_token_npz(npz_path)            # (C,H,W)\n            grids.append(g.astype(np.float32))\n            cid_sub.append(cid)\n\n        x = torch.from_numpy(np.stack(grids, axis=0))\n        prob_batch = infer_probs(fold_models[int(fold)], x)\n\n        for cid, prob_tok in zip(cid_sub, prob_batch):\n            pred_npz = save_prob_tok(PRED_TRAIN_DIR, str(cid), prob_tok)\n            mean_prob_tok, area_frac_tok, has_prob, n_inst = feats_from_prob_tok(prob_tok, thr_tok=0.5)\n\n            rows_train.append({\n                \"case_id\": str(cid),\n                \"uid_safe\": str(cid),\n                \"split\": \"train\",\n                \"y\": int(df_train.loc[df_train[\"case_id\"] == str(cid), \"y\"].iloc[0]),\n                \"fold\": int(fold),\n                \"n_inst\": n_inst,\n                \"area_frac\": area_frac_tok,\n                \"area_frac_tok\": area_frac_tok,\n                \"mean_prob_tok\": mean_prob_tok,\n                \"has_prob\": has_prob,\n                \"prob_exists\": True,\n                \"npz_path\": pred_npz,\n            })\n\ndf_pred_train = pd.DataFrame(rows_train).sort_values([\"case_id\"]).reset_index(drop=True)\nprint(\"df_pred_train:\", df_pred_train.shape)\ndisplay(df_pred_train.head(3))\n\n# ----------------------------\n# TEST inference (ensemble avg)\n# ----------------------------\nrows_test = []\ntest_case = df_test[\"case_id\"].tolist()\n\nfor i0 in tqdm(range(0, len(df_test), BATCH), desc=\"TEST ensemble\"):\n    sl = slice(i0, min(len(df_test), i0 + BATCH))\n    cids = test_case[sl]\n\n    grids = []\n    for cid in cids:\n        npz_path = str(TOK_TEST_DIR / f\"{cid}.npz\")\n        g = load_token_npz(npz_path)\n        grids.append(g.astype(np.float32))\n\n    x = torch.from_numpy(np.stack(grids, axis=0))\n\n    acc = infer_probs(fold_models[int(fold_list[0])], x)\n    for fold in fold_list[1:]:\n        acc = acc + infer_probs(fold_models[int(fold)], x)\n    prob_tok_batch = acc / float(len(fold_list))\n\n    for cid, prob_tok in zip(cids, prob_tok_batch):\n        pred_npz = save_prob_tok(PRED_TEST_DIR, str(cid), prob_tok)\n        mean_prob_tok, area_frac_tok, has_prob, n_inst = feats_from_prob_tok(prob_tok, thr_tok=0.5)\n\n        rows_test.append({\n            \"case_id\": str(cid),\n            \"uid_safe\": str(cid),\n            \"split\": \"test\",\n            \"y\": np.nan,\n            \"fold\": -1,\n            \"n_inst\": n_inst,\n            \"area_frac\": area_frac_tok,\n            \"area_frac_tok\": area_frac_tok,\n            \"mean_prob_tok\": mean_prob_tok,\n            \"has_prob\": has_prob,\n            \"prob_exists\": True,\n            \"npz_path\": pred_npz,\n        })\n\ndf_pred_test = pd.DataFrame(rows_test).sort_values([\"case_id\"]).reset_index(drop=True)\nprint(\"df_pred_test:\", df_pred_test.shape)\ndisplay(df_pred_test.head(3))\n\n# ----------------------------\n# Export pred_features_{train,test}.csv (for Gate model)\n# (Add a few safe placeholder cols expected by many gate notebooks)\n# ----------------------------\ndef export_features(df_pred, out_csv: Path):\n    df = df_pred.copy()\n    df[\"has_match\"] = 0\n    df[\"best_peak_score\"] = 0\n    df[\"match_exists\"] = False\n    df[\"n_inst\"] = df[\"n_inst\"].fillna(0).astype(int)\n    df[\"has_prob\"] = df[\"has_prob\"].fillna(0).astype(int)\n    df[\"area_frac_tok\"] = df[\"area_frac_tok\"].fillna(0.0).astype(float)\n    df[\"area_frac\"] = df[\"area_frac\"].fillna(0.0).astype(float)\n    df[\"mean_prob_tok\"] = df[\"mean_prob_tok\"].fillna(0.0).astype(float)\n\n    cols = [\n        \"case_id\",\"uid_safe\",\"split\",\"y\",\"fold\",\n        \"n_inst\",\"area_frac\",\"area_frac_tok\",\"mean_prob_tok\",\n        \"best_peak_score\",\"has_match\",\"has_prob\",\n        \"match_exists\",\"prob_exists\",\"npz_path\"\n    ]\n    df = df[cols]\n    df.to_csv(out_csv, index=False)\n    return df\n\npred_train_csv = PRED_DIR / \"pred_features_train.csv\"\npred_test_csv  = PRED_DIR / \"pred_features_test.csv\"\n\n_ = export_features(df_pred_train, pred_train_csv)\n_ = export_features(df_pred_test, pred_test_csv)\n\nprint(\"SAVED:\")\nprint(\" -\", PRED_TRAIN_DIR)\nprint(\" -\", PRED_TEST_DIR)\nprint(\" -\", pred_train_csv)\nprint(\" -\", pred_test_csv)\n\ngc.collect()\ntry:\n    torch.cuda.empty_cache()\nexcept Exception:\n    pass\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Build Training Table (X, y, folds)","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE — Build Training Table (X, y, folds)  [ONE CELL]\n# - Input : pred_features_train.csv + train_manifest.parquet + folds.parquet\n# - Output: gate_train_table_<CFG_ID>.parquet  (+ feature_cols.json)\n#\n# REQUIRE globals:\n#   PRED_DIR (or PRED_FEATS_TRAIN), TRAIN_MANIFEST, FOLDS_PATH, GATE_OUT_DIR, GATE_CFG (+GATE_CFG_ID optional)\n# ============================================================\n\nimport json\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\n\n# ----------------------------\n# Paths\n# ----------------------------\nPRED_FEATS_TRAIN = Path(PRED_DIR) / \"pred_features_train.csv\"\nGATE_OUT_DIR = Path(GATE_OUT_DIR)\nGATE_OUT_DIR.mkdir(parents=True, exist_ok=True)\n\n# ----------------------------\n# Load\n# ----------------------------\ndf_feat  = pd.read_csv(PRED_FEATS_TRAIN)\ndf_man   = pd.read_parquet(TRAIN_MANIFEST)\ndf_folds = pd.read_parquet(FOLDS_PATH)\n\n# ----------------------------\n# Case id column normalize (supports uid_safe fallback)\n# ----------------------------\ncid_col_feat = \"case_id\" if \"case_id\" in df_feat.columns else \"uid_safe\"\ncid_col_man  = \"case_id\" if \"case_id\" in df_man.columns else \"uid\"\n\ndf_feat[cid_col_feat] = df_feat[cid_col_feat].astype(str)\ndf_man[cid_col_man]   = df_man[cid_col_man].astype(str)\ndf_folds[\"case_id\"]   = df_folds[\"case_id\"].astype(str)\n\n# ----------------------------\n# Build y from manifest if missing/NaN in features\n# ----------------------------\nif \"y\" not in df_feat.columns:\n    df_feat = df_feat.merge(df_man[[cid_col_man, \"label\"]].rename(columns={cid_col_man: cid_col_feat}),\n                            on=cid_col_feat, how=\"left\")\n    df_feat[\"y\"] = (df_feat[\"label\"].astype(str).str.lower() == \"forged\").astype(int)\n\ndf_feat[\"y\"] = pd.to_numeric(df_feat[\"y\"], errors=\"coerce\")\nmiss_y = int(df_feat[\"y\"].isna().sum())\nif miss_y > 0:\n    df_tmp = df_man[[cid_col_man, \"label\"]].rename(columns={cid_col_man: cid_col_feat})\n    df_feat = df_feat.drop(columns=[\"label\"], errors=\"ignore\").merge(df_tmp, on=cid_col_feat, how=\"left\")\n    df_feat[\"y\"] = df_feat[\"y\"].fillna((df_feat[\"label\"].astype(str).str.lower() == \"forged\").astype(int))\n\ndf_feat[\"y\"] = df_feat[\"y\"].astype(int)\n\n# ----------------------------\n# Attach folds\n# ----------------------------\ndf = df_feat.merge(df_folds[[\"case_id\",\"fold\"]].rename(columns={\"case_id\": cid_col_feat}),\n                   on=cid_col_feat, how=\"left\")\n\n# ----------------------------\n# Finalize columns\n# ----------------------------\ndf = df.rename(columns={cid_col_feat: \"case_id\"}).copy()\ndf[\"case_id\"] = df[\"case_id\"].astype(str)\ndf[\"fold\"] = df[\"fold\"].astype(int)\n\nDROP = {\"case_id\", \"uid_safe\", \"split\", \"label\", \"y\", \"fold\", \"npz_path\"}\nFEATURE_COLS = [c for c in df.columns if c not in DROP]\n\ndf[FEATURE_COLS] = df[FEATURE_COLS].replace([np.inf, -np.inf], np.nan)\n\n# ----------------------------\n# Report folds\n# ----------------------------\nfold_tab = df.groupby(\"fold\")[\"y\"].agg([\"count\", \"mean\"]).reset_index()\nfold_tab[\"forged%\"] = (100.0 * fold_tab[\"mean\"])\nfold_tab = fold_tab.drop(columns=[\"mean\"])\n\nprint(\"FEATURE_COLS:\", len(FEATURE_COLS))\nprint(fold_tab.to_string(index=False))\n\n# ----------------------------\n# Save\n# ----------------------------\nCFG_ID = GATE_CFG_ID if \"GATE_CFG_ID\" in globals() else \"gate\"\ntrain_tab_path = GATE_OUT_DIR / f\"gate_train_table_{CFG_ID}.parquet\"\nfeat_cols_path = GATE_OUT_DIR / \"feature_cols.json\"\n\ndf_gate_train = df[[\"case_id\",\"fold\",\"y\"] + FEATURE_COLS].copy()\ndf_gate_train.to_parquet(train_tab_path, index=False)\nfeat_cols_path.write_text(json.dumps(FEATURE_COLS, indent=2))\n\nprint(\"SAVED:\")\nprint(\" -\", train_tab_path)\nprint(\" -\", feat_cols_path)\n\ndisplay(df_gate_train.head(3))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Build & Export Test Feature Table","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE — Build & Export Test Feature Table  [ONE CELL]\n# - Input : pred_features_test.csv\n# - Output: gate_test_table_<CFG_ID>.parquet\n#\n# REQUIRE globals:\n#   PRED_DIR (or PRED_FEATS_TEST), GATE_OUT_DIR, feature_cols.json exists (from train table stage)\n# ============================================================\n\nimport json\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\n\n# ----------------------------\n# Paths\n# ----------------------------\nPRED_FEATS_TEST = Path(PRED_DIR) / \"pred_features_test.csv\"\nGATE_OUT_DIR = Path(GATE_OUT_DIR)\nGATE_OUT_DIR.mkdir(parents=True, exist_ok=True)\n\nCFG_ID = GATE_CFG_ID if \"GATE_CFG_ID\" in globals() else \"gate\"\ntest_tab_path = GATE_OUT_DIR / f\"gate_test_table_{CFG_ID}.parquet\"\nfeat_cols_path = GATE_OUT_DIR / \"feature_cols.json\"\n\n# ----------------------------\n# Load + normalize case_id column\n# ----------------------------\ndf_test_feat = pd.read_csv(PRED_FEATS_TEST)\n\ncid_col = \"case_id\" if \"case_id\" in df_test_feat.columns else \"uid_safe\"\ndf_test_feat[cid_col] = df_test_feat[cid_col].astype(str)\n\ndf_test_feat = df_test_feat.rename(columns={cid_col: \"case_id\"}).copy()\ndf_test_feat[\"case_id\"] = df_test_feat[\"case_id\"].astype(str)\n\n# ----------------------------\n# Ensure feature columns match training\n# ----------------------------\nFEATURE_COLS = json.loads(Path(feat_cols_path).read_text())\n\nfor c in FEATURE_COLS:\n    if c not in df_test_feat.columns:\n        df_test_feat[c] = 0.0\n\ndf_test_feat[FEATURE_COLS] = df_test_feat[FEATURE_COLS].replace([np.inf, -np.inf], np.nan).fillna(0.0)\n\ndf_gate_test = df_test_feat[[\"case_id\"] + FEATURE_COLS].copy()\n\n# ----------------------------\n# Save\n# ----------------------------\ndf_gate_test.to_parquet(test_tab_path, index=False)\n\nprint(\"df_gate_test:\", df_gate_test.shape)\nprint(\"SAVED:\", test_tab_path)\ndisplay(df_gate_test.head(3))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train Baseline Model (Leakage-Safe CV)","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE — Train Baseline Gate Model (Leakage-Safe CV)  [ONE CELL]\n# - Model: LightGBM (binary) + optional calibration (sigmoid/isotonic)\n# - CV    : use fold column from gate_train_table_*.parquet\n# - Output:\n#   - gate_oof_pred_<CFG_ID>.parquet\n#   - gate_cv_metrics_<CFG_ID>.json\n#   - gate_models_<CFG_ID>.pkl\n#   - gate_calibrators_<CFG_ID>.pkl (if enabled)\n# ============================================================\n\nimport json, pickle\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\n\nfrom sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.linear_model import LogisticRegression\n\n# LightGBM (baseline)\nimport lightgbm as lgb\n\n# ----------------------------\n# Paths\n# ----------------------------\nCFG_ID = GATE_CFG_ID if \"GATE_CFG_ID\" in globals() else \"gate\"\nGATE_OUT_DIR = Path(GATE_OUT_DIR)\ntrain_tab_path = GATE_OUT_DIR / f\"gate_train_table_{CFG_ID}.parquet\"\nfeat_cols_path = GATE_OUT_DIR / \"feature_cols.json\"\n\noof_path   = GATE_OUT_DIR / f\"gate_oof_pred_{CFG_ID}.parquet\"\nmetrics_p  = GATE_OUT_DIR / f\"gate_cv_metrics_{CFG_ID}.json\"\nmodels_p   = GATE_OUT_DIR / f\"gate_models_{CFG_ID}.pkl\"\ncalibs_p   = GATE_OUT_DIR / f\"gate_calibrators_{CFG_ID}.pkl\"\n\n# ----------------------------\n# Load\n# ----------------------------\ndf = pd.read_parquet(train_tab_path)\nFEATURE_COLS = json.loads(feat_cols_path.read_text())\n\nX = df[FEATURE_COLS].to_numpy(dtype=np.float32)\ny = df[\"y\"].to_numpy(dtype=np.int64)\nfolds = df[\"fold\"].to_numpy(dtype=np.int64)\n\nuniq_folds = sorted(np.unique(folds).tolist())\nprint(\"Train rows:\", len(df))\nprint(\"FEATURE_COLS:\", len(FEATURE_COLS))\nprint(\"Folds:\", uniq_folds)\n\n# ----------------------------\n# Train CV\n# ----------------------------\noof = np.zeros(len(df), dtype=np.float32)\nfold_metrics = {}\nmodels = {}\ncalibrators = {}\n\nuse_cal = bool(GATE_CFG.use_calibration)\ncal_method = str(GATE_CFG.calibration_method)\n\nfor f in uniq_folds:\n    tr_idx = np.where(folds != f)[0]\n    va_idx = np.where(folds == f)[0]\n\n    Xtr, ytr = X[tr_idx], y[tr_idx]\n    Xva, yva = X[va_idx], y[va_idx]\n\n    params = dict(GATE_CFG.lgbm_params or {})\n    params.setdefault(\"objective\", \"binary\")\n    params.setdefault(\"random_state\", int(GATE_CFG.seed))\n    params.setdefault(\"n_jobs\", -1)\n\n    clf = lgb.LGBMClassifier(**params)\n    clf.fit(Xtr, ytr)\n\n    # raw probs\n    p_va = clf.predict_proba(Xva)[:, 1].astype(np.float32)\n\n    # optional calibration (fit on train, apply to val)\n    if use_cal:\n        base = lgb.LGBMClassifier(**params)\n        cal = CalibratedClassifierCV(base, method=cal_method, cv=3)\n        cal.fit(Xtr, ytr)\n        p_va = cal.predict_proba(Xva)[:, 1].astype(np.float32)\n        calibrators[int(f)] = cal\n\n    oof[va_idx] = p_va\n    models[int(f)] = clf\n\n    auc = float(roc_auc_score(yva, p_va))\n    thr = 0.5\n    pred = (p_va >= thr).astype(int)\n    f1 = float(f1_score(yva, pred))\n    prec = float(precision_score(yva, pred, zero_division=0))\n    rec = float(recall_score(yva, pred, zero_division=0))\n\n    fold_metrics[int(f)] = {\"auc\": auc, \"f1@0.5\": f1, \"precision@0.5\": prec, \"recall@0.5\": rec}\n    print(f\"[fold {f}] AUC={auc:.5f} F1@0.5={f1:.5f} P={prec:.5f} R={rec:.5f}\")\n\n# ----------------------------\n# Save OOF + metrics\n# ----------------------------\ndf_oof = df[[\"case_id\", \"fold\", \"y\"]].copy()\ndf_oof[\"oof_prob\"] = oof\n\noof_auc = float(roc_auc_score(y, oof))\noof_pred = (oof >= 0.5).astype(int)\noof_f1 = float(f1_score(y, oof_pred))\n\nreport = {\n    \"cfg_id\": CFG_ID,\n    \"n_rows\": int(len(df)),\n    \"n_features\": int(len(FEATURE_COLS)),\n    \"oof_auc\": oof_auc,\n    \"oof_f1@0.5\": oof_f1,\n    \"fold_metrics\": fold_metrics,\n    \"calibration\": {\"enabled\": use_cal, \"method\": cal_method},\n}\n\ndf_oof.to_parquet(oof_path, index=False)\nmetrics_p.write_text(json.dumps(report, indent=2))\n\nwith open(models_p, \"wb\") as f:\n    pickle.dump(models, f)\n\nif use_cal:\n    with open(calibs_p, \"wb\") as f:\n        pickle.dump(calibrators, f)\n\nprint(\"SAVED:\")\nprint(\" -\", oof_path)\nprint(\" -\", metrics_p)\nprint(\" -\", models_p)\nif use_cal:\n    print(\" -\", calibs_p)\n\ndisplay(df_oof.head(5))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Optimize Model & Hyperparameters (Iterative)","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE — Optimize Model & Hyperparameters (Iterative) [ONE CELL]\n# - Optuna hyperopt for LightGBM (leakage-safe CV using provided folds)\n# - Objective: mean AUC across folds (fast + stable); stores best params for next stages\n#\n# REQUIRE globals:\n#   GATE_OUT_DIR, GATE_CFG (seed), GATE_CFG_ID\n#   gate_train_table_<CFG_ID>.parquet, feature_cols.json (from previous stage)\n# ============================================================\n\nimport json, pickle, math\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\n\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\n\n# ----------------------------\n# Settings\n# ----------------------------\nN_TRIALS = 40          # increase if you want stronger search\nNUM_BOOST_MAX = 6000   # upper bound for boosting rounds\nEARLY_STOP = 150\nSEED = int(getattr(GATE_CFG, \"seed\", 42))\n\nCFG_ID = GATE_CFG_ID if \"GATE_CFG_ID\" in globals() else \"gate\"\nGATE_OUT_DIR = Path(GATE_OUT_DIR)\ntrain_tab_path = GATE_OUT_DIR / f\"gate_train_table_{CFG_ID}.parquet\"\nfeat_cols_path = GATE_OUT_DIR / \"feature_cols.json\"\n\nstudy_path = GATE_OUT_DIR / f\"optuna_lgbm_study_{CFG_ID}.pkl\"\nbest_params_path = GATE_OUT_DIR / f\"best_lgbm_params_{CFG_ID}.json\"\ntrials_csv_path  = GATE_OUT_DIR / f\"optuna_trials_{CFG_ID}.csv\"\n\n# ----------------------------\n# Load data\n# ----------------------------\ndf = pd.read_parquet(train_tab_path)\nFEATURE_COLS = json.loads(feat_cols_path.read_text())\n\nX = df[FEATURE_COLS].to_numpy(dtype=np.float32)\ny = df[\"y\"].to_numpy(dtype=np.int64)\nfolds = df[\"fold\"].to_numpy(dtype=np.int64)\nuniq_folds = sorted(np.unique(folds).tolist())\n\nprint(\"rows:\", len(df), \"| features:\", len(FEATURE_COLS), \"| folds:\", uniq_folds)\n\n# ----------------------------\n# CV scorer\n# ----------------------------\ndef cv_auc_lgb(params: dict) -> float:\n    aucs = []\n    for f in uniq_folds:\n        tr_idx = np.where(folds != f)[0]\n        va_idx = np.where(folds == f)[0]\n\n        Xtr, ytr = X[tr_idx], y[tr_idx]\n        Xva, yva = X[va_idx], y[va_idx]\n\n        dtr = lgb.Dataset(Xtr, label=ytr, free_raw_data=False)\n        dva = lgb.Dataset(Xva, label=yva, reference=dtr, free_raw_data=False)\n\n        bst = lgb.train(\n            params=params,\n            train_set=dtr,\n            num_boost_round=int(params.get(\"num_boost_round\", 2000)),\n            valid_sets=[dva],\n            valid_names=[\"val\"],\n            callbacks=[lgb.early_stopping(EARLY_STOP, verbose=False)],\n        )\n        p = bst.predict(Xva, num_iteration=bst.best_iteration)\n        aucs.append(float(roc_auc_score(yva, p)))\n    return float(np.mean(aucs))\n\n# ----------------------------\n# Optuna (resume-able)\n# ----------------------------\nimport optuna\n\ntry:\n    with open(study_path, \"rb\") as f:\n        study = pickle.load(f)\n    print(\"Loaded existing study:\", study_path)\nexcept Exception:\n    study = optuna.create_study(direction=\"maximize\", study_name=f\"lgbm_gate_{CFG_ID}\")\n\ndef objective(trial: optuna.Trial) -> float:\n    params = {\n        \"objective\": \"binary\",\n        \"metric\": \"auc\",\n        \"verbosity\": -1,\n        \"seed\": SEED,\n        \"feature_pre_filter\": False,\n\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.08, log=True),\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 16, 256),\n        \"max_depth\": trial.suggest_int(\"max_depth\", -1, 12),\n        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 20, 300),\n        \"min_sum_hessian_in_leaf\": trial.suggest_float(\"min_sum_hessian_in_leaf\", 1e-3, 5.0, log=True),\n\n        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.55, 0.95),\n        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.55, 0.95),\n        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 0, 4),\n\n        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 0.0, 10.0),\n        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 0.0, 10.0),\n        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0.0, 2.0),\n\n        \"num_boost_round\": trial.suggest_int(\"num_boost_round\", 800, NUM_BOOST_MAX),\n    }\n\n    score = cv_auc_lgb(params)\n    return score\n\nstudy.optimize(objective, n_trials=N_TRIALS, show_progress_bar=True)\n\n# ----------------------------\n# Save artifacts\n# ----------------------------\nwith open(study_path, \"wb\") as f:\n    pickle.dump(study, f)\n\nbest = study.best_params.copy()\n\nBEST_LGBM_PARAMS = {\n    \"objective\": \"binary\",\n    \"metric\": \"auc\",\n    \"verbosity\": -1,\n    \"seed\": SEED,\n    \"feature_pre_filter\": False,\n    **best,\n}\n\nbest_params_path.write_text(json.dumps(\n    {\"best_value_auc\": float(study.best_value), \"best_params\": BEST_LGBM_PARAMS},\n    indent=2\n))\n\n# trials table\ntry:\n    tdf = study.trials_dataframe(attrs=(\"number\", \"value\", \"state\", \"params\"))\n    tdf.to_csv(trials_csv_path, index=False)\nexcept Exception:\n    pass\n\nprint(\"BEST AUC:\", float(study.best_value))\nprint(\"BEST_LGBM_PARAMS:\", json.dumps(BEST_LGBM_PARAMS, indent=2))\nprint(\"SAVED:\")\nprint(\" -\", study_path)\nprint(\" -\", best_params_path)\nprint(\" -\", trials_csv_path)\n\nBEST_LGBM_PARAMS\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Final Training (Train on Full Data)","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE — Final Training (Train on Full Data)  [ONE CELL]\n# - Train Gate model on ALL training rows using BEST params (from optuna json if exists)\n# - Optional calibration on full data (sigmoid / isotonic)\n# - Predict TEST probs\n# - Output:\n#   - gate_final_model_<CFG_ID>.pkl\n#   - gate_test_pred_<CFG_ID>.parquet\n#   - gate_final_bundle_<CFG_ID>.json (metadata)\n#\n# REQUIRE globals:\n#   GATE_OUT_DIR, GATE_CFG, GATE_CFG_ID\n#   gate_train_table_<CFG_ID>.parquet, gate_test_table_<CFG_ID>.parquet, feature_cols.json\n# ============================================================\n\nimport json, pickle\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\n\nimport lightgbm as lgb\nfrom sklearn.calibration import CalibratedClassifierCV\n\nCFG_ID = GATE_CFG_ID if \"GATE_CFG_ID\" in globals() else \"gate\"\nGATE_OUT_DIR = Path(GATE_OUT_DIR)\n\ntrain_tab_path = GATE_OUT_DIR / f\"gate_train_table_{CFG_ID}.parquet\"\ntest_tab_path  = GATE_OUT_DIR / f\"gate_test_table_{CFG_ID}.parquet\"\nfeat_cols_path = GATE_OUT_DIR / \"feature_cols.json\"\n\nbest_params_path = GATE_OUT_DIR / f\"best_lgbm_params_{CFG_ID}.json\"\n\nfinal_model_path = GATE_OUT_DIR / f\"gate_final_model_{CFG_ID}.pkl\"\ntest_pred_path   = GATE_OUT_DIR / f\"gate_test_pred_{CFG_ID}.parquet\"\nbundle_path      = GATE_OUT_DIR / f\"gate_final_bundle_{CFG_ID}.json\"\n\n# ----------------------------\n# Load tables\n# ----------------------------\ndf_tr = pd.read_parquet(train_tab_path)\ndf_te = pd.read_parquet(test_tab_path)\nFEATURE_COLS = json.loads(feat_cols_path.read_text())\n\nXtr = df_tr[FEATURE_COLS].to_numpy(dtype=np.float32)\nytr = df_tr[\"y\"].to_numpy(dtype=np.int64)\nXte = df_te[FEATURE_COLS].to_numpy(dtype=np.float32)\n\nprint(\"Train:\", Xtr.shape, \" Test:\", Xte.shape, \" Features:\", len(FEATURE_COLS))\n\n# ----------------------------\n# Params: prefer optuna best if exists, else fallback to GATE_CFG.lgbm_params\n# ----------------------------\ntry:\n    best_pack = json.loads(best_params_path.read_text())\n    params = dict(best_pack[\"best_params\"])\n    print(\"Using BEST params from:\", best_params_path.name)\nexcept Exception:\n    params = dict(GATE_CFG.lgbm_params or {})\n    params.setdefault(\"objective\", \"binary\")\n    print(\"Using fallback params from GATE_CFG.lgbm_params\")\n\nparams.setdefault(\"objective\", \"binary\")\nparams.setdefault(\"random_state\", int(getattr(GATE_CFG, \"seed\", 42)))\nparams.setdefault(\"n_jobs\", -1)\n\n# ----------------------------\n# Train full model\n# ----------------------------\nbase = lgb.LGBMClassifier(**params)\nbase.fit(Xtr, ytr)\n\n# ----------------------------\n# Optional calibration (fit on full data)\n# ----------------------------\nuse_cal = bool(getattr(GATE_CFG, \"use_calibration\", True))\ncal_method = str(getattr(GATE_CFG, \"calibration_method\", \"sigmoid\"))\n\nfinal_model = base\nif use_cal:\n    base2 = lgb.LGBMClassifier(**params)\n    cal = CalibratedClassifierCV(base2, method=cal_method, cv=5)\n    cal.fit(Xtr, ytr)\n    final_model = cal\n\n# ----------------------------\n# Predict test\n# ----------------------------\np_test = final_model.predict_proba(Xte)[:, 1].astype(np.float32)\n\ndf_out = df_te[[\"case_id\"]].copy()\ndf_out[\"prob_forged\"] = p_test\ndf_out.to_parquet(test_pred_path, index=False)\n\n# ----------------------------\n# Save model\n# ----------------------------\nwith open(final_model_path, \"wb\") as f:\n    pickle.dump({\"model\": final_model, \"feature_cols\": FEATURE_COLS, \"cfg_id\": CFG_ID}, f)\n\nbundle = {\n    \"cfg_id\": CFG_ID,\n    \"model_type\": \"lgbm_calibrated\" if use_cal else \"lgbm\",\n    \"calibration\": {\"enabled\": use_cal, \"method\": cal_method},\n    \"n_train\": int(len(df_tr)),\n    \"n_test\": int(len(df_te)),\n    \"n_features\": int(len(FEATURE_COLS)),\n    \"feature_cols_path\": str(feat_cols_path),\n    \"best_params_path\": str(best_params_path),\n    \"final_model_path\": str(final_model_path),\n    \"test_pred_path\": str(test_pred_path),\n}\nbundle_path.write_text(json.dumps(bundle, indent=2))\n\nprint(\"SAVED:\")\nprint(\" -\", final_model_path)\nprint(\" -\", test_pred_path)\nprint(\" -\", bundle_path)\ndisplay(df_out.head(5))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Finalize & Save Model Bundle (Reproducible)","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE — Finalize & Save Model Bundle (Reproducible)  [ONE CELL]\n# - Collects segmentation models + gate model + configs + feature cols into one portable ZIP\n# - Output folder:\n#   /kaggle/working/recodai_luc_artifacts_bundle/<BUNDLE_NAME>/\n#   + <BUNDLE_NAME>.zip\n#\n# REQUIRE globals:\n#   SEG_RUN_DIR, SEG_CFG, SEG_CFG_ID\n#   GATE_OUT_DIR, GATE_CFG, GATE_CFG_ID\n# ============================================================\n\nimport os, json, time, zipfile, hashlib, platform\nfrom pathlib import Path\nfrom dataclasses import asdict\n\n# ----------------------------\n# Output root\n# ----------------------------\nBUNDLE_NAME = f\"recodai_luc_bundle_seg{SEG_CFG_ID}_gate{GATE_CFG_ID}\"\nOUT_ROOT = Path(\"/kaggle/working/recodai_luc_artifacts_bundle\") / BUNDLE_NAME\nOUT_ROOT.mkdir(parents=True, exist_ok=True)\n\n# ----------------------------\n# Files to include\n# ----------------------------\nseg_ckpts = sorted(Path(SEG_RUN_DIR).glob(\"seg_unet_aspp_fold*.pt\"))\nseg_hist  = Path(SEG_RUN_DIR) / \"seg_cv_history.json\"\n\ngate_files = [\n    Path(GATE_OUT_DIR) / f\"feature_cols.json\",\n    Path(GATE_OUT_DIR) / f\"best_lgbm_params_{GATE_CFG_ID}.json\",\n    Path(GATE_OUT_DIR) / f\"gate_final_model_{GATE_CFG_ID}.pkl\",\n    Path(GATE_OUT_DIR) / f\"gate_final_bundle_{GATE_CFG_ID}.json\",\n]\n\n# optional (not fatal if missing): oof, test pred, optuna study\nopt_files = [\n    Path(GATE_OUT_DIR) / f\"gate_oof_pred_{GATE_CFG_ID}.parquet\",\n    Path(GATE_OUT_DIR) / f\"gate_test_pred_{GATE_CFG_ID}.parquet\",\n    Path(GATE_OUT_DIR) / f\"optuna_lgbm_study_{GATE_CFG_ID}.pkl\",\n    Path(GATE_OUT_DIR) / f\"optuna_trials_{GATE_CFG_ID}.csv\",\n]\n\n# ----------------------------\n# Save metadata\n# ----------------------------\nmeta = {\n    \"bundle_name\": BUNDLE_NAME,\n    \"created_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n    \"platform\": {\"python\": platform.python_version(), \"system\": platform.platform()},\n    \"seg\": {\"seg_run_dir\": str(SEG_RUN_DIR), \"seg_cfg_id\": SEG_CFG_ID, \"seg_cfg\": asdict(SEG_CFG)},\n    \"gate\": {\"gate_out_dir\": str(GATE_OUT_DIR), \"gate_cfg_id\": GATE_CFG_ID, \"gate_cfg\": asdict(GATE_CFG)},\n}\n\nmeta_path = OUT_ROOT / \"bundle_meta.json\"\nmeta_path.write_text(json.dumps(meta, indent=2))\n\n# ----------------------------\n# Copy artifacts into OUT_ROOT (no if/else; copy only existing via try/except)\n# ----------------------------\ndef copy_into(src: Path, dst_dir: Path):\n    dst = dst_dir / src.name\n    dst.write_bytes(src.read_bytes())\n    return dst\n\ncopied = []\n\nfor p in seg_ckpts:\n    copied.append(str(copy_into(p, OUT_ROOT)))\ncopied.append(str(copy_into(seg_hist, OUT_ROOT)))\nfor p in gate_files + opt_files:\n    try:\n        copied.append(str(copy_into(p, OUT_ROOT)))\n    except Exception:\n        pass\n\n# ----------------------------\n# Checksums\n# ----------------------------\ndef md5_file(p: Path) -> str:\n    h = hashlib.md5()\n    with p.open(\"rb\") as f:\n        for chunk in iter(lambda: f.read(1024 * 1024), b\"\"):\n            h.update(chunk)\n    return h.hexdigest()\n\ncksum = {Path(p).name: md5_file(Path(p)) for p in copied if Path(p).exists()}\n(OUT_ROOT / \"checksums_md5.json\").write_text(json.dumps(cksum, indent=2))\n\n# ----------------------------\n# Zip bundle\n# ----------------------------\nzip_path = OUT_ROOT.parent / f\"{BUNDLE_NAME}.zip\"\nwith zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as z:\n    for p in sorted(OUT_ROOT.rglob(\"*\")):\n        z.write(p, arcname=str(p.relative_to(OUT_ROOT.parent)))\n\nprint(\"BUNDLE_DIR:\", OUT_ROOT)\nprint(\"ZIP       :\", zip_path)\nprint(\"FILES COPIED:\", len(copied))\nprint(\"Seg ckpts:\", len(seg_ckpts))\nprint(\"SAVED:\")\nprint(\" -\", meta_path)\nprint(\" -\", OUT_ROOT / \"checksums_md5.json\")\nprint(\" -\", zip_path)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}