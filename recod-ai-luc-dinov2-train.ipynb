{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":113558,"databundleVersionId":14878066,"sourceType":"competition"},{"sourceId":477526,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":384037,"modelId":403416}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train & Save: Gate Model + Calibration + Thresholds","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 5 — DINOv2 Multi-Task (Classification + Segmentation) (ONE CELL, REVISI FULL v5)\n# - Replace tabular gate with real DINOv2 training (multi-task)\n# - Patch-grid segmentation (stable, fast) + classification head\n# - CV OOF + calibration + threshold tuning (thr_forged, thr_mask, min_pred_patches)\n# - Save ONLY trainable weights (heads + last N blocks) to keep checkpoint small\n#\n# Outputs:\n# - /kaggle/working/recodai_luc/models/dinov2_mt_v5_*/checkpoints/fold_*.pt\n# - model_config.json, thresholds.json, calibrator.joblib, oof_predictions.csv, report.json\n# ============================================================\n\nimport os, json, time, math, ast, hashlib, random, gc\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image, ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n\nfrom transformers import AutoModel\nimport joblib\nfrom sklearn.metrics import roc_auc_score, average_precision_score\nfrom sklearn.isotonic import IsotonicRegression\nfrom sklearn.linear_model import LogisticRegression\n\n# ----------------------------\n# REQUIRE\n# ----------------------------\nif \"df_train_all\" not in globals():\n    raise RuntimeError(\"Missing df_train_all. Jalankan STAGE 1 dulu.\")\ndf_train_all = df_train_all.copy()\n\nneed_cols = {\"sample_id\",\"case_id\",\"variant\",\"fold\",\"y_forged\",\"mask_paths\",\"image_path\"}\nmiss = need_cols - set(df_train_all.columns)\nif miss:\n    raise RuntimeError(f\"df_train_all missing columns: {miss}\")\n\n# ----------------------------\n# ID normalization (same idea as STAGE 4)\n# ----------------------------\ndef _norm_one_id(x):\n    if x is None or (isinstance(x, float) and np.isnan(x)):\n        return \"\"\n    if isinstance(x, (np.integer, int)):\n        return str(int(x))\n    if isinstance(x, (np.floating, float)):\n        if np.isfinite(x) and abs(x - round(x)) < 1e-9:\n            return str(int(round(x)))\n        return str(float(x))\n    s = str(x)\n    if s.endswith(\".0\"):\n        head = s[:-2]\n        if head.isdigit():\n            return head\n    return s\n\ndef norm_id_series(s: pd.Series) -> pd.Series:\n    return s.map(_norm_one_id)\n\nfor c in [\"sample_id\",\"case_id\"]:\n    df_train_all[c] = norm_id_series(df_train_all[c])\n\ndf_train_all[\"variant\"]  = df_train_all[\"variant\"].astype(str)\ndf_train_all[\"fold\"]     = df_train_all[\"fold\"].astype(int)\ndf_train_all[\"y_forged\"] = df_train_all[\"y_forged\"].astype(int)\ndf_train_all[\"image_path\"] = df_train_all[\"image_path\"].astype(str)\n\n# keep only fold >=0 (train CV)\ndf_train_all = df_train_all[df_train_all[\"fold\"] >= 0].reset_index(drop=True)\nif len(df_train_all) == 0:\n    raise RuntimeError(\"Tidak ada data train dengan fold>=0.\")\n\n# ----------------------------\n# CONFIG (tuning-ready)\n# ----------------------------\nCFG = {\n    # DINO dir (from STAGE 1/2)\n    \"dino_dir\": str(globals().get(\"DINO_BASE_DIR\", \"/kaggle/input/dinov2/pytorch/base/1\")),\n\n    # image / patch grid\n    \"img_size\": 560,           # MUST be multiple of patch_size\n    \"patch_size\": 14,\n    \"use_center_crop_val\": True,\n\n    # training\n    \"seed\": 2025,\n    \"epochs\": 5,\n    \"batch_size\": 4,\n    \"num_workers\": 2,\n    \"amp\": True,\n    \"grad_accum\": 1,\n    \"clip_grad\": 1.0,\n\n    # finetune policy\n    \"unfreeze_last_n_blocks\": 2,   # 0 => linear probe (heads only)\n    \"use_grad_ckpt\": False,\n\n    # optimizer\n    \"lr_backbone\": 3e-5,\n    \"lr_heads\": 3e-4,\n    \"weight_decay\": 0.05,\n\n    # losses\n    \"w_cls\": 1.0,\n    \"w_seg_bce\": 1.0,\n    \"w_seg_dice\": 1.0,\n    \"dice_eps\": 1e-6,\n\n    # augmentation (light, scientific-friendly)\n    \"aug_hflip_p\": 0.5,\n    \"aug_vflip_p\": 0.1,\n    \"aug_rot90_p\": 0.15,         # rotate by 0/90/180/270\n    \"aug_brightness\": 0.10,\n    \"aug_contrast\": 0.10,\n\n    # early stopping\n    \"patience\": 2,\n\n    # output\n    \"out_root\": \"/kaggle/working/recodai_luc/models\",\n    \"gt_cache_root\": \"/kaggle/working/recodai_luc/cache/gt_grid_union\",\n    \"print_every\": 200,\n}\n\nIMG_SIZE = int(CFG[\"img_size\"])\nPATCH    = int(CFG[\"patch_size\"])\nassert IMG_SIZE % PATCH == 0, f\"img_size harus kelipatan patch_size. Got {IMG_SIZE} vs {PATCH}\"\nGH = IMG_SIZE // PATCH\nGW = IMG_SIZE // PATCH\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# threads (CPU side)\ntry:\n    torch.set_num_threads(max(1, (os.cpu_count() or 2)//2))\nexcept Exception:\n    pass\n\n# seed\ndef seed_everything(seed=2025):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\nseed_everything(CFG[\"seed\"])\n\n# imagenet norm (DINOv2 typical)\nIMNET_MEAN = torch.tensor([0.485, 0.456, 0.406], dtype=torch.float32).view(3,1,1)\nIMNET_STD  = torch.tensor([0.229, 0.224, 0.225], dtype=torch.float32).view(3,1,1)\n\n# popcount LUT (for packed bits)\nPOPCNT = np.array([bin(i).count(\"1\") for i in range(256)], dtype=np.uint8)\n\n# ----------------------------\n# Mask path parsing + loader (robust)\n# ----------------------------\ndef parse_mask_paths(val):\n    if val is None or (isinstance(val, float) and np.isnan(val)):\n        return []\n    if isinstance(val, (list, tuple)):\n        return [str(x) for x in val if str(x)]\n    if isinstance(val, np.ndarray):\n        try:\n            return [str(x) for x in val.reshape(-1).tolist() if str(x)]\n        except Exception:\n            return []\n    if isinstance(val, str):\n        s = val.strip()\n        if s == \"\" or s.lower() in (\"nan\",\"none\",\"null\"):\n            return []\n        if (s.startswith(\"[\") and s.endswith(\"]\")) or (s.startswith(\"(\") and s.endswith(\")\")):\n            try:\n                out = json.loads(s)\n                if isinstance(out, (list, tuple)):\n                    return [str(x) for x in out if str(x)]\n            except Exception:\n                pass\n            try:\n                out = ast.literal_eval(s)\n                if isinstance(out, (list, tuple)):\n                    return [str(x) for x in out if str(x)]\n            except Exception:\n                pass\n        return [s]\n    return []\n\ndef load_mask_any_as_bool(path: str, target_h: int, target_w: int):\n    p = Path(str(path))\n    if not p.exists():\n        return None\n    suf = p.suffix.lower()\n\n    if suf in (\".png\",\".jpg\",\".jpeg\",\".bmp\",\".tif\",\".tiff\",\".webp\"):\n        im = Image.open(p).convert(\"L\")\n        if im.size != (target_w, target_h):\n            im = im.resize((target_w, target_h), resample=Image.NEAREST)\n        return (np.array(im) > 0)\n\n    if suf == \".npz\":\n        z = np.load(p, allow_pickle=False)\n        if (\"mask_pack\" in z.files) and (\"mask_h\" in z.files) and (\"mask_w\" in z.files):\n            mh = int(z[\"mask_h\"]); mw = int(z[\"mask_w\"])\n            pack = z[\"mask_pack\"].astype(np.uint8).reshape(-1)\n            bits = np.unpackbits(pack, axis=None)[: mh*mw].reshape(mh, mw).astype(bool)\n            if (mh, mw) != (target_h, target_w):\n                im = Image.fromarray((bits.astype(np.uint8)*255)).resize((target_w, target_h), resample=Image.NEAREST)\n                return (np.array(im) > 0)\n            return bits\n        return None\n\n    # npy / others\n    try:\n        arr = np.load(p, allow_pickle=False)\n    except Exception:\n        arr = np.load(p, allow_pickle=True)\n        if np.ndim(arr) == 0 and hasattr(arr, \"item\"):\n            arr = arr.item()\n\n    a = np.asarray(arr)\n    a = np.squeeze(a)\n    if a.ndim == 2:\n        m = (a > 0)\n        if m.shape != (target_h, target_w):\n            im = Image.fromarray((m.astype(np.uint8)*255)).resize((target_w, target_h), resample=Image.NEAREST)\n            m = (np.array(im) > 0)\n        return m.astype(bool)\n\n    if a.ndim == 3:\n        # take max across channels\n        m = (a.max(axis=-1) > 0)\n        if m.shape != (target_h, target_w):\n            im = Image.fromarray((m.astype(np.uint8)*255)).resize((target_w, target_h), resample=Image.NEAREST)\n            m = (np.array(im) > 0)\n        return m.astype(bool)\n\n    return None\n\n# ----------------------------\n# GT cache: store union mask on PATCH GRID (GH x GW) packed bits\n# - super small files, super fast training\n# ----------------------------\nGT_CACHE_ROOT = Path(CFG[\"gt_cache_root\"]) / f\"sz{IMG_SIZE}_p{PATCH}\"\nGT_CACHE_ROOT.mkdir(parents=True, exist_ok=True)\n\ndef mask_to_grid(mask_bool_hw: np.ndarray, gh: int, gw: int, patch: int) -> np.ndarray:\n    # mask_bool_hw: (H,W) where H=W=IMG_SIZE\n    H, W = mask_bool_hw.shape\n    assert H == gh*patch and W == gw*patch\n    x = mask_bool_hw.reshape(gh, patch, gw, patch)\n    g = x.max(axis=(1,3))  # (gh,gw) bool\n    return g\n\ndef pack_grid_bool(grid_bool: np.ndarray) -> np.ndarray:\n    flat = grid_bool.astype(np.uint8).reshape(-1)\n    return np.packbits(flat, axis=None).astype(np.uint8)\n\ndef unpack_grid_pack(pack_u8: np.ndarray, gh: int, gw: int) -> np.ndarray:\n    bits = np.unpackbits(pack_u8.reshape(-1).astype(np.uint8), axis=None)[: gh*gw]\n    return bits.reshape(gh, gw).astype(np.uint8)\n\ndef build_gt_cache_for_row(sample_id: str, y_forged: int, mask_paths_val):\n    outp = GT_CACHE_ROOT / f\"{sample_id}.npz\"\n    if outp.exists():\n        return True\n\n    # authentic => empty\n    if int(y_forged) == 0:\n        pack = pack_grid_bool(np.zeros((GH, GW), dtype=bool))\n        np.savez_compressed(str(outp),\n                            grid_pack=pack,\n                            gh=np.int16(GH), gw=np.int16(GW),\n                            pos=np.int32(0),\n                            empty=np.int8(1))\n        return True\n\n    paths = parse_mask_paths(mask_paths_val)\n    if len(paths) == 0:\n        pack = pack_grid_bool(np.zeros((GH, GW), dtype=bool))\n        np.savez_compressed(str(outp),\n                            grid_pack=pack,\n                            gh=np.int16(GH), gw=np.int16(GW),\n                            pos=np.int32(0),\n                            empty=np.int8(1))\n        return True\n\n    union = np.zeros((IMG_SIZE, IMG_SIZE), dtype=bool)\n    for p in paths:\n        m = load_mask_any_as_bool(p, IMG_SIZE, IMG_SIZE)\n        if m is None:\n            continue\n        union |= m\n\n    grid = mask_to_grid(union, GH, GW, PATCH)\n    pos = int(grid.sum())\n    pack = pack_grid_bool(grid)\n\n    np.savez_compressed(str(outp),\n                        grid_pack=pack,\n                        gh=np.int16(GH), gw=np.int16(GW),\n                        pos=np.int32(pos),\n                        empty=np.int8(1 if pos == 0 else 0))\n    return True\n\nprint(\"\\n[GT CACHE] Building missing GT grid cache files (only if absent) ...\")\nt0 = time.time()\nbuilt = 0\nfail = 0\nfor i, r in enumerate(df_train_all.itertuples(index=False), start=1):\n    sid = getattr(r, \"sample_id\")\n    yfg = getattr(r, \"y_forged\")\n    mpv = getattr(r, \"mask_paths\")\n    try:\n        ok = build_gt_cache_for_row(str(sid), int(yfg), mpv)\n        built += 1 if ok else 0\n    except Exception:\n        fail += 1\n    if (i % CFG[\"print_every\"]) == 0:\n        print(f\"[GT CACHE] {i:,}/{len(df_train_all):,} processed | fail={fail:,}\")\ndt = time.time() - t0\nprint(f\"[GT CACHE] Done. processed={built:,} fail={fail:,} elapsed_s={dt:.1f} | dir={GT_CACHE_ROOT}\")\n\n# ----------------------------\n# Dataset\n# ----------------------------\ndef pil_load_rgb(path: str):\n    p = Path(path)\n    if not p.exists():\n        return None\n    try:\n        return Image.open(p).convert(\"RGB\")\n    except Exception:\n        return None\n\ndef pil_resize_sq(img: Image.Image, size: int):\n    # keep it simple: resize to square (scientific images often ok)\n    return img.resize((size, size), resample=Image.BICUBIC)\n\ndef img_to_tensor_norm(img: Image.Image):\n    arr = np.array(img, dtype=np.float32) / 255.0  # HWC\n    t = torch.from_numpy(arr).permute(2,0,1).contiguous()  # CHW\n    t = (t - IMNET_MEAN) / IMNET_STD\n    return t\n\ndef apply_aug(image_t: torch.Tensor, grid_u8: torch.Tensor, cfg: dict):\n    # image_t: [3,H,W], grid_u8: [GH,GW]\n    # flips/rot90 on both; color jitter only on image\n    if random.random() < float(cfg[\"aug_hflip_p\"]):\n        image_t = torch.flip(image_t, dims=[2])\n        grid_u8 = torch.flip(grid_u8, dims=[1])\n    if random.random() < float(cfg[\"aug_vflip_p\"]):\n        image_t = torch.flip(image_t, dims=[1])\n        grid_u8 = torch.flip(grid_u8, dims=[0])\n\n    if random.random() < float(cfg[\"aug_rot90_p\"]):\n        k = random.randint(0, 3)\n        if k > 0:\n            image_t = torch.rot90(image_t, k=k, dims=[1,2])\n            grid_u8 = torch.rot90(grid_u8, k=k, dims=[0,1])\n\n    # light brightness/contrast\n    b = float(cfg[\"aug_brightness\"])\n    c = float(cfg[\"aug_contrast\"])\n    if (b > 0) or (c > 0):\n        # brightness: multiply\n        if b > 0 and random.random() < 0.5:\n            factor = 1.0 + random.uniform(-b, b)\n            image_t = torch.clamp(image_t * factor, -5.0, 5.0)\n        # contrast: scale deviation from mean\n        if c > 0 and random.random() < 0.5:\n            mean = image_t.mean(dim=(1,2), keepdim=True)\n            factor = 1.0 + random.uniform(-c, c)\n            image_t = torch.clamp((image_t - mean) * factor + mean, -5.0, 5.0)\n\n    return image_t, grid_u8\n\nclass DinoMTDataset(Dataset):\n    def __init__(self, df: pd.DataFrame, train: bool):\n        self.df = df.reset_index(drop=True)\n        self.train = bool(train)\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        r = self.df.iloc[idx]\n        sid = str(r[\"sample_id\"])\n        yfg = int(r[\"y_forged\"])\n        ip  = str(r[\"image_path\"])\n\n        img = pil_load_rgb(ip)\n        if img is None:\n            # fallback blank\n            img = Image.fromarray(np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8))\n        img = pil_resize_sq(img, IMG_SIZE)\n        x = img_to_tensor_norm(img)  # [3,IMG,IMG]\n\n        gt_path = GT_CACHE_ROOT / f\"{sid}.npz\"\n        if gt_path.exists():\n            z = np.load(gt_path, allow_pickle=False)\n            pack = z[\"grid_pack\"].astype(np.uint8).reshape(-1)\n            grid = unpack_grid_pack(pack, GH, GW)  # uint8 0/1\n        else:\n            grid = np.zeros((GH, GW), dtype=np.uint8)\n\n        g = torch.from_numpy(grid).to(torch.uint8)  # [GH,GW]\n\n        if self.train:\n            x, g = apply_aug(x, g, CFG)\n\n        # label float\n        y = torch.tensor([float(yfg)], dtype=torch.float32)\n\n        # seg target float (0/1)\n        g = g.to(torch.float32)\n\n        return x, g, y, sid\n\n# ----------------------------\n# Build DINOv2 multitask model\n# ----------------------------\ndef find_encoder_layers(model):\n    # try common structures\n    if hasattr(model, \"encoder\") and hasattr(model.encoder, \"layer\"):\n        return model.encoder.layer\n    if hasattr(model, \"vit\") and hasattr(model.vit, \"encoder\") and hasattr(model.vit.encoder, \"layer\"):\n        return model.vit.encoder.layer\n    if hasattr(model, \"backbone\") and hasattr(model.backbone, \"encoder\") and hasattr(model.backbone.encoder, \"layer\"):\n        return model.backbone.encoder.layer\n    return None\n\ndef infer_num_layers_from_names(model):\n    # fallback by scanning parameter names like \"...encoder.layer.11....\"\n    ids = set()\n    for n, _ in model.named_parameters():\n        if \".layer.\" in n:\n            try:\n                t = n.split(\".layer.\")[1]\n                i = int(t.split(\".\")[0])\n                ids.add(i)\n            except Exception:\n                pass\n    return (max(ids)+1) if ids else 0\n\ndef freeze_all(model):\n    for p in model.parameters():\n        p.requires_grad = False\n\ndef unfreeze_last_n_blocks(model, n_last: int):\n    if n_last <= 0:\n        return 0\n\n    layers = find_encoder_layers(model)\n    if layers is not None:\n        L = len(layers)\n        n_last = min(int(n_last), L)\n        for i in range(L - n_last, L):\n            for p in layers[i].parameters():\n                p.requires_grad = True\n        return n_last\n\n    # fallback: infer number of layers from names\n    L = infer_num_layers_from_names(model)\n    if L <= 0:\n        return 0\n    n_last = min(int(n_last), L)\n    allow = set(range(L - n_last, L))\n    for name, p in model.named_parameters():\n        if \".layer.\" in name:\n            try:\n                i = int(name.split(\".layer.\")[1].split(\".\")[0])\n                if i in allow:\n                    p.requires_grad = True\n            except Exception:\n                pass\n    return n_last\n\nclass DinoMultiTask(nn.Module):\n    def __init__(self, backbone: nn.Module, gh: int, gw: int):\n        super().__init__()\n        self.backbone = backbone\n        self.gh = int(gh)\n        self.gw = int(gw)\n\n        # infer embed dim\n        with torch.no_grad():\n            dummy = torch.zeros((1,3,IMG_SIZE,IMG_SIZE), dtype=torch.float32)\n            out = self.backbone(pixel_values=dummy)\n            D = int(out.last_hidden_state.shape[-1])\n\n        self.embed_dim = D\n\n        # heads\n        self.cls_head = nn.Sequential(\n            nn.LayerNorm(D),\n            nn.Linear(D, 1)\n        )\n        self.seg_head = nn.Sequential(\n            nn.LayerNorm(D),\n            nn.Linear(D, 1)  # per patch\n        )\n\n    def forward(self, x):\n        out = self.backbone(pixel_values=x)\n        h = out.last_hidden_state  # [B, 1+N, D]\n        cls_tok = h[:, 0, :]       # [B,D]\n        ptok    = h[:, 1:, :]      # [B,N,D]\n\n        cls_logit = self.cls_head(cls_tok).squeeze(-1)  # [B]\n\n        # patch logits -> grid\n        seg_patch = self.seg_head(ptok).squeeze(-1)     # [B,N]\n        B, N = seg_patch.shape\n        # expect N == gh*gw, but be robust\n        if N != self.gh * self.gw:\n            # try to infer grid close to square\n            side = int(round(math.sqrt(N)))\n            gh = max(1, side)\n            gw = max(1, N // gh)\n            gh = max(1, N // gw)\n            seg_grid = seg_patch[:, :gh*gw].reshape(B, gh, gw)\n        else:\n            seg_grid = seg_patch.reshape(B, self.gh, self.gw)\n\n        return cls_logit, seg_grid\n\ndef bce_with_pos_weight(logits, targets, pos_weight: float):\n    pw = torch.tensor([pos_weight], device=logits.device, dtype=logits.dtype)\n    return F.binary_cross_entropy_with_logits(logits, targets, pos_weight=pw)\n\ndef dice_loss_from_logits(seg_logits, seg_targets, eps=1e-6):\n    # seg_logits: [B,GH,GW], seg_targets: [B,GH,GW] (0/1)\n    p = torch.sigmoid(seg_logits)\n    t = seg_targets\n    # flatten\n    p = p.reshape(p.size(0), -1)\n    t = t.reshape(t.size(0), -1)\n    inter = (p * t).sum(dim=1)\n    den = p.sum(dim=1) + t.sum(dim=1)\n    dice = (2.0 * inter + eps) / (den + eps)\n    return (1.0 - dice).mean()\n\ndef get_trainable_state_dict(model: nn.Module):\n    sd = model.state_dict()\n    trainable = {}\n    # save params that are trainable OR belong to heads\n    trainable_prefix = (\"cls_head.\", \"seg_head.\")\n    for n, p in model.named_parameters():\n        if p.requires_grad or n.startswith(trainable_prefix):\n            trainable[n] = sd[n].detach().half().cpu()\n    # also include LN running buffers if any inside heads (usually none)\n    for n, b in model.named_buffers():\n        if n.startswith(trainable_prefix):\n            trainable[n] = b.detach().half().cpu() if torch.is_floating_point(b) else b.detach().cpu()\n    return trainable\n\n# ----------------------------\n# Prepare data splits + weights\n# ----------------------------\nfolds_all = df_train_all[\"fold\"].values.astype(int)\nunique_folds = sorted(np.unique(folds_all).tolist())\n\ny_all = df_train_all[\"y_forged\"].values.astype(int)\npos = float((y_all == 1).sum()); neg = float((y_all == 0).sum())\npos_weight_cls = (neg / max(pos, 1.0)) if (pos > 0 and neg > 0) else 1.0\n\n# seg pos_weight: estimate from cached GT grids\n# (neg_pixels / pos_pixels) on grid space\nprint(\"\\n[SEG POS WEIGHT] Estimating from cached GT grids ...\")\npos_pix = 0\ntot_pix = 0\nfor sid in df_train_all[\"sample_id\"].tolist():\n    p = GT_CACHE_ROOT / f\"{sid}.npz\"\n    if not p.exists():\n        continue\n    z = np.load(p, allow_pickle=False)\n    pack = z[\"grid_pack\"].astype(np.uint8).reshape(-1)\n    cnt = int(POPCNT[pack].sum())\n    pos_pix += cnt\n    tot_pix += (GH * GW)\nneg_pix = max(0, tot_pix - pos_pix)\npos_weight_seg = (neg_pix / max(pos_pix, 1)) if pos_pix > 0 else 1.0\npos_weight_seg = float(np.clip(pos_weight_seg, 1.0, 50.0))  # clamp to avoid extreme\nprint(f\"[SEG POS WEIGHT] pos_pix={pos_pix:,} tot_pix={tot_pix:,} => pos_weight_seg={pos_weight_seg:.3f}\")\n\n# sampler weights (balance class)\nw_pos = (pos + neg) / (2.0 * max(pos, 1.0))\nw_neg = (pos + neg) / (2.0 * max(neg, 1.0))\nsample_w = np.where(y_all == 1, w_pos, w_neg).astype(np.float32)\n\n# ----------------------------\n# Training / Eval helpers\n# ----------------------------\n@torch.no_grad()\ndef evaluate(model, loader):\n    model.eval()\n    all_sid = []\n    all_y = []\n    all_p = []\n    all_seg = []\n    all_gt = []\n\n    for x, g, y, sid in loader:\n        x = x.to(device, non_blocking=True)\n        g = g.to(device, non_blocking=True)  # [B,GH,GW]\n        y = y.to(device, non_blocking=True).view(-1)  # [B]\n\n        cls_logit, seg_logit = model(x)  # seg_logit [B,GH,GW] (or inferred)\n        p = torch.sigmoid(cls_logit).detach().cpu().numpy().astype(np.float32)\n\n        seg_p = torch.sigmoid(seg_logit).detach().cpu().numpy().astype(np.float16)\n\n        all_sid.extend(list(sid))\n        all_y.append(y.detach().cpu().numpy().astype(np.int8))\n        all_p.append(p)\n        all_seg.append(seg_p)\n        all_gt.append(g.detach().cpu().numpy().astype(np.uint8))\n\n    all_y = np.concatenate(all_y, axis=0)\n    all_p = np.concatenate(all_p, axis=0)\n    all_seg = np.concatenate(all_seg, axis=0)  # [N,gh,gw]\n    all_gt = np.concatenate(all_gt, axis=0)    # [N,gh,gw] uint8\n\n    # metrics\n    if np.unique(all_y).size >= 2:\n        auc = float(roc_auc_score(all_y, all_p))\n        ap  = float(average_precision_score(all_y, all_p))\n    else:\n        auc = float(\"nan\")\n        ap  = float(\"nan\")\n\n    # dice at default thr=0.5 (for monitoring)\n    thr = 0.5\n    pred = (all_seg >= thr).astype(np.uint8)\n    gt = (all_gt > 0).astype(np.uint8)\n\n    ps = pred.reshape(len(pred), -1).sum(axis=1).astype(np.float32)\n    gs = gt.reshape(len(gt), -1).sum(axis=1).astype(np.float32)\n    inter = (pred & gt).reshape(len(pred), -1).sum(axis=1).astype(np.float32)\n\n    dice = np.zeros(len(pred), dtype=np.float32)\n    both0 = (ps == 0) & (gs == 0)\n    dice[both0] = 1.0\n    m = ~both0\n    dice[m] = (2.0*inter[m]) / (ps[m] + gs[m] + 1e-6)\n\n    # focus dice on forged (more meaningful)\n    forged = (all_y == 1)\n    dice_forg = float(dice[forged].mean()) if forged.any() else 0.0\n\n    # combined score for checkpointing\n    # (favor classification, but keep seg quality)\n    score = float((0.65 * (auc if np.isfinite(auc) else 0.0)) + (0.35 * dice_forg))\n\n    return {\n        \"sid\": all_sid,\n        \"y\": all_y,\n        \"p_cls\": all_p,\n        \"seg_prob\": all_seg,   # float16\n        \"gt_grid\": all_gt,     # uint8\n        \"auc\": auc,\n        \"ap\": ap,\n        \"dice_forg@0.5\": dice_forg,\n        \"score\": score,\n    }\n\ndef build_optimizer(model: nn.Module):\n    # param groups: heads (higher lr), trainable backbone (lower lr)\n    head_params = []\n    bb_params = []\n    for n, p in model.named_parameters():\n        if not p.requires_grad:\n            continue\n        if n.startswith(\"cls_head.\") or n.startswith(\"seg_head.\"):\n            head_params.append(p)\n        else:\n            bb_params.append(p)\n\n    groups = []\n    if bb_params:\n        groups.append({\"params\": bb_params, \"lr\": float(CFG[\"lr_backbone\"]), \"weight_decay\": float(CFG[\"weight_decay\"])})\n    if head_params:\n        groups.append({\"params\": head_params, \"lr\": float(CFG[\"lr_heads\"]), \"weight_decay\": float(CFG[\"weight_decay\"])})\n\n    opt = torch.optim.AdamW(groups)\n    return opt\n\ndef cosine_lr(step, total, lr_max):\n    # simple cosine from lr_max -> 0\n    if total <= 1:\n        return lr_max\n    t = min(max(step / total, 0.0), 1.0)\n    return lr_max * 0.5 * (1.0 + math.cos(math.pi * t))\n\n# ----------------------------\n# Output directory (versioned)\n# ----------------------------\nRUN_TAG = hashlib.md5(json.dumps(CFG, sort_keys=True).encode()).hexdigest()[:10]\nOUT_DIR = Path(CFG[\"out_root\"]) / f\"dinov2_mt_v5_{RUN_TAG}\"\nCKPT_DIR = OUT_DIR / \"checkpoints\"\nOUT_DIR.mkdir(parents=True, exist_ok=True)\nCKPT_DIR.mkdir(parents=True, exist_ok=True)\n\nprint(\"\\nOUT_DIR:\", OUT_DIR)\nprint(\"device:\", device, \"| folds:\", unique_folds)\n\n# ----------------------------\n# CV TRAIN\n# ----------------------------\nn_all = len(df_train_all)\noof_p_cls = np.zeros(n_all, dtype=np.float32)\noof_seg   = np.zeros((n_all, GH, GW), dtype=np.float16)\noof_gt    = np.zeros((n_all, GH, GW), dtype=np.uint8)\noof_y     = df_train_all[\"y_forged\"].values.astype(np.int8)\noof_fold  = df_train_all[\"fold\"].values.astype(int)\noof_sid   = df_train_all[\"sample_id\"].astype(str).tolist()\n\nfold_reports = {}\nbest_fold_paths = {}\n\nfor f in unique_folds:\n    print(f\"\\n====================\\nFOLD {f}\\n====================\")\n    tr_idx = np.where(oof_fold != f)[0]\n    va_idx = np.where(oof_fold == f)[0]\n    if len(va_idx) == 0:\n        print(\"Skip fold (no val).\")\n        continue\n\n    df_tr = df_train_all.iloc[tr_idx].reset_index(drop=True)\n    df_va = df_train_all.iloc[va_idx].reset_index(drop=True)\n\n    ds_tr = DinoMTDataset(df_tr, train=True)\n    ds_va = DinoMTDataset(df_va, train=False)\n\n    # sampler for train\n    sw = sample_w[tr_idx]\n    sampler = WeightedRandomSampler(weights=torch.from_numpy(sw), num_samples=len(sw), replacement=True)\n\n    dl_tr = DataLoader(ds_tr, batch_size=int(CFG[\"batch_size\"]), sampler=sampler,\n                       num_workers=int(CFG[\"num_workers\"]), pin_memory=(device.type==\"cuda\"))\n    dl_va = DataLoader(ds_va, batch_size=int(CFG[\"batch_size\"]), shuffle=False,\n                       num_workers=int(CFG[\"num_workers\"]), pin_memory=(device.type==\"cuda\"))\n\n    # backbone\n    print(\"Loading DINO from:\", CFG[\"dino_dir\"])\n    backbone = AutoModel.from_pretrained(str(CFG[\"dino_dir\"]), local_files_only=True)\n    backbone.eval()\n\n    if CFG.get(\"use_grad_ckpt\", False) and hasattr(backbone, \"gradient_checkpointing_enable\"):\n        try:\n            backbone.gradient_checkpointing_enable()\n            print(\"gradient checkpointing: ON\")\n        except Exception:\n            pass\n\n    freeze_all(backbone)\n    used_unfreeze = unfreeze_last_n_blocks(backbone, int(CFG[\"unfreeze_last_n_blocks\"]))\n    print(\"unfreeze_last_n_blocks used:\", used_unfreeze)\n\n    model = DinoMultiTask(backbone, gh=GH, gw=GW).to(device)\n    # heads always trainable\n    for p in model.cls_head.parameters():\n        p.requires_grad = True\n    for p in model.seg_head.parameters():\n        p.requires_grad = True\n\n    opt = build_optimizer(model)\n\n    # AMP scaler\n    use_amp = bool(CFG[\"amp\"]) and (device.type == \"cuda\")\n    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n\n    # training steps for cosine schedule\n    steps_per_epoch = max(1, len(dl_tr))\n    total_steps = int(CFG[\"epochs\"]) * steps_per_epoch\n\n    best_score = -1e9\n    best_state = None\n    best_epoch = -1\n    bad_epochs = 0\n\n    global_step = 0\n    t0 = time.time()\n\n    for epoch in range(int(CFG[\"epochs\"])):\n        model.train()\n        running = 0.0\n        n_seen = 0\n\n        for it, (x, g, y, sid) in enumerate(dl_tr, start=1):\n            x = x.to(device, non_blocking=True)\n            g = g.to(device, non_blocking=True)         # [B,GH,GW]\n            y = y.to(device, non_blocking=True).view(-1)  # [B]\n\n            # lr schedule (two groups): scale by cosine on each group's base lr\n            lr_scale = cosine_lr(global_step, total_steps, 1.0)\n            for pg in opt.param_groups:\n                base = float(pg.get(\"lr\", 1e-4))\n                # base already set; rescale relative to initial? keep simple:\n                pg[\"lr\"] = base * lr_scale\n\n            with torch.cuda.amp.autocast(enabled=use_amp):\n                cls_logit, seg_logit = model(x)\n\n                # cls loss\n                loss_cls = bce_with_pos_weight(cls_logit, y, pos_weight=pos_weight_cls)\n\n                # seg loss on grid\n                loss_seg_bce  = bce_with_pos_weight(seg_logit, g, pos_weight=pos_weight_seg)\n                loss_seg_dice = dice_loss_from_logits(seg_logit, g, eps=float(CFG[\"dice_eps\"]))\n\n                loss = (float(CFG[\"w_cls\"]) * loss_cls\n                        + float(CFG[\"w_seg_bce\"]) * loss_seg_bce\n                        + float(CFG[\"w_seg_dice\"]) * loss_seg_dice)\n\n            loss = loss / float(CFG[\"grad_accum\"])\n\n            scaler.scale(loss).backward()\n\n            if (it % int(CFG[\"grad_accum\"])) == 0:\n                # grad clip\n                if float(CFG[\"clip_grad\"]) > 0:\n                    scaler.unscale_(opt)\n                    torch.nn.utils.clip_grad_norm_(model.parameters(), float(CFG[\"clip_grad\"]))\n\n                scaler.step(opt)\n                scaler.update()\n                opt.zero_grad(set_to_none=True)\n\n            running += float(loss.item()) * float(CFG[\"grad_accum\"])\n            n_seen += x.size(0)\n            global_step += 1\n\n            if (it % int(CFG[\"print_every\"])) == 0:\n                dt = time.time() - t0\n                print(f\"epoch={epoch+1}/{CFG['epochs']} it={it}/{len(dl_tr)} \"\n                      f\"loss={running/max(1,it):.4f} seen={n_seen} step={global_step} elapsed_s={dt:.1f}\")\n\n        # eval\n        ev = evaluate(model, dl_va)\n        print(f\"[VAL] epoch={epoch+1} score={ev['score']:.5f} AUC={ev['auc']:.5f} AP={ev['ap']:.5f} dice_forg@0.5={ev['dice_forg@0.5']:.5f}\")\n\n        if ev[\"score\"] > best_score:\n            best_score = ev[\"score\"]\n            best_epoch = epoch + 1\n            bad_epochs = 0\n            # save trainable state\n            best_state = get_trainable_state_dict(model)\n        else:\n            bad_epochs += 1\n            if bad_epochs >= int(CFG[\"patience\"]):\n                print(f\"Early stop on fold {f} at epoch {epoch+1}. Best epoch={best_epoch} best_score={best_score:.5f}\")\n                break\n\n        gc.collect()\n        if device.type == \"cuda\":\n            torch.cuda.empty_cache()\n\n    # load best state into model (for OOF extraction)\n    if best_state is not None:\n        # apply into current model\n        cur = model.state_dict()\n        for k, v in best_state.items():\n            if k in cur:\n                cur[k] = v.to(cur[k].dtype)\n        model.load_state_dict(cur, strict=False)\n\n    # final val for OOF storing\n    ev = evaluate(model, dl_va)\n\n    # write OOF to global arrays\n    # map val local indices -> global indices\n    for j, sid in enumerate(ev[\"sid\"]):\n        # sid belongs to df_va order, map by position j\n        gi = va_idx[j]\n        oof_p_cls[gi] = ev[\"p_cls\"][j]\n        # ensure shapes align\n        sg = ev[\"seg_prob\"][j]\n        gt = ev[\"gt_grid\"][j]\n        if sg.shape != (GH, GW):\n            # resize fallback via nearest on numpy (rare)\n            sg = np.array(Image.fromarray(sg.astype(np.float32)).resize((GW, GH), resample=Image.NEAREST)).astype(np.float16)\n        if gt.shape != (GH, GW):\n            gt = np.array(Image.fromarray(gt.astype(np.uint8)*255).resize((GW, GH), resample=Image.NEAREST) > 0).astype(np.uint8)\n        oof_seg[gi] = sg\n        oof_gt[gi]  = gt\n\n    # save fold checkpoint (trainable only)\n    ckpt_path = CKPT_DIR / f\"fold_{int(f)}.pt\"\n    torch.save({\n        \"fold\": int(f),\n        \"best_epoch\": int(best_epoch),\n        \"best_score\": float(best_score),\n        \"trainable_state\": best_state,\n        \"unfreeze_last_n_blocks\": int(CFG[\"unfreeze_last_n_blocks\"]),\n        \"img_size\": int(IMG_SIZE),\n        \"patch_size\": int(PATCH),\n        \"gh\": int(GH),\n        \"gw\": int(GW),\n        \"dino_dir\": str(CFG[\"dino_dir\"]),\n    }, ckpt_path)\n\n    best_fold_paths[int(f)] = str(ckpt_path)\n\n    fold_reports[int(f)] = {\n        \"best_epoch\": int(best_epoch),\n        \"best_score\": float(best_score),\n        \"val_auc\": float(ev[\"auc\"]) if np.isfinite(ev[\"auc\"]) else None,\n        \"val_ap\": float(ev[\"ap\"]) if np.isfinite(ev[\"ap\"]) else None,\n        \"val_dice_forg@0.5\": float(ev[\"dice_forg@0.5\"]),\n        \"ckpt_path\": str(ckpt_path),\n    }\n\n    print(f\"[FOLD {f}] saved: {ckpt_path}\")\n\n# ----------------------------\n# Calibration on OOF (cls only)\n# ----------------------------\ny = oof_y.astype(int)\np_raw = oof_p_cls.astype(np.float32)\n\ncalibrator = None\ncalib_kind = \"none\"\ntry:\n    if np.unique(y).size >= 2 and len(y) >= 200 and np.unique(p_raw).size >= 50:\n        iso = IsotonicRegression(out_of_bounds=\"clip\")\n        iso.fit(p_raw, y)\n        calibrator = iso\n        calib_kind = \"isotonic\"\n    else:\n        raise RuntimeError(\"Not enough unique probs for isotonic.\")\nexcept Exception:\n    try:\n        platt = LogisticRegression(solver=\"lbfgs\", max_iter=4000)\n        platt.fit(p_raw.reshape(-1,1), y)\n        calibrator = platt\n        calib_kind = \"platt\"\n    except Exception:\n        calibrator = None\n        calib_kind = \"none\"\n\ndef apply_calibrator(p):\n    p = np.asarray(p, dtype=np.float32)\n    if calibrator is None or calib_kind == \"none\":\n        return p\n    if calib_kind == \"isotonic\":\n        return calibrator.transform(p).astype(np.float32)\n    return calibrator.predict_proba(p.reshape(-1,1))[:,1].astype(np.float32)\n\np_cal = apply_calibrator(p_raw)\n\n# OOF cls metrics\nif np.unique(y).size >= 2:\n    auc_raw = float(roc_auc_score(y, p_raw))\n    ap_raw  = float(average_precision_score(y, p_raw))\n    auc_cal = float(roc_auc_score(y, p_cal))\n    ap_cal  = float(average_precision_score(y, p_cal))\nelse:\n    auc_raw = ap_raw = auc_cal = ap_cal = float(\"nan\")\n\nprint(\"\\n[OOF CLS] raw : AUC=%.5f AP=%.5f\" % (auc_raw, ap_raw))\nprint(\"[OOF CLS] cal(%s): AUC=%.5f AP=%.5f\" % (calib_kind, auc_cal, ap_cal))\n\n# save calibrator\njoblib.dump({\"kind\": calib_kind, \"calibrator\": calibrator}, OUT_DIR / \"calibrator.joblib\")\n\n# ----------------------------\n# Threshold tuning (vectorized, FAST)\n# - tune: thr_forged, thr_mask, min_pred_patches\n# Objective (weighted per-fold):\n#   if gt_empty: score=1 - pf*(pred_nonempty)\n#   if gt_nonempty: score=pf * dice\n# where pf = (p_cal >= thr_forged)\n# dice computed on grid with threshold thr_mask\n# pred_nonempty uses min_pred_patches\n# ----------------------------\ngt = (oof_gt > 0).astype(np.uint8)                 # [N,GH,GW]\ngt_sum = gt.reshape(n_all, -1).sum(axis=1).astype(np.int32)\ngt_empty = (gt_sum == 0)\n\n# balanced weights for objective\nw_pos2 = (y.sum() + (y==0).sum()) / (2.0 * max(y.sum(), 1))\nw_neg2 = (y.sum() + (y==0).sum()) / (2.0 * max((y==0).sum(), 1))\nw_obj = np.where(y == 1, w_pos2, w_neg2).astype(np.float32)\n\nthr_p_list = np.linspace(0.05, 0.95, 37).astype(np.float32)\nthr_m_list = np.linspace(0.20, 0.80, 31).astype(np.float32)\nmin_patches_list = np.array([0, 1, 2, 4, 8, 16], dtype=np.int32)\n\n# precompute per-fold masks\nfold_ids = sorted(np.unique(oof_fold).tolist())\nfold_masks = [(f, (oof_fold == f)) for f in fold_ids]\n\n# precompute dice and pred_sum for each thr_mask\nseg = oof_seg.astype(np.float32)  # [N,GH,GW] (float16 -> float32)\n\ndice_by_tm = np.zeros((len(thr_m_list), n_all), dtype=np.float32)\npsum_by_tm = np.zeros((len(thr_m_list), n_all), dtype=np.int32)\n\nprint(\"\\n[THR] Precomputing dice / pred_sum across thr_mask ...\")\nt0 = time.time()\nfor i_tm, tm in enumerate(thr_m_list):\n    pred = (seg >= float(tm)).astype(np.uint8)\n    ps = pred.reshape(n_all, -1).sum(axis=1).astype(np.int32)\n    inter = (pred & gt).reshape(n_all, -1).sum(axis=1).astype(np.int32)\n    gs = gt_sum.astype(np.int32)\n\n    dice = np.zeros(n_all, dtype=np.float32)\n    both0 = (ps == 0) & (gs == 0)\n    dice[both0] = 1.0\n    m = ~both0\n    dice[m] = (2.0 * inter[m].astype(np.float32)) / (ps[m].astype(np.float32) + gs[m].astype(np.float32) + 1e-6)\n\n    dice_by_tm[i_tm] = dice\n    psum_by_tm[i_tm] = ps\n\ndt = time.time() - t0\nprint(f\"[THR] Precompute done in {dt:.1f}s\")\n\nbest = {\n    \"score\": -1e9,\n    \"thr_forged\": 0.5,\n    \"thr_mask\": 0.5,\n    \"min_pred_patches\": 0,\n}\n\nprint(\"\\n[THR] Grid search thr_forged x thr_mask x min_pred_patches (weighted fold-mean) ...\")\nt0 = time.time()\n\nfor tp in thr_p_list:\n    pf = (p_cal >= float(tp))  # [N] bool\n    for i_tm, tm in enumerate(thr_m_list):\n        dice = dice_by_tm[i_tm]   # [N]\n        ps   = psum_by_tm[i_tm]   # [N] int\n\n        for mp in min_patches_list:\n            pred_nonempty = (ps >= int(mp))  # [N] bool\n\n            # score per sample:\n            # gt_empty: 1 - pf*pred_nonempty\n            # gt_nonempty: pf*dice\n            s = np.zeros(n_all, dtype=np.float32)\n            s[gt_empty] = 1.0 - (pf[gt_empty] & pred_nonempty[gt_empty]).astype(np.float32)\n            ne = ~gt_empty\n            s[ne] = (pf[ne].astype(np.float32) * dice[ne].astype(np.float32))\n\n            # fold mean weighted\n            fold_scores = []\n            for f, m in fold_masks:\n                if m.sum() == 0:\n                    continue\n                ww = w_obj[m]\n                fold_scores.append(float(np.sum(s[m] * ww) / (np.sum(ww) + 1e-12)))\n            mean_score = float(np.mean(fold_scores)) if fold_scores else -1e9\n\n            if mean_score > best[\"score\"]:\n                best = {\n                    \"score\": mean_score,\n                    \"thr_forged\": float(tp),\n                    \"thr_mask\": float(tm),\n                    \"min_pred_patches\": int(mp),\n                }\n\nprint(f\"[THR] Search done in {time.time()-t0:.1f}s\")\nprint(\"Best thresholds:\")\nprint(json.dumps(best, indent=2))\n\n# ----------------------------\n# Save artifacts\n# ----------------------------\nthresholds = {\n    \"thr_forged\": best[\"thr_forged\"],\n    \"thr_p\": best[\"thr_forged\"],          # alias for compatibility\n    \"thr_mask\": best[\"thr_mask\"],\n    \"min_pred_patches\": best[\"min_pred_patches\"],\n    \"grid_hw\": [int(GH), int(GW)],\n    \"img_size\": int(IMG_SIZE),\n    \"patch_size\": int(PATCH),\n    \"calibration\": calib_kind,\n}\nwith open(OUT_DIR / \"thresholds.json\", \"w\") as f:\n    json.dump(thresholds, f, indent=2)\n\nmodel_config = {\n    \"dino_dir\": str(CFG[\"dino_dir\"]),\n    \"img_size\": int(IMG_SIZE),\n    \"patch_size\": int(PATCH),\n    \"grid_hw\": [int(GH), int(GW)],\n    \"unfreeze_last_n_blocks\": int(CFG[\"unfreeze_last_n_blocks\"]),\n    \"note\": \"Checkpoints store trainable_state only (heads + unfrozen blocks). Load base DINO from dino_dir, then apply trainable_state.\",\n    \"fold_checkpoints\": best_fold_paths,\n}\nwith open(OUT_DIR / \"model_config.json\", \"w\") as f:\n    json.dump(model_config, f, indent=2)\n\n# OOF audit file\ndf_oof = pd.DataFrame({\n    \"sample_id\": oof_sid,\n    \"fold\": oof_fold,\n    \"y_forged\": oof_y,\n    \"p_raw\": p_raw.astype(np.float32),\n    \"p_cal\": p_cal.astype(np.float32),\n    \"gt_sum\": gt_sum.astype(np.int32),\n})\ndf_oof.to_csv(OUT_DIR / \"oof_predictions.csv\", index=False)\n\n# final report\nreport = {\n    \"cfg\": CFG,\n    \"out_dir\": str(OUT_DIR),\n    \"device\": str(device),\n    \"n_train\": int(n_all),\n    \"forged_rate\": float(oof_y.mean()),\n    \"oof_auc_raw\": auc_raw if np.isfinite(auc_raw) else None,\n    \"oof_ap_raw\": ap_raw if np.isfinite(ap_raw) else None,\n    \"oof_auc_cal\": auc_cal if np.isfinite(auc_cal) else None,\n    \"oof_ap_cal\": ap_cal if np.isfinite(ap_cal) else None,\n    \"thresholds\": thresholds,\n    \"fold_reports\": fold_reports,\n}\nwith open(OUT_DIR / \"report.json\", \"w\") as f:\n    json.dump(report, f, indent=2)\n\n# print checkpoint sizes\nsizes = {}\nfor k, p in best_fold_paths.items():\n    pp = Path(p)\n    if pp.exists():\n        sizes[str(k)] = float(pp.stat().st_size / (1024**2))\nprint(\"\\nCheckpoint sizes (MB) per fold:\", sizes)\n\nprint(\"\\nSAVED ->\", OUT_DIR)\nprint(\"Files:\", sorted([p.name for p in OUT_DIR.iterdir()]))\n\nDINO_MT_MODEL_DIR = str(OUT_DIR)\nprint(\"\\nDONE. Exported: DINO_MT_MODEL_DIR =\", DINO_MT_MODEL_DIR)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Inference Strategy: Two-Pass + Smart Ensemble + Export RLE (Strict Guard)","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 6 — DINOv2 Multi-Task Inference: Two-Pass + Smart Ensemble + Export RLE (Strict Guard)\n# ONE CELL, REVISI FULL v3 (FAST + ROBUST + STRICT ORDER)\n#\n# Requirements:\n# - Output STAGE 5 (DINO Multi-task) exists:\n#   * DINO_MT_MODEL_DIR (or auto-find /kaggle/working/recodai_luc/models/dinov2_mt_v5_*)\n#   * model_config.json, thresholds.json, calibrator.joblib, checkpoints/fold_*.pt\n#\n# Key upgrades:\n# - Mean-weights ensemble across folds (FAST). Optional exact fold ensemble if needed.\n# - PASS-1 small (448) + PASS-2 large (700) only for borderline.\n# - Strict guard uses: thr_forged + thr_mask + min_pred_patches + anti-huge/fragment rules.\n# - Cache PASS-1/PASS-2 masks as NPZ (mask_pack) => rerun is fast.\n# - Export RLE strictly in sample_submission order.\n# ============================================================\n\nimport os, gc, json, time, math, re\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image, ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import AutoModel\nimport joblib\n\n# ----------------------------\n# Optional SciPy for morphology / components\n# ----------------------------\ntry:\n    import scipy.ndimage as ndi\n    _HAS_SCIPY = True\nexcept Exception:\n    _HAS_SCIPY = False\n\n# ----------------------------\n# PATHS (fixed)\n# ----------------------------\nDATA_ROOT = Path(\"/kaggle/input/recodai-luc-scientific-image-forgery-detection\")\nTEST_IMAGES_DIR = DATA_ROOT / \"test_images\"\nSAMPLE_SUB_PATH = DATA_ROOT / \"sample_submission.csv\"\n\n# ----------------------------\n# CACHE DIRS\n# ----------------------------\nP1_DIR = Path(\"/kaggle/working/recodai_luc/cache/dino_mt_p1\")\nP2_DIR = Path(\"/kaggle/working/recodai_luc/cache/dino_mt_p2\")\nP1_DIR.mkdir(parents=True, exist_ok=True)\nP2_DIR.mkdir(parents=True, exist_ok=True)\n\nOUT_SUB_PATH  = Path(\"/kaggle/working/submission.csv\")\nOUT_COPY_PATH = Path(\"/kaggle/working/recodai_luc/outputs/submission.csv\")\nOUT_COPY_PATH.parent.mkdir(parents=True, exist_ok=True)\n\n# ----------------------------\n# USER TUNABLE (safe defaults)\n# ----------------------------\nPASS1_SIZE = 448          # must be multiple of patch_size=14 (OK)\nPASS2_SIZE = 700          # must be multiple of 14 (OK)\nPASS1_BS   = 8            # auto-reduce if OOM\nPASS2_BS   = 4\nUSE_PASS2  = True\n\nBORDER_MARGIN = 0.08      # borderline if |p-thr| <= margin\nMAX_BORDERLINE = None     # set int to cap PASS-2 (e.g., 1500)\n\n# FAST ensemble: average weights across folds (recommended)\nEXACT_FOLD_ENSEMBLE = False  # if True: run all folds and average outputs (slower)\n\n# RLE order (if you already set global RLE_ORDER, it will use it)\nRLE_ORDER = globals().get(\"RLE_ORDER\", \"F\")\nif RLE_ORDER not in (\"F\",\"C\"):\n    RLE_ORDER = \"F\"\n\n# ----------------------------\n# Require sample submission\n# ----------------------------\nif not SAMPLE_SUB_PATH.exists():\n    raise FileNotFoundError(f\"sample_submission.csv not found: {SAMPLE_SUB_PATH}\")\n\ndf_sample = pd.read_csv(SAMPLE_SUB_PATH)\nif not {\"case_id\",\"annotation\"}.issubset({c.lower() for c in df_sample.columns}):\n    raise ValueError(f\"sample_submission must contain case_id, annotation. Found: {list(df_sample.columns)}\")\n\ncol_case = [c for c in df_sample.columns if c.lower()==\"case_id\"][0]\ncol_ann  = [c for c in df_sample.columns if c.lower()==\"annotation\"][0]\ndf_sample = df_sample.rename(columns={col_case:\"case_id\", col_ann:\"annotation\"}).copy()\ndf_sample[\"case_id\"] = df_sample[\"case_id\"].astype(str)\n\n# ----------------------------\n# Resolve test images in STRICT sample order\n# ----------------------------\nIMG_EXTS = {\".png\",\".jpg\",\".jpeg\",\".tif\",\".tiff\",\".bmp\",\".webp\"}\n\ndef build_caseid_map(folder: Path) -> dict:\n    mp = {}\n    files = [p for p in folder.rglob(\"*\") if p.is_file() and p.suffix.lower() in IMG_EXTS]\n    files.sort()\n    for p in files:\n        cid = p.stem\n        if cid not in mp:\n            mp[cid] = p\n    return mp\n\ntest_img_map = build_caseid_map(TEST_IMAGES_DIR)\ndf_test = pd.DataFrame({\"case_id\": df_sample[\"case_id\"].astype(str).tolist()})\ndf_test[\"image_path\"] = df_test[\"case_id\"].map(lambda x: str(test_img_map.get(str(x), \"\")))\n\nn_ok = int(df_test[\"image_path\"].map(lambda p: Path(p).exists()).sum())\nprint(f\"Test images resolved: {n_ok:,}/{len(df_test):,}\")\n\n# ----------------------------\n# RLE encode\n# ----------------------------\ndef rle_encode(mask: np.ndarray, order: str=\"F\") -> str:\n    m = (mask > 0).astype(np.uint8)\n    if m.sum() == 0:\n        return \"\"\n    if order.upper() == \"F\":\n        pixels = m.T.reshape(-1)\n    else:\n        pixels = m.reshape(-1)\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[0::2]\n    return \" \".join(map(str, runs))\n\n# ----------------------------\n# Auto-find DINO_MT_MODEL_DIR\n# ----------------------------\ndef _auto_find_latest_dir(root: Path, pattern: str):\n    root = Path(root)\n    if not root.exists():\n        return None\n    cands = [p for p in root.glob(pattern) if p.is_dir()]\n    if not cands:\n        return None\n    cands.sort(key=lambda p: p.stat().st_mtime, reverse=True)\n    return cands[0]\n\nif \"DINO_MT_MODEL_DIR\" in globals():\n    DINO_MT_MODEL_DIR = Path(str(globals()[\"DINO_MT_MODEL_DIR\"]))\nelse:\n    DINO_MT_MODEL_DIR = _auto_find_latest_dir(Path(\"/kaggle/working/recodai_luc/models\"), \"dinov2_mt_v5_*\")\n\nif DINO_MT_MODEL_DIR is None or (not DINO_MT_MODEL_DIR.exists()):\n    raise FileNotFoundError(\"DINO_MT_MODEL_DIR not found. Jalankan STAGE 5 DINO Multi-task dulu.\")\n\ncfg_path = DINO_MT_MODEL_DIR / \"model_config.json\"\nthr_path = DINO_MT_MODEL_DIR / \"thresholds.json\"\ncal_path = DINO_MT_MODEL_DIR / \"calibrator.joblib\"\nckpt_dir = DINO_MT_MODEL_DIR / \"checkpoints\"\n\nfor p in [cfg_path, thr_path, cal_path, ckpt_dir]:\n    if not p.exists():\n        raise FileNotFoundError(f\"Missing artifact: {p}\")\n\nmodel_cfg = json.loads(cfg_path.read_text())\nthr_cfg   = json.loads(thr_path.read_text())\ncal_pack  = joblib.load(cal_path)\n\ncalib_kind = cal_pack.get(\"kind\", \"none\")\ncalibrator = cal_pack.get(\"calibrator\", None)\n\n# thresholds from stage 5\nthr_forged = float(thr_cfg.get(\"thr_forged\", thr_cfg.get(\"thr_p\", 0.5)))\nthr_mask   = float(thr_cfg.get(\"thr_mask\", 0.5))\nmin_pred_patches = int(thr_cfg.get(\"min_pred_patches\", 0))\n\npatch_size = int(thr_cfg.get(\"patch_size\", model_cfg.get(\"patch_size\", 14)))\nassert PASS1_SIZE % patch_size == 0 and PASS2_SIZE % patch_size == 0, \"PASS sizes must be multiple of patch_size.\"\n\nprint(\"\\nLoaded DINO multi-task artifacts:\")\nprint(f\"  model_dir          : {DINO_MT_MODEL_DIR}\")\nprint(f\"  dino_dir           : {model_cfg.get('dino_dir')}\")\nprint(f\"  patch_size         : {patch_size}\")\nprint(f\"  thr_forged         : {thr_forged}\")\nprint(f\"  thr_mask           : {thr_mask}\")\nprint(f\"  min_pred_patches   : {min_pred_patches}\")\nprint(f\"  calib_kind         : {calib_kind}\")\nprint(f\"  EXACT_FOLD_ENSEMBLE: {EXACT_FOLD_ENSEMBLE}\")\nprint(f\"  RLE_ORDER          : {RLE_ORDER}\")\n\ndef apply_calibrator(p):\n    p = np.asarray(p, dtype=np.float32)\n    if calibrator is None or calib_kind == \"none\":\n        return p\n    if calib_kind == \"isotonic\":\n        return calibrator.transform(p).astype(np.float32)\n    return calibrator.predict_proba(p.reshape(-1,1))[:,1].astype(np.float32)\n\n# ----------------------------\n# Build DINO multitask model (same heads as STAGE 5)\n# ----------------------------\nIMNET_MEAN = torch.tensor([0.485, 0.456, 0.406], dtype=torch.float32).view(3,1,1)\nIMNET_STD  = torch.tensor([0.229, 0.224, 0.225], dtype=torch.float32).view(3,1,1)\n\ndef freeze_all(model):\n    for p in model.parameters():\n        p.requires_grad = False\n\nclass DinoMultiTask(nn.Module):\n    def __init__(self, backbone: nn.Module, patch: int):\n        super().__init__()\n        self.backbone = backbone\n        self.patch = int(patch)\n\n        # infer embed dim\n        with torch.no_grad():\n            dummy = torch.zeros((1,3,PASS1_SIZE,PASS1_SIZE), dtype=torch.float32)\n            out = self.backbone(pixel_values=dummy)\n            D = int(out.last_hidden_state.shape[-1])\n        self.embed_dim = D\n\n        self.cls_head = nn.Sequential(nn.LayerNorm(D), nn.Linear(D, 1))\n        self.seg_head = nn.Sequential(nn.LayerNorm(D), nn.Linear(D, 1))\n\n    def forward(self, x):\n        out = self.backbone(pixel_values=x)\n        h = out.last_hidden_state  # [B,1+N,D]\n        cls_tok = h[:, 0, :]\n        ptok = h[:, 1:, :]\n        cls_logit = self.cls_head(cls_tok).squeeze(-1)      # [B]\n        seg_patch = self.seg_head(ptok).squeeze(-1)         # [B,N]\n\n        # infer grid from input size (square)\n        B, _, H, W = x.shape\n        gh = H // self.patch\n        gw = W // self.patch\n        Nexp = gh * gw\n        if seg_patch.shape[1] < Nexp:\n            # safety: pad\n            pad = Nexp - seg_patch.shape[1]\n            seg_patch = torch.cat([seg_patch, seg_patch.new_zeros((B, pad))], dim=1)\n        seg_grid = seg_patch[:, :Nexp].reshape(B, gh, gw)\n        return cls_logit, seg_grid\n\n# ----------------------------\n# Load fold checkpoints and build ensemble state\n# ----------------------------\ndef list_fold_ckpts(ckpt_dir: Path):\n    cands = sorted(ckpt_dir.glob(\"fold_*.pt\"))\n    if not cands:\n        raise FileNotFoundError(f\"No fold checkpoints found in {ckpt_dir}\")\n    return cands\n\nfold_ckpts = list_fold_ckpts(ckpt_dir)\nprint(f\"\\nFound fold checkpoints: {len(fold_ckpts)}\")\n\ndef load_trainable_state(pt_path: Path):\n    ck = torch.load(pt_path, map_location=\"cpu\")\n    sd = ck.get(\"trainable_state\", None)\n    if sd is None:\n        raise RuntimeError(f\"Checkpoint missing trainable_state: {pt_path}\")\n    # ensure float32 for averaging\n    out = {}\n    for k, v in sd.items():\n        if torch.is_tensor(v) and v.is_floating_point():\n            out[k] = v.float()\n        else:\n            out[k] = v\n    return out\n\ndef average_states(states: list):\n    keys = set(states[0].keys())\n    for st in states[1:]:\n        keys &= set(st.keys())\n    keys = sorted(list(keys))\n    avg = {}\n    for k in keys:\n        vs = [st[k] for st in states]\n        if torch.is_tensor(vs[0]) and vs[0].is_floating_point():\n            s = vs[0].clone()\n            for t in vs[1:]:\n                s += t\n            avg[k] = (s / float(len(vs)))\n        else:\n            avg[k] = vs[0]\n    return avg\n\ndef apply_trainable_state(model: nn.Module, trainable_state: dict):\n    cur = model.state_dict()\n    for k, v in trainable_state.items():\n        if k in cur:\n            if torch.is_tensor(v) and torch.is_tensor(cur[k]):\n                cur[k] = v.to(cur[k].dtype)\n            else:\n                cur[k] = v\n    model.load_state_dict(cur, strict=False)\n\n# ----------------------------\n# Image preprocessing (square, consistent with STAGE 5)\n# ----------------------------\ndef load_image_square(path: str, size: int):\n    p = Path(path)\n    if not p.exists():\n        return None, None\n    im = Image.open(p).convert(\"RGB\")\n    orig_w, orig_h = im.size\n    if im.size != (size, size):\n        im = im.resize((size, size), resample=Image.BICUBIC)\n    arr = (np.asarray(im, dtype=np.float32) / 255.0)  # HWC\n    x = torch.from_numpy(arr).permute(2,0,1).contiguous()  # CHW\n    x = (x - IMNET_MEAN) / IMNET_STD\n    meta = {\"orig_h\": int(orig_h), \"orig_w\": int(orig_w), \"side\": int(size)}\n    return x, meta\n\ndef grid_to_mask_orig(grid_u8: np.ndarray, meta: dict, patch: int):\n    # grid_u8: [gh,gw] 0/1 on square side meta[\"side\"]\n    side = int(meta[\"side\"])\n    orig_h = int(meta[\"orig_h\"])\n    orig_w = int(meta[\"orig_w\"])\n    mask_sq = np.kron(grid_u8.astype(np.uint8), np.ones((patch, patch), dtype=np.uint8))\n    mask_sq = mask_sq[:side, :side]\n    # resize square->orig\n    if (orig_w, orig_h) != (side, side):\n        im = Image.fromarray((mask_sq * 255).astype(np.uint8))\n        im = im.resize((orig_w, orig_h), resample=Image.NEAREST)\n        mask = (np.array(im) > 0).astype(np.uint8)\n    else:\n        mask = mask_sq.astype(np.uint8)\n    return mask\n\ndef pack_mask(mask_u8: np.ndarray):\n    mh, mw = mask_u8.shape\n    pack = np.packbits((mask_u8 > 0).astype(np.uint8), axis=None).astype(np.uint8)\n    return pack, mh, mw\n\ndef unpack_mask(pack: np.ndarray, h: int, w: int):\n    if h <= 0 or w <= 0 or pack is None or pack.size == 0:\n        return np.zeros((max(h,1), max(w,1)), dtype=np.uint8)\n    bits = np.unpackbits(pack.astype(np.uint8), axis=None)[: h*w]\n    return bits.reshape(h, w).astype(np.uint8)\n\n# ----------------------------\n# Post-filter mask (anti-fragment, anti-noise)\n# ----------------------------\ndef filter_mask(mask_u8: np.ndarray, min_area_frac=0.0, keep_topk=10, close_ks=3, open_ks=0):\n    if mask_u8.sum() == 0:\n        return mask_u8, {\"n_comp\": 0, \"largest\": 0}\n\n    H, W = mask_u8.shape\n    area = int(mask_u8.sum())\n    denom = float(H*W) + 1e-9\n    if float(min_area_frac) > 0 and (area/denom) < float(min_area_frac):\n        return np.zeros_like(mask_u8, dtype=np.uint8), {\"n_comp\": 0, \"largest\": 0}\n\n    m = mask_u8.astype(bool)\n    if _HAS_SCIPY:\n        if int(close_ks) and int(close_ks) > 1:\n            st = np.ones((int(close_ks), int(close_ks)), dtype=bool)\n            m = ndi.binary_closing(m, structure=st)\n        if int(open_ks) and int(open_ks) > 1:\n            st = np.ones((int(open_ks), int(open_ks)), dtype=bool)\n            m = ndi.binary_opening(m, structure=st)\n\n        lab, n = ndi.label(m)\n        if n <= 0:\n            return np.zeros_like(mask_u8, dtype=np.uint8), {\"n_comp\": 0, \"largest\": 0}\n\n        areas = np.bincount(lab.ravel())\n        areas[0] = 0\n        comps = np.where(areas > 0)[0]\n        comps = comps[np.argsort(areas[comps])[::-1]]\n        if keep_topk and int(keep_topk) > 0:\n            comps = comps[:int(keep_topk)]\n        out = np.isin(lab, comps).astype(np.uint8)\n        largest = int(areas[comps[0]]) if comps.size else 0\n        return out, {\"n_comp\": int(comps.size), \"largest\": largest}\n\n    # no scipy: minimal\n    return mask_u8.astype(np.uint8), {\"n_comp\": 1, \"largest\": int(mask_u8.sum())}\n\n# ----------------------------\n# Strict guard + quality score (DINO multi-task)\n# ----------------------------\ndef strict_guard(p_cal: float, pred_patches: int, area_frac: float):\n    if float(p_cal) < thr_forged:\n        return False\n    if int(pred_patches) < int(min_pred_patches):\n        return False\n    # anti-huge mask unless very confident\n    if float(area_frac) > 0.65 and float(p_cal) < (thr_forged + 0.12):\n        return False\n    # tiny mask with low confidence -> reject\n    if float(area_frac) < 0.00015 and float(p_cal) < (thr_forged + 0.10):\n        return False\n    return True\n\ndef quality_score(p_cal: float, area_frac: float, n_comp: float, mean_conf_in_mask: float):\n    # higher is better\n    frag_pen = min(float(n_comp) / 35.0, 1.0) * 0.35\n    huge_pen = 0.0\n    if float(area_frac) > 0.35:\n        huge_pen = min((float(area_frac) - 0.35) / 0.35, 1.0) * 0.45\n    q = float(p_cal) * (0.55 + 0.45*float(mean_conf_in_mask)) * (1.0 - frag_pen) * (1.0 - huge_pen)\n    return float(q)\n\ndef mean_conf_inside(seg_prob_grid: np.ndarray, grid_bin: np.ndarray):\n    # seg_prob_grid float32 [gh,gw], grid_bin uint8\n    if grid_bin.sum() == 0:\n        return 0.0\n    v = seg_prob_grid[grid_bin > 0]\n    return float(v.mean()) if v.size else 0.0\n\n# ----------------------------\n# Cache IO (store final thresholded mask + stats)\n# ----------------------------\ndef cache_path(cache_dir: Path, case_id: str, tag: str):\n    return cache_dir / f\"{case_id}_{tag}.npz\"\n\ndef load_cached(cache_dir: Path, case_id: str, tag: str):\n    p = cache_path(cache_dir, case_id, tag)\n    if not p.exists():\n        return None\n    z = np.load(p, allow_pickle=False)\n    pack = z[\"mask_pack\"].astype(np.uint8).reshape(-1)\n    mh = int(z[\"mask_h\"]); mw = int(z[\"mask_w\"])\n    info = {k: float(z[k]) for k in z.files if k not in (\"mask_pack\",\"mask_h\",\"mask_w\")}\n    return pack, mh, mw, info\n\ndef save_cached(cache_dir: Path, case_id: str, tag: str, mask_u8: np.ndarray, info: dict):\n    pack, mh, mw = pack_mask(mask_u8)\n    payload = {\n        \"mask_pack\": pack,\n        \"mask_h\": np.int32(mh),\n        \"mask_w\": np.int32(mw),\n        \"p_raw\": np.float32(float(info.get(\"p_raw\", 0.0))),\n        \"p_cal\": np.float32(float(info.get(\"p_cal\", 0.0))),\n        \"pred_patches\": np.float32(float(info.get(\"pred_patches\", 0.0))),\n        \"area_frac\": np.float32(float(info.get(\"area_frac\", 0.0))),\n        \"n_comp\": np.float32(float(info.get(\"n_comp\", 0.0))),\n        \"mean_conf\": np.float32(float(info.get(\"mean_conf\", 0.0))),\n        \"side\": np.float32(float(info.get(\"side\", 0.0))),\n    }\n    np.savez_compressed(cache_path(cache_dir, case_id, tag), **payload)\n\n# ----------------------------\n# Inference core (supports mean-state or exact fold ensemble)\n# ----------------------------\ndef build_model_on_device(dino_dir: str, device: torch.device):\n    backbone = AutoModel.from_pretrained(str(dino_dir), local_files_only=True).eval()\n    freeze_all(backbone)\n    model = DinoMultiTask(backbone, patch=patch_size).eval().to(device)\n    return model\n\ndef infer_batch(model, x_batch, use_amp=True):\n    device = next(model.parameters()).device\n    x_batch = x_batch.to(device, non_blocking=True)\n    with torch.inference_mode():\n        if use_amp and device.type == \"cuda\":\n            with torch.cuda.amp.autocast(True):\n                cls_logit, seg_logit = model(x_batch)\n        else:\n            cls_logit, seg_logit = model(x_batch)\n    p_raw = torch.sigmoid(cls_logit).detach().float().cpu().numpy().astype(np.float32)\n    seg_prob = torch.sigmoid(seg_logit).detach().float().cpu().numpy().astype(np.float32)  # [B,gh,gw]\n    return p_raw, seg_prob\n\ndef infer_with_mean_state(image_paths, metas, side: int, batch_size: int, cache_dir: Path, tag: str):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = build_model_on_device(model_cfg[\"dino_dir\"], device)\n\n    # build mean state once\n    states = [load_trainable_state(p) for p in fold_ckpts]\n    mean_state = average_states(states)\n    apply_trainable_state(model, mean_state)\n\n    # optional: half on cuda\n    if device.type == \"cuda\":\n        model = model.half()\n\n    n = len(image_paths)\n    p_raw_all = np.zeros(n, dtype=np.float32)\n    seg_prob_all = None  # store per item while saving cache\n\n    # process in batches\n    i = 0\n    while i < n:\n        j = min(i + batch_size, n)\n        xb = []\n        mb = metas[i:j]\n        for k in range(i, j):\n            x, _ = load_image_square(image_paths[k], size=side)\n            if x is None:\n                x = torch.zeros((3, side, side), dtype=torch.float32)\n            xb.append(x)\n        xb = torch.stack(xb, dim=0)\n        if device.type == \"cuda\":\n            xb = xb.half()\n        p_raw, seg_prob = infer_batch(model, xb, use_amp=True)\n        p_raw_all[i:j] = p_raw\n\n        # per item: threshold seg -> mask -> post-filter -> cache\n        p_cal = apply_calibrator(p_raw)\n\n        gh = side // patch_size\n        gw = side // patch_size\n        for t in range(j - i):\n            meta = mb[t]\n            cid = str(meta[\"case_id\"])\n            orig_h = int(meta[\"orig_h\"]); orig_w = int(meta[\"orig_w\"])\n            seg = seg_prob[t]  # [gh,gw]\n            grid = (seg >= thr_mask).astype(np.uint8)\n            pred_patches = int(grid.sum())\n\n            mask = grid_to_mask_orig(grid, meta={\"orig_h\": orig_h, \"orig_w\": orig_w, \"side\": side}, patch=patch_size)\n\n            # post-filter: keep stable; set minimal tiny filter\n            mask2, comp = filter_mask(mask, min_area_frac=0.0, keep_topk=10, close_ks=3, open_ks=0)\n\n            area = float(mask2.sum())\n            area_frac = float(area / (float(orig_h*orig_w) + 1e-9))\n            mean_conf = mean_conf_inside(seg, grid)\n\n            info = {\n                \"p_raw\": float(p_raw[t]),\n                \"p_cal\": float(p_cal[t]),\n                \"pred_patches\": float(pred_patches),\n                \"area_frac\": float(area_frac),\n                \"n_comp\": float(comp.get(\"n_comp\", 0)),\n                \"mean_conf\": float(mean_conf),\n                \"side\": float(side),\n            }\n            save_cached(cache_dir, cid, tag, mask2.astype(np.uint8), info)\n\n        i = j\n        if (i % max(100, batch_size*25)) == 0:\n            print(f\"[{tag}] infer+cache {i:,}/{n:,}\")\n\n    # cleanup\n    del model\n    gc.collect()\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n\ndef infer_with_exact_fold_ensemble(image_paths, metas, side: int, batch_size: int, cache_dir: Path, tag: str):\n    # exact: average outputs across folds (slower)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = build_model_on_device(model_cfg[\"dino_dir\"], device)\n    if device.type == \"cuda\":\n        model = model.half()\n\n    n = len(image_paths)\n    # accumulator\n    p_raw_sum = np.zeros(n, dtype=np.float32)\n    seg_sum = np.zeros((n, side//patch_size, side//patch_size), dtype=np.float32)\n\n    for fi, ckpt_path in enumerate(fold_ckpts, 1):\n        st = load_trainable_state(ckpt_path)\n        apply_trainable_state(model, st)\n\n        i = 0\n        while i < n:\n            j = min(i + batch_size, n)\n            xb = []\n            mb = metas[i:j]\n            for k in range(i, j):\n                x, _ = load_image_square(image_paths[k], size=side)\n                if x is None:\n                    x = torch.zeros((3, side, side), dtype=torch.float32)\n                xb.append(x)\n            xb = torch.stack(xb, dim=0)\n            if device.type == \"cuda\":\n                xb = xb.half()\n            p_raw, seg_prob = infer_batch(model, xb, use_amp=True)\n            p_raw_sum[i:j] += p_raw\n            seg_sum[i:j] += seg_prob\n            i = j\n\n        print(f\"[{tag}] fold {fi}/{len(fold_ckpts)} done\")\n\n    p_raw_avg = p_raw_sum / float(len(fold_ckpts))\n    seg_avg = seg_sum / float(len(fold_ckpts))\n    p_cal = apply_calibrator(p_raw_avg)\n\n    # write cache\n    gh = side // patch_size\n    gw = side // patch_size\n    for idx in range(n):\n        meta = metas[idx]\n        cid = str(meta[\"case_id\"])\n        orig_h = int(meta[\"orig_h\"]); orig_w = int(meta[\"orig_w\"])\n        seg = seg_avg[idx]\n        grid = (seg >= thr_mask).astype(np.uint8)\n        pred_patches = int(grid.sum())\n\n        mask = grid_to_mask_orig(grid, meta={\"orig_h\": orig_h, \"orig_w\": orig_w, \"side\": side}, patch=patch_size)\n        mask2, comp = filter_mask(mask, min_area_frac=0.0, keep_topk=10, close_ks=3, open_ks=0)\n\n        area = float(mask2.sum())\n        area_frac = float(area / (float(orig_h*orig_w) + 1e-9))\n        mean_conf = mean_conf_inside(seg, grid)\n\n        info = {\n            \"p_raw\": float(p_raw_avg[idx]),\n            \"p_cal\": float(p_cal[idx]),\n            \"pred_patches\": float(pred_patches),\n            \"area_frac\": float(area_frac),\n            \"n_comp\": float(comp.get(\"n_comp\", 0)),\n            \"mean_conf\": float(mean_conf),\n            \"side\": float(side),\n        }\n        save_cached(cache_dir, cid, tag, mask2.astype(np.uint8), info)\n\n    del model\n    gc.collect()\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n\n# ----------------------------\n# Build meta list + load from cache (PASS-1)\n# ----------------------------\nt0 = time.time()\n\nmetas = []\nneed_p1 = []\nfor i, row in df_test.iterrows():\n    cid = str(row[\"case_id\"])\n    ip = str(row[\"image_path\"])\n    if not Path(ip).exists():\n        metas.append({\"case_id\": cid, \"image_path\": ip, \"orig_h\": 1, \"orig_w\": 1})\n        continue\n    im = Image.open(ip)\n    ow, oh = im.size\n    im.close()\n    metas.append({\"case_id\": cid, \"image_path\": ip, \"orig_h\": int(oh), \"orig_w\": int(ow)})\n\n    c = load_cached(P1_DIR, cid, tag=f\"s{PASS1_SIZE}\")\n    if c is None:\n        need_p1.append(i)\n\nprint(f\"\\nPASS-1 cache check: need_compute={len(need_p1):,}/{len(df_test):,}\")\n\n# Compute missing PASS-1 caches\nif len(need_p1) > 0:\n    idxs = need_p1\n    img_paths = [metas[i][\"image_path\"] for i in idxs]\n    meta_sub  = [dict(metas[i], case_id=str(metas[i][\"case_id\"])) for i in idxs]\n    # batch size auto reduce on OOM\n    bs = int(PASS1_BS)\n    while True:\n        try:\n            if EXACT_FOLD_ENSEMBLE:\n                infer_with_exact_fold_ensemble(img_paths, meta_sub, side=PASS1_SIZE, batch_size=bs, cache_dir=P1_DIR, tag=f\"s{PASS1_SIZE}\")\n            else:\n                infer_with_mean_state(img_paths, meta_sub, side=PASS1_SIZE, batch_size=bs, cache_dir=P1_DIR, tag=f\"s{PASS1_SIZE}\")\n            break\n        except RuntimeError as e:\n            if \"out of memory\" in str(e).lower() and bs > 1:\n                bs = max(1, bs // 2)\n                print(f\"[OOM] Reduce PASS1_BS -> {bs}\")\n                gc.collect()\n                if torch.cuda.is_available():\n                    torch.cuda.empty_cache()\n                continue\n            raise\n\n# Load PASS-1 info for all\np1_pack = [None]*len(df_test)\np1_hw   = [None]*len(df_test)\np1_info = [None]*len(df_test)\n\nmiss_p1 = 0\nfor i, row in df_test.iterrows():\n    cid = str(row[\"case_id\"])\n    c = load_cached(P1_DIR, cid, tag=f\"s{PASS1_SIZE}\")\n    if c is None:\n        miss_p1 += 1\n        p1_pack[i] = np.zeros((0,), dtype=np.uint8)\n        p1_hw[i]   = (1,1)\n        p1_info[i] = {\"p_raw\":0.0,\"p_cal\":0.0,\"pred_patches\":0.0,\"area_frac\":0.0,\"n_comp\":0.0,\"mean_conf\":0.0,\"side\":float(PASS1_SIZE)}\n    else:\n        pack, mh, mw, info = c\n        p1_pack[i] = pack\n        p1_hw[i]   = (mh, mw)\n        p1_info[i] = info\n\nprint(f\"PASS-1 loaded. missing_after_compute={miss_p1:,}\")\n\n# ----------------------------\n# Borderline selection for PASS-2\n# ----------------------------\nborderline = []\nif USE_PASS2:\n    for i, row in df_test.iterrows():\n        cid = str(row[\"case_id\"])\n        ip  = str(row[\"image_path\"])\n        if not Path(ip).exists():\n            continue\n\n        p = float(p1_info[i].get(\"p_cal\", 0.0))\n        area = float(p1_info[i].get(\"area_frac\", 0.0))\n        pp = int(round(float(p1_info[i].get(\"pred_patches\", 0.0))))\n        # borderline conditions (smart)\n        near_thr = (abs(p - thr_forged) <= float(BORDER_MARGIN))\n        repair_small = (p >= (thr_forged - 0.06)) and (pp < max(min_pred_patches, 2)) and (area < 0.0012)\n        recover_fn = (p >= (thr_forged - 0.10)) and (pp >= max(min_pred_patches-1, 1)) and (area >= 0.00025)\n        if (near_thr or repair_small or recover_fn):\n            borderline.append((cid, abs(p - thr_forged)))\n\n    borderline.sort(key=lambda x: x[1])\n    if MAX_BORDERLINE is not None and len(borderline) > int(MAX_BORDERLINE):\n        borderline = borderline[:int(MAX_BORDERLINE)]\n    borderline_ids = [x[0] for x in borderline]\nelse:\n    borderline_ids = []\n\nprint(f\"Borderline for PASS-2: {len(borderline_ids):,}/{len(df_test):,}\")\n\n# Compute missing PASS-2 caches for borderline only\nif USE_PASS2 and len(borderline_ids) > 0:\n    need_p2 = []\n    id_to_index = {str(df_test.iloc[i][\"case_id\"]): i for i in range(len(df_test))}\n    for cid in borderline_ids:\n        if load_cached(P2_DIR, cid, tag=f\"s{PASS2_SIZE}\") is None:\n            need_p2.append(cid)\n\n    print(f\"PASS-2 cache check: need_compute={len(need_p2):,}/{len(borderline_ids):,}\")\n\n    if len(need_p2) > 0:\n        idxs = [id_to_index[cid] for cid in need_p2]\n        img_paths = [metas[i][\"image_path\"] for i in idxs]\n        meta_sub  = [dict(metas[i], case_id=str(metas[i][\"case_id\"])) for i in idxs]\n        bs = int(PASS2_BS)\n        while True:\n            try:\n                if EXACT_FOLD_ENSEMBLE:\n                    infer_with_exact_fold_ensemble(img_paths, meta_sub, side=PASS2_SIZE, batch_size=bs, cache_dir=P2_DIR, tag=f\"s{PASS2_SIZE}\")\n                else:\n                    infer_with_mean_state(img_paths, meta_sub, side=PASS2_SIZE, batch_size=bs, cache_dir=P2_DIR, tag=f\"s{PASS2_SIZE}\")\n                break\n            except RuntimeError as e:\n                if \"out of memory\" in str(e).lower() and bs > 1:\n                    bs = max(1, bs // 2)\n                    print(f\"[OOM] Reduce PASS2_BS -> {bs}\")\n                    gc.collect()\n                    if torch.cuda.is_available():\n                        torch.cuda.empty_cache()\n                    continue\n                raise\n\n# ----------------------------\n# Smart ensemble P1 vs P2 + Strict guard + Export\n# ----------------------------\ndef iou_masks(m1: np.ndarray, m2: np.ndarray):\n    inter = float(np.logical_and(m1 > 0, m2 > 0).sum())\n    uni = float(np.logical_or(m1 > 0, m2 > 0).sum()) + 1e-9\n    return inter/uni\n\nresults = []\nn_pred_forg = 0\nn_used_p2 = 0\nn_union = 0\nn_inter = 0\n\nfor i, row in df_test.iterrows():\n    cid = str(row[\"case_id\"])\n    ip  = str(row[\"image_path\"])\n\n    # PASS-1 info\n    info1 = p1_info[i]\n    mh1, mw1 = p1_hw[i]\n    pcal1 = float(info1.get(\"p_cal\", 0.0))\n    area1 = float(info1.get(\"area_frac\", 0.0))\n    pp1   = int(round(float(info1.get(\"pred_patches\", 0.0))))\n    nc1   = float(info1.get(\"n_comp\", 0.0))\n    mc1   = float(info1.get(\"mean_conf\", 0.0))\n\n    g1 = strict_guard(pcal1, pp1, area1)\n    q1 = quality_score(pcal1, area1, nc1, mc1)\n\n    final_source = \"p1\"\n    final_guard = g1\n    final_mask = None\n    final_pcal = pcal1\n    final_q = q1\n\n    # PASS-2 available?\n    use_p2 = False\n    if USE_PASS2 and (cid in set(borderline_ids)) and Path(ip).exists():\n        c2 = load_cached(P2_DIR, cid, tag=f\"s{PASS2_SIZE}\")\n        if c2 is not None:\n            use_p2 = True\n            pack2, mh2, mw2, info2 = c2\n            pcal2 = float(info2.get(\"p_cal\", 0.0))\n            area2 = float(info2.get(\"area_frac\", 0.0))\n            pp2   = int(round(float(info2.get(\"pred_patches\", 0.0))))\n            nc2   = float(info2.get(\"n_comp\", 0.0))\n            mc2   = float(info2.get(\"mean_conf\", 0.0))\n\n            g2 = strict_guard(pcal2, pp2, area2)\n            q2 = quality_score(pcal2, area2, nc2, mc2)\n\n            # decision rules (stronger + stable)\n            if g2 and (not g1):\n                final_source = \"p2\"; final_guard = True; final_pcal = pcal2; final_q = q2\n                final_mask = unpack_mask(pack2, mh2, mw2)\n                n_used_p2 += 1\n            elif g1 and (not g2):\n                final_source = \"p1\"\n            else:\n                if g1 and g2:\n                    # compare masks\n                    m1 = unpack_mask(p1_pack[i], mh1, mw1)\n                    m2 = unpack_mask(pack2, mh2, mw2)\n                    iou = iou_masks(m1, m2)\n\n                    strong1 = (pcal1 >= thr_forged + 0.12) and (mc1 >= 0.60)\n                    strong2 = (pcal2 >= thr_forged + 0.12) and (mc2 >= 0.60)\n\n                    if iou >= 0.18 and strong1 and strong2:\n                        mu = np.logical_or(m1 > 0, m2 > 0).astype(np.uint8)\n                        final_source = \"union\"; final_guard = True; final_pcal = max(pcal1, pcal2); final_q = max(q1, q2)\n                        final_mask = mu\n                        n_union += 1\n                        n_used_p2 += 1\n                    elif iou <= 0.06 and strong1 and strong2:\n                        mi = np.logical_and(m1 > 0, m2 > 0).astype(np.uint8)\n                        # re-check guard after intersection\n                        area_i = float(mi.sum()) / (float(mi.size) + 1e-9)\n                        pp_i = int(round((mi.sum() / (patch_size*patch_size)) / max(1.0, (PASS1_SIZE*PASS1_SIZE)/(patch_size*patch_size))))  # coarse proxy\n                        if strict_guard(max(pcal1, pcal2), max(pp1, pp2), area_i):\n                            final_source = \"inter\"; final_guard = True; final_pcal = max(pcal1, pcal2); final_q = max(q1, q2)\n                            final_mask = mi\n                            n_inter += 1\n                            n_used_p2 += 1\n                        else:\n                            # fallback best quality\n                            if q2 > q1 * 1.03:\n                                final_source = \"p2\"; final_guard = g2; final_pcal = pcal2; final_q = q2\n                                final_mask = m2\n                                n_used_p2 += 1\n                            else:\n                                final_source = \"p1\"\n                    else:\n                        if q2 > q1 * 1.05:\n                            final_source = \"p2\"; final_guard = g2; final_pcal = pcal2; final_q = q2\n                            final_mask = m2\n                            n_used_p2 += 1\n                        else:\n                            final_source = \"p1\"\n                else:\n                    # both not guarded: pick best quality if clearly better\n                    if q2 > q1 * 1.12:\n                        final_source = \"p2\"; final_guard = g2; final_pcal = pcal2; final_q = q2\n                        final_mask = unpack_mask(pack2, mh2, mw2)\n                        n_used_p2 += 1\n                    else:\n                        final_source = \"p1\"\n\n    # final annotation\n    if final_guard:\n        if final_mask is None:\n            final_mask = unpack_mask(p1_pack[i], mh1, mw1)\n        rle = rle_encode(final_mask.astype(np.uint8), order=RLE_ORDER)\n        ann = rle if rle != \"\" else \"authentic\"\n        if ann != \"authentic\":\n            n_pred_forg += 1\n    else:\n        ann = \"authentic\"\n\n    results.append({\"case_id\": cid, \"annotation\": ann})\n\ndf_sub = pd.DataFrame(results)\ndf_sub = df_sample[[\"case_id\"]].merge(df_sub, on=\"case_id\", how=\"left\")\ndf_sub[\"annotation\"] = df_sub[\"annotation\"].fillna(\"authentic\").astype(str)\n\ndf_sub.to_csv(OUT_SUB_PATH, index=False)\ndf_sub.to_csv(OUT_COPY_PATH, index=False)\n\ndt = time.time() - t0\nprint(\"\\nDONE.\")\nprint(f\"submission.csv -> {OUT_SUB_PATH}\")\nprint(f\"copy          -> {OUT_COPY_PATH}\")\nprint(f\"elapsed_s     -> {dt:.1f}\")\nprint(f\"pred_forged   -> {n_pred_forg:,}/{len(df_sub):,}\")\nprint(f\"used_pass2    -> {n_used_p2:,} | union={n_union:,} | inter={n_inter:,}\")\nprint(df_sub.head())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}