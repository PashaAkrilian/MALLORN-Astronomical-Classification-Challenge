{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":113558,"databundleVersionId":14878066,"sourceType":"competition"},{"sourceId":14387840,"sourceType":"datasetVersion","datasetId":9171323},{"sourceId":4535,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":3327,"modelId":986},{"sourceId":4537,"sourceType":"modelInstanceVersion","modelInstanceId":3329,"modelId":986}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Set Paths & Select Config (CFG)","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 0 — Set Paths & Select Config (CFG) (Kaggle-ready, offline) — REVISI FULL (anti-error)\n# - English step name, Indonesian explanations.\n#\n# Tujuan:\n# - Deteksi root kompetisi (COMP_ROOT)\n# - Deteksi root output dataset hasil PREP (OUT_DS_ROOT) + OUT_ROOT (= .../recodai_luc)\n# - Auto-pilih CFG terbaik untuk MATCH + PRED (berdasarkan coverage rows features train)\n# - Deteksi CFG DINO cache (opsional) + simpan path model DINOv2-LARGE offline\n#\n# Output globals (dipakai step berikutnya, JANGAN diganti namanya):\n# - COMP_ROOT, OUT_DS_ROOT, OUT_ROOT\n# - PATHS (dict jalur penting)\n# - MATCH_CFG_DIR, PRED_CFG_DIR, DINO_CFG_DIR\n# ============================================================\n\nimport os, re, json\nfrom pathlib import Path\nimport pandas as pd\n\n# ----------------------------\n# Helper: find competition root\n# ----------------------------\ndef find_comp_root(preferred: str = \"/kaggle/input/recodai-luc-scientific-image-forgery-detection\") -> Path:\n    p = Path(preferred)\n    if p.exists():\n        return p\n\n    base = Path(\"/kaggle/input\")\n    if not base.exists():\n        raise FileNotFoundError(\"/kaggle/input tidak ditemukan (pastikan kamu di Kaggle Notebook).\")\n\n    cands = []\n    for d in base.iterdir():\n        if not d.is_dir():\n            continue\n        # Heuristic kompetisi: ada sample_submission.csv dan folder train/test images\n        if (d / \"sample_submission.csv\").exists() and ((d / \"train_images\").exists() or (d / \"test_images\").exists()):\n            cands.append(d)\n\n    if not cands:\n        # fallback: cari yang nested satu-level\n        for d in base.iterdir():\n            if not d.is_dir():\n                continue\n            inner = [x for x in d.iterdir() if x.is_dir()]\n            for x in inner:\n                if (x / \"sample_submission.csv\").exists() and ((x / \"train_images\").exists() or (x / \"test_images\").exists()):\n                    cands.append(x)\n\n    if not cands:\n        raise FileNotFoundError(\n            \"COMP_ROOT tidak ditemukan. Harus ada folder yang memuat sample_submission.csv dan train_images/test_images.\"\n        )\n\n    # prefer yang mengandung kata kunci\n    cands.sort(key=lambda x: ((\"recodai\" not in x.name.lower()), (\"forgery\" not in x.name.lower()), x.name))\n    return cands[0]\n\n# ----------------------------\n# Helper: find output dataset root (hasil PREP)\n# ----------------------------\ndef find_output_dataset_root(preferred_names=(\n    \"recod-ailuc-dinov2-base\",\n    \"recod-ai-luc-dinov2-base\",\n    \"recodai-luc-dinov2-base\",\n    \"recodai-luc-dinov2\",\n    \"recodai-luc-dinov2-prep\",\n)) -> Path:\n    base = Path(\"/kaggle/input\")\n\n    # direct hit\n    for nm in preferred_names:\n        p = base / nm\n        if p.exists():\n            return p\n\n    # scan: cari yang punya recodai_luc/artifacts\n    cands = []\n    for d in base.iterdir():\n        if not d.is_dir():\n            continue\n        if (d / \"recodai_luc\" / \"artifacts\").exists():\n            cands.append(d)\n            continue\n        inner = list(d.glob(\"*/recodai_luc/artifacts\"))\n        if inner:\n            cands.append(d)\n\n    if not cands:\n        raise FileNotFoundError(\n            \"OUT_DS_ROOT tidak ditemukan. Harus ada /kaggle/input/<...>/recodai_luc/artifacts/\"\n        )\n\n    # prefer yang mengandung 'dinov2'\n    cands.sort(key=lambda x: ((\"dinov2\" not in x.name.lower()), x.name))\n    return cands[0]\n\n# ----------------------------\n# Helper: resolve OUT_ROOT = <dataset>/recodai_luc\n# ----------------------------\ndef resolve_out_root(out_ds_root: Path) -> Path:\n    direct = out_ds_root / \"recodai_luc\"\n    if direct.exists():\n        return direct\n    hits = list(out_ds_root.glob(\"*/recodai_luc\"))\n    if hits:\n        return hits[0]\n    raise FileNotFoundError(f\"Folder recodai_luc tidak ditemukan di bawah {out_ds_root}\")\n\n# ----------------------------\n# Helper: pick best cfg directory by train feature coverage (row count)\n# ----------------------------\ndef _fast_count_rows_csv(path: Path) -> int:\n    # hitung rows CSV (tanpa pandas) supaya cepat & hemat memori\n    try:\n        with path.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n            # -1 untuk header\n            n = sum(1 for _ in f) - 1\n        return int(max(n, 0))\n    except Exception:\n        return -1\n\ndef pick_best_cfg(cache_root: Path, prefix: str, feat_train_filename: str) -> Path:\n    \"\"\"\n    cache_root: .../recodai_luc/cache\n    prefix: contoh 'match_base_cfg_' atau 'pred_base'\n    feat_train_filename: contoh 'match_features_train_all.csv'\n    \"\"\"\n    if not cache_root.exists():\n        raise FileNotFoundError(f\"cache_root tidak ditemukan: {cache_root}\")\n\n    cands = []\n    for d in cache_root.iterdir():\n        if not d.is_dir():\n            continue\n        if not d.name.startswith(prefix):\n            continue\n        feat_path = d / feat_train_filename\n        if not feat_path.exists():\n            continue\n        n = _fast_count_rows_csv(feat_path)\n        cands.append((n, d, feat_path))\n\n    if not cands:\n        raise FileNotFoundError(\n            f\"Tidak ada CFG folder di {cache_root} dengan prefix='{prefix}' dan file '{feat_train_filename}'.\"\n        )\n\n    # pilih coverage terbesar, tie-break nama\n    cands.sort(key=lambda x: (-x[0], x[1].name))\n    best_n, best_dir, best_feat = cands[0]\n    return best_dir\n\n# ----------------------------\n# 0) Locate roots\n# ----------------------------\nCOMP_ROOT = find_comp_root(\"/kaggle/input/recodai-luc-scientific-image-forgery-detection\")\nOUT_DS_ROOT = find_output_dataset_root()\nOUT_ROOT = resolve_out_root(OUT_DS_ROOT)  # .../recodai_luc\n\nART_DIR = OUT_ROOT / \"artifacts\"\nCACHE_DIR = OUT_ROOT / \"cache\"\n\nif not ART_DIR.exists():\n    raise FileNotFoundError(f\"ART_DIR tidak ditemukan: {ART_DIR}\")\nif not CACHE_DIR.exists():\n    raise FileNotFoundError(f\"CACHE_DIR tidak ditemukan: {CACHE_DIR}\")\n\n# ----------------------------\n# 1) Competition paths (raw images/masks)\n# ----------------------------\nPATHS = {}\nPATHS[\"COMP_ROOT\"] = str(COMP_ROOT)\nPATHS[\"SAMPLE_SUB\"] = str(COMP_ROOT / \"sample_submission.csv\")\n\nPATHS[\"TRAIN_IMAGES\"] = str(COMP_ROOT / \"train_images\")\nPATHS[\"TEST_IMAGES\"]  = str(COMP_ROOT / \"test_images\")\nPATHS[\"TRAIN_MASKS\"]  = str(COMP_ROOT / \"train_masks\")\nPATHS[\"SUPP_IMAGES\"]  = str(COMP_ROOT / \"supplemental_images\")\nPATHS[\"SUPP_MASKS\"]   = str(COMP_ROOT / \"supplemental_masks\")\n\n# opsional: jika train_images dibagi authentic/forged\nPATHS[\"TRAIN_AUTH_DIR\"] = str(COMP_ROOT / \"train_images\" / \"authentic\")\nPATHS[\"TRAIN_FORG_DIR\"] = str(COMP_ROOT / \"train_images\" / \"forged\")\n\n# ----------------------------\n# 2) Output dataset paths (clean artifacts + cache)\n# ----------------------------\nPATHS[\"OUT_DS_ROOT\"] = str(OUT_DS_ROOT)\nPATHS[\"OUT_ROOT\"]    = str(OUT_ROOT)\nPATHS[\"ART_DIR\"]     = str(ART_DIR)\nPATHS[\"CACHE_DIR\"]   = str(CACHE_DIR)\n\n# artifacts utama\nPATHS[\"DF_TRAIN_ALL\"] = str(ART_DIR / \"df_train_all.parquet\")\nPATHS[\"DF_TRAIN_CLS\"] = str(ART_DIR / \"df_train_cls.parquet\")\nPATHS[\"DF_TRAIN_SEG\"] = str(ART_DIR / \"df_train_seg.parquet\")\nPATHS[\"DF_TEST\"]      = str(ART_DIR / \"df_test.parquet\")\n\nPATHS[\"CV_CASE_FOLDS\"]   = str(ART_DIR / \"cv_case_folds.csv\")\nPATHS[\"CV_SAMPLE_FOLDS\"] = str(ART_DIR / \"cv_sample_folds.csv\")\n\nPATHS[\"IMG_PROFILE_TRAIN\"] = str(ART_DIR / \"image_profile_train.parquet\")\nPATHS[\"IMG_PROFILE_TEST\"]  = str(ART_DIR / \"image_profile_test.parquet\")\nPATHS[\"MASK_PROFILE\"]      = str(ART_DIR / \"mask_profile.parquet\")\nPATHS[\"CASE_SUMMARY\"]      = str(ART_DIR / \"case_summary.parquet\")\n\n# ----------------------------\n# 3) Select best MATCH/PRED CFG dirs automatically\n# ----------------------------\n# MATCH: match_base_cfg_<hash>/match_features_train_all.csv\nMATCH_CFG_DIR = pick_best_cfg(\n    CACHE_DIR,\n    prefix=\"match_base_cfg_\",\n    feat_train_filename=\"match_features_train_all.csv\",\n)\n\n# PRED: pred_base.../pred_features_train_all.csv\nPRED_CFG_DIR = pick_best_cfg(\n    CACHE_DIR,\n    prefix=\"pred_base\",\n    feat_train_filename=\"pred_features_train_all.csv\",\n)\n\n# DINO cache cfg (opsional): cache/dino_v2_large/cfg_*/manifest_train_all.csv\nDINO_CFG_DIR = None\ndino_root = CACHE_DIR / \"dino_v2_large\"\nif dino_root.exists():\n    dino_cands = []\n    for d in dino_root.iterdir():\n        if d.is_dir() and d.name.startswith(\"cfg_\") and (d / \"manifest_train_all.csv\").exists():\n            dino_cands.append(d)\n    if dino_cands:\n        # pilih yang paling \"lengkap\" berdasarkan rows manifest_train_all\n        scored = []\n        for d in dino_cands:\n            mf = d / \"manifest_train_all.csv\"\n            scored.append((_fast_count_rows_csv(mf), d))\n        scored.sort(key=lambda x: (-x[0], x[1].name))\n        DINO_CFG_DIR = scored[0][1]\n\n# simpan cfg dir ke PATHS\nPATHS[\"MATCH_CFG_DIR\"] = str(MATCH_CFG_DIR)\nPATHS[\"PRED_CFG_DIR\"]  = str(PRED_CFG_DIR)\nPATHS[\"DINO_CFG_DIR\"]  = str(DINO_CFG_DIR) if DINO_CFG_DIR else \"\"\n\n# feature paths dari cfg terpilih\nPATHS[\"MATCH_FEAT_TRAIN\"] = str(MATCH_CFG_DIR / \"match_features_train_all.csv\")\nPATHS[\"MATCH_FEAT_TEST\"]  = str(MATCH_CFG_DIR / \"match_features_test.csv\")\nPATHS[\"PRED_FEAT_TRAIN\"]  = str(PRED_CFG_DIR / \"pred_features_train_all.csv\")\nPATHS[\"PRED_FEAT_TEST\"]   = str(PRED_CFG_DIR / \"pred_features_test.csv\")\n\n# ----------------------------\n# 4) DINOv2-LARGE model path (offline) — dipakai step training/infer berikutnya\n# ----------------------------\nDINO_LARGE_DIR = Path(\"/kaggle/input/dinov2/pytorch/large/1\")\nPATHS[\"DINO_LARGE_DIR\"] = str(DINO_LARGE_DIR)\n\n# ----------------------------\n# 5) Sanity checks (wajib ada)\n# ----------------------------\nmust_exist = [\n    (\"sample_submission.csv\", PATHS[\"SAMPLE_SUB\"]),\n    (\"df_train_all.parquet\",  PATHS[\"DF_TRAIN_ALL\"]),\n    (\"cv_case_folds.csv\",     PATHS[\"CV_CASE_FOLDS\"]),\n    (\"match_features_train_all.csv\", PATHS[\"MATCH_FEAT_TRAIN\"]),\n    (\"pred_features_train_all.csv\",  PATHS[\"PRED_FEAT_TRAIN\"]),\n]\nmissing = [name for name, p in must_exist if not Path(p).exists()]\nif missing:\n    raise FileNotFoundError(\"Missing required files: \" + \", \".join(missing))\n\n# DINO model dir opsional tapi biasanya kamu butuh; jadi hanya warning (tidak hard fail)\nif not DINO_LARGE_DIR.exists():\n    print(f\"WARNING: DINOv2-Large dir tidak ditemukan: {DINO_LARGE_DIR} (kalau butuh backbone, pastikan input ada)\")\n\n# ----------------------------\n# 6) Print summary (konsisten dengan step-step kamu)\n# ----------------------------\nprint(\"OK — Roots\")\nprint(\"  COMP_ROOT   :\", COMP_ROOT)\nprint(\"  OUT_DS_ROOT :\", OUT_DS_ROOT)\nprint(\"  OUT_ROOT    :\", OUT_ROOT)\n\nprint(\"\\nOK — Selected CFG\")\nprint(\"  MATCH_CFG_DIR:\", MATCH_CFG_DIR.name)\nprint(\"  PRED_CFG_DIR :\", PRED_CFG_DIR.name)\nprint(\"  DINO_CFG_DIR :\", (DINO_CFG_DIR.name if DINO_CFG_DIR else \"(not found / optional)\"))\n\nprint(\"\\nOK — Key files\")\nfor k in [\"DF_TRAIN_ALL\", \"CV_CASE_FOLDS\", \"MATCH_FEAT_TRAIN\", \"PRED_FEAT_TRAIN\", \"IMG_PROFILE_TRAIN\"]:\n    p = Path(PATHS[k])\n    print(f\"  {k:16s}: {p}  {'(exists)' if p.exists() else '(missing/optional)'}\")\n\nprint(\"\\nOK — DINO model dir\")\nprint(\"  DINO_LARGE_DIR:\", DINO_LARGE_DIR, \"(exists)\" if DINO_LARGE_DIR.exists() else \"(missing)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:57:47.290162Z","iopub.execute_input":"2026-01-04T13:57:47.290513Z","iopub.status.idle":"2026-01-04T13:57:47.751165Z","shell.execute_reply.started":"2026-01-04T13:57:47.290482Z","shell.execute_reply":"2026-01-04T13:57:47.750276Z"}},"outputs":[{"name":"stdout","text":"OK — Roots\n  COMP_ROOT   : /kaggle/input/recodai-luc-scientific-image-forgery-detection\n  OUT_DS_ROOT : /kaggle/input/recod-ailuc-dinov2-base\n  OUT_ROOT    : /kaggle/input/recod-ailuc-dinov2-base/recodai_luc\n\nOK — Selected CFG\n  MATCH_CFG_DIR: match_base_cfg_f9f7ea3a65c5\n  PRED_CFG_DIR : pred_base_v3_v7_cfg_5dbf0aa165\n  DINO_CFG_DIR : cfg_3246fd54aab0\n\nOK — Key files\n  DF_TRAIN_ALL    : /kaggle/input/recod-ailuc-dinov2-base/recodai_luc/artifacts/df_train_all.parquet  (exists)\n  CV_CASE_FOLDS   : /kaggle/input/recod-ailuc-dinov2-base/recodai_luc/artifacts/cv_case_folds.csv  (exists)\n  MATCH_FEAT_TRAIN: /kaggle/input/recod-ailuc-dinov2-base/recodai_luc/cache/match_base_cfg_f9f7ea3a65c5/match_features_train_all.csv  (exists)\n  PRED_FEAT_TRAIN : /kaggle/input/recod-ailuc-dinov2-base/recodai_luc/cache/pred_base_v3_v7_cfg_5dbf0aa165/pred_features_train_all.csv  (exists)\n  IMG_PROFILE_TRAIN: /kaggle/input/recod-ailuc-dinov2-base/recodai_luc/artifacts/image_profile_train.parquet  (exists)\n\nOK — DINO model dir\n  DINO_LARGE_DIR: /kaggle/input/dinov2/pytorch/large/1 (exists)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Build Training Table (X, y, folds)","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STEP 2 — Build Training Table (X, y, folds) — REVISI FULL (Transformer-ready, robust)\n# - Fokus: siapkan df_train_tabular + FEATURE_COLS\n# - Sumber utama: pred_features + (opsional) match_features + (opsional) image_profile\n# - Split: gunakan cv_case_folds.csv (anti leakage, by case_id)\n# - Tidak ada submission di sini\n#\n# Output globals:\n# - df_train_tabular, FEATURE_COLS\n# - (opsional) X_train, y_train, folds (pandas series/df)\n#\n# Saved:\n# - /kaggle/working/recodai_luc_gate_artifacts/feature_cols.json\n# - /kaggle/working/recodai_luc_gate_artifacts/feature_schema.json\n# - /kaggle/working/recodai_luc_gate_artifacts/df_train_tabular.parquet\n# ============================================================\n\nimport os, json, math, gc, warnings\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\n\nwarnings.filterwarnings(\"ignore\")\n\n# ----------------------------\n# 0) Require PATHS\n# ----------------------------\nif \"PATHS\" not in globals() or not isinstance(PATHS, dict):\n    raise RuntimeError(\"Missing PATHS. Jalankan dulu STAGE 0 — Set Paths & Select Config (CFG).\")\n\n# ----------------------------\n# 1) Check DINOv2 Large local path (offline) (hanya cek exist)\n# ----------------------------\nDINO_LARGE_DIR = Path(PATHS.get(\"DINO_LARGE_DIR\", \"/kaggle/input/dinov2/pytorch/large/1\"))\nif not DINO_LARGE_DIR.exists():\n    raise FileNotFoundError(f\"DINOv2-Large path not found: {DINO_LARGE_DIR}\")\nPATHS[\"DINO_LARGE_DIR\"] = str(DINO_LARGE_DIR)\n\n# ----------------------------\n# 2) Feature Engineering Config (fleksibel)\n# ----------------------------\nFE_CFG = {\n    \"use_match_features\": True,\n    \"use_image_profile\": True,\n\n    \"add_log_features\": True,\n    \"add_interactions\": True,\n    \"drop_constant_features\": True,\n\n    # outlier control\n    \"clip_by_quantile\": True,\n    \"clip_q\": 0.999,              # p99.9 cap\n    \"clip_max_fallback\": 1e9,      # fallback cap jika quantile gagal\n\n    # fill\n    \"fillna_value\": 0.0,\n\n    # dtype\n    \"cast_float32\": True,\n}\n\n# ----------------------------\n# 3) Prefer WORKING features if exist (kalau kamu regen di /kaggle/working)\n# ----------------------------\ndef prefer_working(input_path: str, working_candidate: str | None = None) -> Path:\n    p_in = Path(input_path)\n    if working_candidate is not None:\n        p_w = Path(working_candidate)\n        if p_w.exists():\n            return p_w\n    return p_in\n\nmatch_cfg_name = Path(PATHS[\"MATCH_CFG_DIR\"]).name if PATHS.get(\"MATCH_CFG_DIR\") else \"\"\npred_cfg_name  = Path(PATHS[\"PRED_CFG_DIR\"]).name  if PATHS.get(\"PRED_CFG_DIR\") else \"\"\n\nWORK_ROOT = Path(\"/kaggle/working/recodai_luc/cache\")\nmatch_feat_work = WORK_ROOT / match_cfg_name / \"match_features_train_all.csv\"\npred_feat_work  = WORK_ROOT / pred_cfg_name  / \"pred_features_train_all.csv\"\n\nPRED_FEAT_TRAIN  = prefer_working(PATHS[\"PRED_FEAT_TRAIN\"],  str(pred_feat_work))\nMATCH_FEAT_TRAIN = prefer_working(PATHS[\"MATCH_FEAT_TRAIN\"], str(match_feat_work))\n\nDF_TRAIN_ALL      = Path(PATHS[\"DF_TRAIN_ALL\"])\nCV_CASE_FOLDS     = Path(PATHS[\"CV_CASE_FOLDS\"])\nIMG_PROFILE_TRAIN = Path(PATHS.get(\"IMG_PROFILE_TRAIN\", \"\"))\n\nfor need_name, need_path in [\n    (\"df_train_all.parquet\", DF_TRAIN_ALL),\n    (\"cv_case_folds.csv\", CV_CASE_FOLDS),\n    (\"pred_features_train_all.csv\", PRED_FEAT_TRAIN),\n]:\n    if not need_path.exists():\n        raise FileNotFoundError(f\"Missing required file: {need_name} -> {need_path}\")\n\nprint(\"Using:\")\nprint(\"  DF_TRAIN_ALL      :\", DF_TRAIN_ALL)\nprint(\"  CV_CASE_FOLDS     :\", CV_CASE_FOLDS)\nprint(\"  PRED_FEAT_TRAIN   :\", PRED_FEAT_TRAIN)\nprint(\"  MATCH_FEAT_TRAIN  :\", MATCH_FEAT_TRAIN, \"(optional)\" if MATCH_FEAT_TRAIN.exists() else \"(missing/skip)\")\nprint(\"  IMG_PROFILE_TRAIN :\", IMG_PROFILE_TRAIN, \"(optional)\" if IMG_PROFILE_TRAIN.exists() else \"(missing/skip)\")\nprint(\"  DINO_LARGE_DIR    :\", DINO_LARGE_DIR)\n\n# ----------------------------\n# 4) Load minimal inputs\n# ----------------------------\ndf_base = pd.read_parquet(DF_TRAIN_ALL)\ndf_cv   = pd.read_csv(CV_CASE_FOLDS)\ndf_pred = pd.read_csv(PRED_FEAT_TRAIN)\n\ndf_match = None\nif FE_CFG[\"use_match_features\"] and MATCH_FEAT_TRAIN.exists():\n    try:\n        df_match = pd.read_csv(MATCH_FEAT_TRAIN)\n    except Exception:\n        df_match = None\n\ndf_prof = None\nif FE_CFG[\"use_image_profile\"] and IMG_PROFILE_TRAIN.exists():\n    try:\n        df_prof = pd.read_parquet(IMG_PROFILE_TRAIN)\n    except Exception:\n        df_prof = None\n\n# ----------------------------\n# 5) Normalize keys: uid/sample_id, case_id, variant\n# ----------------------------\ndef ensure_uid_case_variant(df: pd.DataFrame) -> pd.DataFrame:\n    df = df.copy()\n\n    if \"uid\" not in df.columns:\n        for alt in [\"sample_id\", \"id\", \"key\"]:\n            if alt in df.columns:\n                df = df.rename(columns={alt: \"uid\"})\n                break\n    if \"uid\" not in df.columns:\n        raise ValueError(\"Cannot find uid/sample_id column. Expected 'uid' or 'sample_id'.\")\n\n    if (\"case_id\" not in df.columns) or (\"variant\" not in df.columns):\n        uid = df[\"uid\"].astype(str)\n        if \"case_id\" not in df.columns:\n            df[\"case_id\"] = uid.str.extract(r\"^(\\d+)\")[0].astype(\"Int64\")\n        if \"variant\" not in df.columns:\n            v  = uid.str.extract(r\"__(\\w+)$\")[0]\n            v2 = uid.str.extract(r\"_(\\w+)$\")[0]\n            df[\"variant\"] = v.fillna(v2).fillna(\"unk\")\n\n    # guard missing extraction\n    if df[\"case_id\"].isna().any():\n        raise ValueError(\"Failed to parse case_id from uid for some rows. Check uid format.\")\n\n    df[\"case_id\"] = df[\"case_id\"].astype(int)\n    df[\"variant\"] = df[\"variant\"].astype(str)\n    df[\"uid\"]     = df[\"uid\"].astype(str)\n    return df\n\ndf_pred = ensure_uid_case_variant(df_pred)\n\ndf_base2 = df_base.copy()\nif \"uid\" not in df_base2.columns:\n    if \"sample_id\" in df_base2.columns:\n        df_base2 = df_base2.rename(columns={\"sample_id\": \"uid\"})\n    elif (\"case_id\" in df_base2.columns and \"variant\" in df_base2.columns):\n        df_base2[\"uid\"] = df_base2[\"case_id\"].astype(str) + \"__\" + df_base2[\"variant\"].astype(str)\n\n# label detection\nlabel_col = None\nfor cand in [\"y_forged\", \"has_mask\", \"is_forged\", \"forged\"]:\n    if cand in df_base2.columns:\n        label_col = cand\n        break\nif label_col is None and \"y_forged\" in df_pred.columns:\n    label_col = \"y_forged\"\nif label_col is None:\n    raise ValueError(\"Cannot find label column in df_train_all/pred_features (y_forged/has_mask/is_forged/forged).\")\n\n# folds sanity\nif \"case_id\" not in df_cv.columns or \"fold\" not in df_cv.columns:\n    raise ValueError(\"cv_case_folds.csv must contain columns: case_id, fold\")\ndf_cv[\"case_id\"] = df_cv[\"case_id\"].astype(int)\ndf_cv[\"fold\"]    = df_cv[\"fold\"].astype(int)\n\n# ----------------------------\n# 6) Merge: start from df_pred (1 row per uid)\n# ----------------------------\ndf_train = df_pred.copy()\n\n# attach label\nif \"y_forged\" in df_train.columns:\n    df_train[\"y\"] = pd.to_numeric(df_train[\"y_forged\"], errors=\"coerce\")\nelse:\n    if \"uid\" in df_base2.columns:\n        df_train = df_train.merge(\n            df_base2[[\"uid\", label_col]].rename(columns={label_col: \"y\"}),\n            on=\"uid\",\n            how=\"left\",\n        )\n    else:\n        if {\"case_id\", \"variant\", label_col}.issubset(df_base2.columns):\n            df_train = df_train.merge(\n                df_base2[[\"case_id\", \"variant\", label_col]].rename(columns={label_col: \"y\"}),\n                on=[\"case_id\", \"variant\"],\n                how=\"left\",\n            )\n        else:\n            raise ValueError(\"Could not merge label from df_train_all (missing uid or case_id+variant).\")\n\n# guard y missing\nif df_train[\"y\"].isna().any():\n    miss = int(df_train[\"y\"].isna().sum())\n    raise ValueError(f\"Label merge produced NaN in y: {miss} rows. Check df_train_all vs pred_features alignment.\")\ndf_train[\"y\"] = df_train[\"y\"].astype(int)\n\n# attach folds\ndf_train = df_train.drop(columns=[\"fold\"], errors=\"ignore\").merge(df_cv[[\"case_id\",\"fold\"]], on=\"case_id\", how=\"left\")\nif df_train[\"fold\"].isna().any():\n    miss = int(df_train[\"fold\"].isna().sum())\n    raise ValueError(f\"Missing fold after merging cv_case_folds.csv: {miss} rows.\")\ndf_train[\"fold\"] = df_train[\"fold\"].astype(int)\n\n# optional: merge match features (only new cols)\nif df_match is not None:\n    df_match = ensure_uid_case_variant(df_match)\n    base_cols = set(df_train.columns)\n    new_cols = [c for c in df_match.columns if c not in base_cols]\n    keep_cols = [\"uid\"] + [c for c in new_cols if c not in [\"case_id\", \"variant\"]]\n    if len(keep_cols) > 1:\n        df_train = df_train.merge(df_match[keep_cols], on=\"uid\", how=\"left\")\n\n# optional: merge image profile by case_id\nif df_prof is not None and \"case_id\" in df_prof.columns:\n    df_prof2 = df_prof.copy()\n    df_prof2[\"case_id\"] = df_prof2[\"case_id\"].astype(int)\n    df_prof2 = df_prof2.drop_duplicates(\"case_id\")\n    clash = set(df_prof2.columns).intersection(df_train.columns)\n    clash -= {\"case_id\"}\n    if clash:\n        df_prof2 = df_prof2.rename(columns={c: f\"profile_{c}\" for c in clash})\n    df_train = df_train.merge(df_prof2, on=\"case_id\", how=\"left\")\n\n# ----------------------------\n# 7) Feature engineering (lebih kaya + stabil untuk Transformer)\n# ----------------------------\ndef safe_log1p(arr):\n    arr = np.asarray(arr, dtype=np.float64)\n    arr = np.where(np.isfinite(arr), arr, 0.0)\n    arr = np.clip(arr, 0.0, None)\n    return np.log1p(arr)\n\ndef get_clip_cap(series: pd.Series, q: float, fallback: float):\n    s = pd.to_numeric(series, errors=\"coerce\").astype(float)\n    s = s.replace([np.inf, -np.inf], np.nan).dropna()\n    if len(s) == 0:\n        return float(fallback)\n    s = s[s >= 0]\n    if len(s) == 0:\n        return float(fallback)\n    cap = float(s.quantile(q))\n    if (not np.isfinite(cap)) or (cap <= 0):\n        return float(fallback)\n    return float(cap)\n\n# heavy-tail candidates (akan dipakai kalau ada)\nHEAVY_COLS = [\n    \"peak_ratio\", \"best_weight\", \"best_count\",\n    \"n_pairs_thr\", \"n_pairs_mnn\", \"n_pairs\",\n    \"n_comp\", \"largest_comp\",\n    \"grid_area_frac\", \"mask_area_frac\", \"pred_area_frac\",\n    \"overmask_tighten_steps\",\n]\n\nclip_caps = {}\nif FE_CFG[\"clip_by_quantile\"]:\n    for c in HEAVY_COLS:\n        if c in df_train.columns:\n            clip_caps[c] = get_clip_cap(df_train[c], FE_CFG[\"clip_q\"], FE_CFG[\"clip_max_fallback\"])\n\n# log+cap features\nif FE_CFG[\"add_log_features\"]:\n    for c in HEAVY_COLS:\n        if c in df_train.columns:\n            cap = clip_caps.get(c, FE_CFG[\"clip_max_fallback\"])\n            x = pd.to_numeric(df_train[c], errors=\"coerce\").fillna(0.0).astype(float)\n            x = np.clip(x, 0.0, cap)\n            df_train[f\"{c}_cap\"] = x.astype(np.float32)\n            df_train[f\"log_{c}\"] = safe_log1p(x).astype(np.float32)\n\n# interaction features\nif FE_CFG[\"add_interactions\"]:\n    def getf(col, default=0.0):\n        if col in df_train.columns:\n            return pd.to_numeric(df_train[col], errors=\"coerce\").fillna(default).astype(float).values\n        return np.full(len(df_train), default, dtype=np.float64)\n\n    best_mean_sim = getf(\"best_mean_sim\", 0.0)\n    best_count    = getf(\"best_count\", 0.0)\n    grid_area     = getf(\"grid_area_frac\", 0.0)\n    has_peak      = getf(\"has_peak\", 0.0)\n    n_comp        = getf(\"n_comp\", 0.0)\n    largest_comp  = getf(\"largest_comp\", 0.0)\n\n    df_train[\"sim_x_count\"]   = (best_mean_sim * best_count).astype(np.float32)\n    df_train[\"area_x_sim\"]    = (grid_area * best_mean_sim).astype(np.float32)\n    df_train[\"area_x_count\"]  = (grid_area * best_count).astype(np.float32)\n    df_train[\"comp_density\"]  = (largest_comp / (1.0 + n_comp)).astype(np.float32)\n    df_train[\"comp_inv\"]      = (1.0 / (1.0 + n_comp)).astype(np.float32)\n\n    # mnn ratio\n    n_pairs_thr = getf(\"n_pairs_thr\", 0.0)\n    n_pairs_mnn = getf(\"n_pairs_mnn\", 0.0)\n    df_train[\"mnn_ratio\"] = (n_pairs_mnn / (1.0 + n_pairs_thr)).astype(np.float32)\n\n    # peak gating\n    if \"log_peak_ratio\" in df_train.columns:\n        df_train[\"has_peak_x_logpeak\"] = (has_peak * getf(\"log_peak_ratio\", 0.0)).astype(np.float32)\n    elif \"log_peak_ratio_cap\" in df_train.columns:\n        df_train[\"has_peak_x_logpeak\"] = (has_peak * getf(\"log_peak_ratio_cap\", 0.0)).astype(np.float32)\n    else:\n        df_train[\"has_peak_x_logpeak\"] = (has_peak * 0.0).astype(np.float32)\n\n# replace inf -> NaN (numeric)\nfor c in df_train.columns:\n    if pd.api.types.is_numeric_dtype(df_train[c]):\n        df_train[c] = df_train[c].replace([np.inf, -np.inf], np.nan)\n\n# ----------------------------\n# 8) Select feature columns (numeric only; exclude identifiers/labels/split)\n# ----------------------------\nTARGET_COLS = {\"y\", \"y_forged\", \"has_mask\", \"is_forged\", \"forged\"}\nSPLIT_COLS  = {\"fold\"}\nID_NUM_DROP = {\"case_id\"}  # numeric id jangan dipakai sebagai feature\n\nnum_cols = [c for c in df_train.columns if pd.api.types.is_numeric_dtype(df_train[c])]\nfeature_cols = [c for c in num_cols if c not in TARGET_COLS and c not in SPLIT_COLS and c not in ID_NUM_DROP]\n\n# fill NaN\ndf_train[feature_cols] = df_train[feature_cols].fillna(FE_CFG[\"fillna_value\"])\n\n# drop constant cols (stabil untuk Transformer)\nif FE_CFG[\"drop_constant_features\"]:\n    nun = df_train[feature_cols].nunique(dropna=False)\n    nonconst = nun[nun > 1].index.tolist()\n    dropped = sorted(set(feature_cols) - set(nonconst))\n    feature_cols = nonconst\nelse:\n    dropped = []\n\n# cast float32\nif FE_CFG[\"cast_float32\"]:\n    df_train[feature_cols] = df_train[feature_cols].astype(np.float32)\n\n# ----------------------------\n# 9) Final outputs\n# ----------------------------\ndf_train_tabular = df_train[[\"uid\",\"case_id\",\"variant\",\"fold\",\"y\"] + feature_cols].copy()\n\nX_train = df_train_tabular[feature_cols]\ny_train = df_train_tabular[\"y\"].astype(int)\nfolds   = df_train_tabular[\"fold\"].astype(int)\n\nprint(\"\\nOK — Training table built\")\nprint(\"  df_train_tabular:\", df_train_tabular.shape)\nprint(\"  X_train:\", X_train.shape, \"| y pos%:\", float(y_train.mean())*100.0)\nprint(\"  folds:\", int(folds.nunique()), \"unique folds\")\nprint(\"  feature_cols:\", int(len(feature_cols)))\nif dropped:\n    print(\"  dropped_constant_features:\", len(dropped))\n\n# quick sanity\nif X_train.shape[0] != y_train.shape[0]:\n    raise RuntimeError(\"X_train and y_train row mismatch\")\nif y_train.isna().any():\n    raise RuntimeError(\"y_train contains NaN\")\nif folds.isna().any():\n    raise RuntimeError(\"folds contains NaN\")\n\nFEATURE_COLS = list(feature_cols)\nprint(\"\\nFeature head:\", FEATURE_COLS[:20])\nprint(\"Feature tail:\", FEATURE_COLS[-10:])\n\n# ----------------------------\n# 10) Save reproducible schema (feature list + FE config + clip caps)\n# ----------------------------\nOUT_ART = Path(\"/kaggle/working/recodai_luc_gate_artifacts\")\nOUT_ART.mkdir(parents=True, exist_ok=True)\n\nwith open(OUT_ART / \"feature_cols.json\", \"w\") as f:\n    json.dump(FEATURE_COLS, f, indent=2)\n\nschema = {\n    \"fe_cfg\": FE_CFG,\n    \"clip_caps\": clip_caps,\n    \"dropped_constant_features\": dropped,\n    \"n_features\": int(len(FEATURE_COLS)),\n    \"example_feature_head\": FEATURE_COLS[:25],\n}\nwith open(OUT_ART / \"feature_schema.json\", \"w\") as f:\n    json.dump(schema, f, indent=2)\n\n# opsional: simpan table agar gampang resume\ndf_train_tabular.to_parquet(OUT_ART / \"df_train_tabular.parquet\", index=False)\n\nprint(f\"\\nSaved -> {OUT_ART/'feature_cols.json'}\")\nprint(f\"Saved -> {OUT_ART/'feature_schema.json'}\")\nprint(f\"Saved -> {OUT_ART/'df_train_tabular.parquet'}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:57:47.752914Z","iopub.execute_input":"2026-01-04T13:57:47.753453Z","iopub.status.idle":"2026-01-04T13:57:48.398903Z","shell.execute_reply.started":"2026-01-04T13:57:47.753413Z","shell.execute_reply":"2026-01-04T13:57:48.398102Z"}},"outputs":[{"name":"stdout","text":"Using:\n  DF_TRAIN_ALL      : /kaggle/input/recod-ailuc-dinov2-base/recodai_luc/artifacts/df_train_all.parquet\n  CV_CASE_FOLDS     : /kaggle/input/recod-ailuc-dinov2-base/recodai_luc/artifacts/cv_case_folds.csv\n  PRED_FEAT_TRAIN   : /kaggle/input/recod-ailuc-dinov2-base/recodai_luc/cache/pred_base_v3_v7_cfg_5dbf0aa165/pred_features_train_all.csv\n  MATCH_FEAT_TRAIN  : /kaggle/input/recod-ailuc-dinov2-base/recodai_luc/cache/match_base_cfg_f9f7ea3a65c5/match_features_train_all.csv (optional)\n  IMG_PROFILE_TRAIN : /kaggle/input/recod-ailuc-dinov2-base/recodai_luc/artifacts/image_profile_train.parquet (optional)\n  DINO_LARGE_DIR    : /kaggle/input/dinov2/pytorch/large/1\n\nOK — Training table built\n  df_train_tabular: (5176, 67)\n  X_train: (5176, 62) | y pos%: 54.07650695517774\n  folds: 5 unique folds\n  feature_cols: 62\n  dropped_constant_features: 6\n\nFeature head: ['has_peak', 'peak_ratio', 'best_weight', 'best_count', 'best_mean_sim', 'n_pairs_thr', 'n_pairs_mnn', 'best_inlier_ratio', 'best_weight_frac', 'inlier_ratio', 'pair_count', 'uniq_src', 'uniq_dst', 'mean_sim', 'thr_used', 'cnt_thr_used', 'relaxed_used', 'min_pairs_used', 'area_frac', 'n_comp']\nFeature tail: ['log_largest_comp', 'grid_area_frac_cap', 'log_grid_area_frac', 'sim_x_count', 'area_x_sim', 'area_x_count', 'comp_density', 'comp_inv', 'mnn_ratio', 'has_peak_x_logpeak']\n\nSaved -> /kaggle/working/recodai_luc_gate_artifacts/feature_cols.json\nSaved -> /kaggle/working/recodai_luc_gate_artifacts/feature_schema.json\nSaved -> /kaggle/working/recodai_luc_gate_artifacts/df_train_tabular.parquet\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Train Baseline Model (Leakage-Safe CV)","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# Step 3 — Train Baseline Model (Leakage-Safe CV)\n# - Baseline: mHC-FTTransformer (numeric tabular) + Sinkhorn (PDF mHC)\n# - CV: pakai kolom `fold` (by case_id)\n# - Output:\n#   * OOF probabilities\n#   * CV report (AUC, F1, Precision, Recall, LogLoss)\n#   * Simpan model per fold + model_full (torch .pt pack: state_dict + scaler + cfg)\n#\n# Implementasi ide PDF (mHC):\n# - Multi-stream residual mixing (n_streams = 4 default)\n# - H_res per-layer diproyeksikan ke doubly-stochastic (Birkhoff polytope) via Sinkhorn-Knopp (tmax=20)\n# - Gating factor alpha init 0.01 (awal dekat identity -> stabil)\n#\n# Kaggle-safe:\n# - Update hanya active stream (stream-0) tiap layer -> jauh lebih cepat\n# - AMP + grad accumulation (effective batch besar tanpa OOM)\n# - LR scheduler step ala tabel: decay di 0.8 & 0.9 progress\n# ============================================================\n\nimport json, gc, math, time, warnings\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\n\nwarnings.filterwarnings(\"ignore\")\n\nfrom IPython.display import display\nfrom sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, log_loss\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# ----------------------------\n# 0) Require outputs from Step 2\n# ----------------------------\nneed_vars = [\"df_train_tabular\", \"FEATURE_COLS\"]\nfor v in need_vars:\n    if v not in globals():\n        raise RuntimeError(f\"Missing `{v}`. Jalankan dulu Step 2 — Build Training Table (X, y, folds).\")\n\ndf_train_tabular = df_train_tabular.copy()\nFEATURE_COLS = list(FEATURE_COLS)\n\nrequired_cols = {\"uid\", \"case_id\", \"variant\", \"fold\", \"y\"}\nmissing_cols = [c for c in required_cols if c not in df_train_tabular.columns]\nif missing_cols:\n    raise ValueError(f\"df_train_tabular missing columns: {missing_cols}.\")\n\n# ----------------------------\n# 1) CFG (dua preset: SAFE vs STRONG)\n# ----------------------------\n# SAFE: cocok T4/P100; STRONG: kalau A100/H100 (atau kamu yakin VRAM kuat)\nCFG_SAFE = {\n    \"seed\": 2025,\n\n    # mHC (PDF)\n    \"n_streams\": 4,         # mHC/HC expansion rate n = 4 (sesuai tabel)\n    \"sinkhorn_tmax\": 20,    # sesuai PDF (praktikal)\n    \"alpha_init\": 0.01,     # sesuai tabel (awal dekat identity)\n\n    # model capacity (SAFE)\n    \"d_model\": 256,\n    \"n_layers\": 6,\n    \"n_heads\": 8,\n    \"ffn_mult\": 4,\n    \"dropout\": 0.15,\n    \"attn_dropout\": 0.10,\n\n    # training (effective batch besar via accum)\n    \"batch_size\": 256,      # micro-batch\n    \"accum_steps\": 2,       # effective batch = 512\n    \"epochs\": 50,\n\n    # AdamW ala tabel (yang relevan)\n    \"lr\": 3e-4,\n    \"betas\": (0.9, 0.95),\n    \"eps\": 1e-8,            # eps tabel 1e-20 terlalu ekstrem utk tabular kecil; ini lebih aman\n    \"weight_decay\": 5e-2,\n\n    # warmup + step decay (mirip tabel: step @ 0.8 & 0.9)\n    \"warmup_frac\": 0.10,\n    \"lr_decay_milestones\": (0.80, 0.90),\n    \"lr_decay_values\": (0.316, 0.10),  # multiplier piecewise setelah milestone\n\n    \"grad_clip\": 1.0,\n\n    # early stopping\n    \"early_stop_patience\": 10,\n    \"early_stop_min_delta\": 1e-4,\n\n    # report threshold (hanya report baseline)\n    \"report_thr\": 0.5,\n}\n\nCFG_STRONG = {\n    **CFG_SAFE,\n    \"d_model\": 384,\n    \"n_layers\": 8,\n    \"dropout\": 0.20,\n    \"epochs\": 70,\n    \"lr\": 2e-4,\n    \"weight_decay\": 7e-2,\n    \"batch_size\": 256,\n    \"accum_steps\": 2,\n}\n\n# pilih otomatis berdasarkan GPU memory (kalau ada)\nCFG = dict(CFG_SAFE)\nif torch.cuda.is_available():\n    try:\n        mem_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n        if mem_gb >= 30:\n            CFG = dict(CFG_STRONG)\n    except Exception:\n        pass\n\n# ----------------------------\n# 2) Seed + device\n# ----------------------------\ndef seed_everything(seed: int = 2025):\n    import random, os\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = False\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(int(CFG[\"seed\"]))\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nuse_amp = (device.type == \"cuda\")\nprint(\"Device:\", device, \"| AMP:\", use_amp, \"| CFG:\", (\"STRONG\" if CFG is CFG_STRONG else \"SAFE\"))\n\n# speed knobs\nif device.type == \"cuda\":\n    torch.backends.cuda.matmul.allow_tf32 = True\n    torch.backends.cudnn.allow_tf32 = True\ntry:\n    torch.set_float32_matmul_precision(\"high\")\nexcept Exception:\n    pass\n\n# ----------------------------\n# 3) Build arrays + guard\n# ----------------------------\nX = df_train_tabular[FEATURE_COLS].to_numpy(dtype=np.float32, copy=True)\ny = df_train_tabular[\"y\"].to_numpy(dtype=np.int64, copy=True)\nfolds = df_train_tabular[\"fold\"].to_numpy(dtype=np.int64, copy=True)\n\nif not np.isfinite(X).all():\n    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n\nn = len(df_train_tabular)\nunique_folds = sorted(pd.Series(folds).unique().tolist())\nn_folds = len(unique_folds)\nn_features = X.shape[1]\n\nprint(\"Setup:\")\nprint(\"  rows      :\", n)\nprint(\"  folds     :\", n_folds, \"|\", unique_folds)\nprint(\"  pos%      :\", float(y.mean()) * 100.0)\nprint(\"  n_features:\", n_features)\n\n# ----------------------------\n# 4) Dataset\n# ----------------------------\nclass TabDataset(Dataset):\n    def __init__(self, X, y=None):\n        self.X = torch.from_numpy(X.astype(np.float32))\n        self.y = None if y is None else torch.from_numpy(y.astype(np.int64))\n\n    def __len__(self):\n        return self.X.shape[0]\n\n    def __getitem__(self, idx):\n        if self.y is None:\n            return self.X[idx]\n        return self.X[idx], self.y[idx]\n\n# ----------------------------\n# 5) Normalization (leakage-safe: fit on train fold only)\n# ----------------------------\ndef fit_standardizer(X_tr: np.ndarray):\n    mu = X_tr.mean(axis=0, dtype=np.float64)\n    sig = X_tr.std(axis=0, dtype=np.float64)\n    sig = np.where(sig < 1e-8, 1.0, sig)\n    return mu.astype(np.float32), sig.astype(np.float32)\n\ndef apply_standardizer(X_in: np.ndarray, mu: np.ndarray, sig: np.ndarray):\n    return ((X_in - mu) / sig).astype(np.float32)\n\n# ----------------------------\n# 6) Metrics helpers\n# ----------------------------\ndef safe_auc(y_true, p):\n    if len(np.unique(y_true)) < 2:\n        return None\n    return float(roc_auc_score(y_true, p))\n\ndef safe_logloss(y_true, p):\n    p = np.clip(np.asarray(p, dtype=np.float64), 1e-6, 1-1e-6)\n    return float(log_loss(y_true, p, labels=[0, 1]))\n\n# ----------------------------\n# 7) PDF mHC: Sinkhorn projection (doubly-stochastic)\n# ----------------------------\ndef sinkhorn_doubly_stochastic(logits: torch.Tensor, tmax: int = 20, eps: float = 1e-6):\n    \"\"\"\n    logits: (n, n) unconstrained\n    return: (n, n) ~ doubly-stochastic via Sinkhorn-Knopp on exp(logits)\n    \"\"\"\n    # stabilize exp\n    z = logits - logits.max()\n    M = torch.exp(z)\n    for _ in range(int(tmax)):\n        M = M / (M.sum(dim=-1, keepdim=True) + eps)  # row norm\n        M = M / (M.sum(dim=-2, keepdim=True) + eps)  # col norm\n    return M\n\n# ----------------------------\n# 8) Model: RMSNorm (PDF uses RMSNorm in big transformers)\n# ----------------------------\nclass RMSNorm(nn.Module):\n    def __init__(self, d: int, eps: float = 1e-6):\n        super().__init__()\n        self.eps = eps\n        self.weight = nn.Parameter(torch.ones(d))\n\n    def forward(self, x):\n        # x: (..., d)\n        rms = x.pow(2).mean(dim=-1, keepdim=True).add(self.eps).rsqrt()\n        return x * rms * self.weight\n\n# ----------------------------\n# 9) Transformer block + mHC mixing (multi-stream)\n# ----------------------------\nclass MHCAttnBlock(nn.Module):\n    \"\"\"\n    Update only active stream-0, then mix all streams with H_res (mHC).\n    \"\"\"\n    def __init__(self, d_model, n_heads, ffn_mult, dropout, attn_dropout,\n                 n_streams=4, sinkhorn_tmax=20, alpha_init=0.01):\n        super().__init__()\n        self.n_streams = int(n_streams)\n        self.sinkhorn_tmax = int(sinkhorn_tmax)\n\n        self.norm1 = RMSNorm(d_model)\n        self.attn = nn.MultiheadAttention(d_model, n_heads, dropout=attn_dropout, batch_first=True)\n        self.drop1 = nn.Dropout(dropout)\n\n        self.norm2 = RMSNorm(d_model)\n        self.ffn = nn.Sequential(\n            nn.Linear(d_model, ffn_mult * d_model),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(ffn_mult * d_model, d_model),\n        )\n        self.drop2 = nn.Dropout(dropout)\n\n        # mHC params (PDF):\n        # raw logits -> Sinkhorn -> doubly-stochastic; then convex combine with Identity using alpha\n        self.h_logits = nn.Parameter(torch.zeros(self.n_streams, self.n_streams))\n        nn.init.zeros_(self.h_logits)\n\n        # alpha in (0,1), init alpha_init ~ 0.01\n        a0 = float(alpha_init)\n        a0 = min(max(a0, 1e-4), 1 - 1e-4)\n        self.alpha_logit = nn.Parameter(torch.log(torch.tensor(a0 / (1 - a0), dtype=torch.float32)))\n\n    def forward(self, streams):\n        # streams: (B, n_streams, S, D)\n        B, nS, S, D = streams.shape\n        assert nS == self.n_streams\n\n        # update only active stream 0\n        x = streams[:, 0]  # (B,S,D)\n\n        # self-attn (pre-norm)\n        x0 = x\n        q = self.norm1(x)\n        attn_out, _ = self.attn(q, q, q, need_weights=False)\n        x = x0 + self.drop1(attn_out)\n\n        # FFN (pre-norm)\n        x1 = x\n        h = self.norm2(x)\n        h = self.ffn(h)\n        x = x1 + self.drop2(h)\n\n        # put back\n        streams = streams.clone()\n        streams[:, 0] = x\n\n        # mHC mixing\n        H = sinkhorn_doubly_stochastic(self.h_logits, tmax=self.sinkhorn_tmax)  # (n,n)\n        alpha = torch.sigmoid(self.alpha_logit).to(dtype=streams.dtype)\n        I = torch.eye(self.n_streams, device=streams.device, dtype=streams.dtype)\n        Hres = (1.0 - alpha) * I + alpha * H.to(dtype=streams.dtype)\n\n        # mix across stream dimension\n        mixed = torch.einsum(\"ij,bjtd->bitd\", Hres, streams)\n        return mixed\n\nclass MHCFTTransformer(nn.Module):\n    def __init__(self, n_features,\n                 d_model=256, n_heads=8, n_layers=6, ffn_mult=4,\n                 dropout=0.15, attn_dropout=0.10,\n                 n_streams=4, sinkhorn_tmax=20, alpha_init=0.01):\n        super().__init__()\n        self.n_features = int(n_features)\n        self.d_model = int(d_model)\n\n        # numeric tokenization: x_f -> x_f * W_f + b_f\n        self.w = nn.Parameter(torch.randn(self.n_features, self.d_model) * 0.02)\n        self.b = nn.Parameter(torch.zeros(self.n_features, self.d_model))\n        self.feat_emb = nn.Parameter(torch.randn(self.n_features, self.d_model) * 0.02)\n\n        self.cls = nn.Parameter(torch.randn(1, 1, self.d_model) * 0.02)\n        self.in_drop = nn.Dropout(dropout)\n\n        self.blocks = nn.ModuleList([\n            MHCAttnBlock(\n                d_model=self.d_model,\n                n_heads=n_heads,\n                ffn_mult=ffn_mult,\n                dropout=dropout,\n                attn_dropout=attn_dropout,\n                n_streams=n_streams,\n                sinkhorn_tmax=sinkhorn_tmax,\n                alpha_init=alpha_init\n            )\n            for _ in range(int(n_layers))\n        ])\n\n        self.out_norm = RMSNorm(self.d_model)\n        self.head = nn.Sequential(\n            nn.Linear(self.d_model, self.d_model),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(self.d_model, 1),\n        )\n\n        self.n_streams = int(n_streams)\n\n    def forward(self, x):\n        # x: (B,F)\n        tok = x.unsqueeze(-1) * self.w.unsqueeze(0) + self.b.unsqueeze(0)   # (B,F,D)\n        tok = tok + self.feat_emb.unsqueeze(0)\n        B = tok.size(0)\n        cls = self.cls.expand(B, -1, -1)                                    # (B,1,D)\n        seq = torch.cat([cls, tok], dim=1)                                  # (B,1+F,D)\n        seq = self.in_drop(seq)\n\n        # init streams: replicate seq\n        streams = seq.unsqueeze(1).repeat(1, self.n_streams, 1, 1)          # (B,nS,S,D)\n\n        for blk in self.blocks:\n            streams = blk(streams)\n\n        z = streams[:, 0, 0]  # CLS from active stream\n        z = self.out_norm(z)\n        logit = self.head(z).squeeze(-1)\n        return logit\n\n# ----------------------------\n# 10) LR Scheduler: warmup + step decay (0.8 & 0.9)\n# ----------------------------\ndef make_warmup_step_scheduler(optimizer, total_steps: int, warmup_steps: int,\n                              milestones_frac=(0.8, 0.9), decay_values=(0.316, 0.1)):\n    m1 = int(float(milestones_frac[0]) * total_steps)\n    m2 = int(float(milestones_frac[1]) * total_steps)\n    d1 = float(decay_values[0])\n    d2 = float(decay_values[1])\n\n    def lr_lambda(step):\n        # warmup: 0 -> 1\n        if step < warmup_steps:\n            return float(step + 1) / float(max(1, warmup_steps))\n\n        # step decay piecewise (mirip tabel)\n        if step < m1:\n            mult = 1.0\n        elif step < m2:\n            mult = d1\n        else:\n            mult = d2\n        return mult\n\n    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n\n# ----------------------------\n# 11) Predict helper (handle batch=(xb,yb))\n# ----------------------------\n@torch.no_grad()\ndef predict_proba(model, loader):\n    model.eval()\n    probs = []\n    for batch in loader:\n        xb = batch[0] if isinstance(batch, (list, tuple)) else batch\n        xb = xb.to(device, non_blocking=True)\n        with torch.cuda.amp.autocast(enabled=use_amp):\n            logits = model(xb)\n            p = torch.sigmoid(logits)\n        probs.append(p.detach().cpu().numpy())\n    return np.concatenate(probs, axis=0).astype(np.float32)\n\n# ----------------------------\n# 12) Train one fold (AMP + grad accumulation + early stopping)\n# ----------------------------\ndef train_one_fold(X_tr, y_tr, X_va, y_va, cfg):\n    mu, sig = fit_standardizer(X_tr)\n    X_trn = apply_standardizer(X_tr, mu, sig)\n    X_van = apply_standardizer(X_va, mu, sig)\n\n    ds_tr = TabDataset(X_trn, y_tr)\n    ds_va = TabDataset(X_van, y_va)\n\n    dl_tr = DataLoader(\n        ds_tr, batch_size=int(cfg[\"batch_size\"]), shuffle=True,\n        num_workers=2, pin_memory=(device.type == \"cuda\"),\n        drop_last=False\n    )\n    dl_va = DataLoader(\n        ds_va, batch_size=int(cfg[\"batch_size\"]), shuffle=False,\n        num_workers=2, pin_memory=(device.type == \"cuda\"),\n        drop_last=False\n    )\n\n    model = MHCFTTransformer(\n        n_features=n_features,\n        d_model=int(cfg[\"d_model\"]),\n        n_heads=int(cfg[\"n_heads\"]),\n        n_layers=int(cfg[\"n_layers\"]),\n        ffn_mult=int(cfg[\"ffn_mult\"]),\n        dropout=float(cfg[\"dropout\"]),\n        attn_dropout=float(cfg[\"attn_dropout\"]),\n        n_streams=int(cfg[\"n_streams\"]),\n        sinkhorn_tmax=int(cfg[\"sinkhorn_tmax\"]),\n        alpha_init=float(cfg[\"alpha_init\"]),\n    ).to(device)\n\n    # imbalance weight\n    pos = int(y_tr.sum())\n    neg = int(len(y_tr) - pos)\n    pos_weight = float(neg / max(1, pos))\n    loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight], device=device))\n\n    opt = torch.optim.AdamW(\n        model.parameters(),\n        lr=float(cfg[\"lr\"]),\n        betas=tuple(cfg[\"betas\"]),\n        eps=float(cfg[\"eps\"]),\n        weight_decay=float(cfg[\"weight_decay\"]),\n    )\n\n    accum_steps = max(1, int(cfg.get(\"accum_steps\", 1)))\n    optim_steps_per_epoch = int(math.ceil(len(dl_tr) / accum_steps))\n    total_optim_steps = int(cfg[\"epochs\"]) * max(1, optim_steps_per_epoch)\n    warmup_steps = int(float(cfg[\"warmup_frac\"]) * total_optim_steps)\n\n    sch = make_warmup_step_scheduler(\n        opt,\n        total_steps=total_optim_steps,\n        warmup_steps=warmup_steps,\n        milestones_frac=cfg[\"lr_decay_milestones\"],\n        decay_values=cfg[\"lr_decay_values\"],\n    )\n\n    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n\n    best = {\"val_logloss\": 1e9, \"epoch\": -1}\n    best_state = None\n    bad = 0\n\n    global_step = 0\n\n    for epoch in range(int(cfg[\"epochs\"])):\n        model.train()\n        t0 = time.time()\n        loss_sum = 0.0\n        n_sum = 0\n\n        opt.zero_grad(set_to_none=True)\n\n        micro_step = 0\n        optim_step_in_epoch = 0\n\n        for batch in dl_tr:\n            xb, yb = batch\n            xb = xb.to(device, non_blocking=True)\n            yb = yb.to(device, non_blocking=True).float()\n\n            with torch.cuda.amp.autocast(enabled=use_amp):\n                logits = model(xb)\n                loss = loss_fn(logits, yb)\n                loss = loss / accum_steps\n\n            scaler.scale(loss).backward()\n            micro_step += 1\n\n            loss_sum += float(loss.item()) * xb.size(0) * accum_steps  # undo divide for logging\n            n_sum += xb.size(0)\n\n            if (micro_step % accum_steps) == 0:\n                if cfg[\"grad_clip\"] and float(cfg[\"grad_clip\"]) > 0:\n                    scaler.unscale_(opt)\n                    torch.nn.utils.clip_grad_norm_(model.parameters(), float(cfg[\"grad_clip\"]))\n\n                scaler.step(opt)\n                scaler.update()\n                opt.zero_grad(set_to_none=True)\n\n                sch.step()\n                global_step += 1\n                optim_step_in_epoch += 1\n\n        # flush last partial accumulation (kalau ada)\n        if (micro_step % accum_steps) != 0:\n            if cfg[\"grad_clip\"] and float(cfg[\"grad_clip\"]) > 0:\n                scaler.unscale_(opt)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), float(cfg[\"grad_clip\"]))\n            scaler.step(opt)\n            scaler.update()\n            opt.zero_grad(set_to_none=True)\n            sch.step()\n            global_step += 1\n            optim_step_in_epoch += 1\n\n        # validate\n        p_va = predict_proba(model, dl_va)\n        vll = safe_logloss(y_va, p_va)\n\n        tr_loss = loss_sum / max(1, n_sum)\n        dt = time.time() - t0\n        print(f\"  epoch {epoch+1:03d}/{cfg['epochs']} | train_loss={tr_loss:.5f} | val_logloss={vll:.5f} | opt_steps={optim_step_in_epoch} | dt={dt:.1f}s\")\n\n        improved = (best[\"val_logloss\"] - vll) > float(cfg[\"early_stop_min_delta\"])\n        if improved:\n            best[\"val_logloss\"] = float(vll)\n            best[\"epoch\"] = int(epoch)\n            best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n            bad = 0\n        else:\n            bad += 1\n            if bad >= int(cfg[\"early_stop_patience\"]):\n                print(f\"  early stop at epoch {epoch+1}, best_epoch={best['epoch']+1}, best_val_logloss={best['val_logloss']:.5f}\")\n                break\n\n        if device.type == \"cuda\":\n            torch.cuda.empty_cache()\n        gc.collect()\n\n    if best_state is not None:\n        model.load_state_dict(best_state, strict=True)\n\n    # final val preds (best)\n    p_va = predict_proba(model, dl_va)\n\n    pack = {\n        \"state_dict\": {k: v.detach().cpu() for k, v in model.state_dict().items()},\n        \"mu\": mu,\n        \"sig\": sig,\n        \"cfg\": cfg,\n    }\n    return pack, p_va, best\n\n# ----------------------------\n# 13) CV loop\n# ----------------------------\noof_pred = np.zeros(n, dtype=np.float32)\nfold_reports = []\n\nmodels_dir = Path(\"/kaggle/working/recodai_luc_gate_artifacts/baseline_mhc_transformer_folds\")\nmodels_dir.mkdir(parents=True, exist_ok=True)\n\nfor f in unique_folds:\n    print(f\"\\n[Fold {f}]\")\n    tr_idx = np.where(folds != f)[0]\n    va_idx = np.where(folds == f)[0]\n\n    X_tr, y_tr = X[tr_idx], y[tr_idx]\n    X_va, y_va = X[va_idx], y[va_idx]\n\n    pack, p_va, best = train_one_fold(X_tr, y_tr, X_va, y_va, CFG)\n    oof_pred[va_idx] = p_va\n\n    auc = safe_auc(y_va, p_va)\n    thr = float(CFG[\"report_thr\"])\n    yhat = (p_va >= thr).astype(np.int32)\n\n    rep = {\n        \"fold\": int(f),\n        \"n_val\": int(len(va_idx)),\n        \"pos_val\": int(y_va.sum()),\n        \"auc\": auc,\n        f\"f1@{thr}\": float(f1_score(y_va, yhat, zero_division=0)),\n        f\"precision@{thr}\": float(precision_score(y_va, yhat, zero_division=0)),\n        f\"recall@{thr}\": float(recall_score(y_va, yhat, zero_division=0)),\n        \"logloss\": safe_logloss(y_va, p_va),\n        \"best_val_logloss\": float(best[\"val_logloss\"]),\n        \"best_epoch\": int(best[\"epoch\"] + 1),\n    }\n    fold_reports.append(rep)\n\n    torch.save(\n        {\"pack\": pack, \"feature_cols\": FEATURE_COLS},\n        models_dir / f\"baseline_mhc_transformer_fold_{f}.pt\"\n    )\n\n    if device.type == \"cuda\":\n        torch.cuda.empty_cache()\n    gc.collect()\n\n# ----------------------------\n# 14) Overall OOF metrics\n# ----------------------------\noof_auc = safe_auc(y, oof_pred)\nthr = float(CFG[\"report_thr\"])\noof_yhat = (oof_pred >= thr).astype(np.int32)\n\noverall = {\n    \"rows\": int(n),\n    \"folds\": int(n_folds),\n    \"pos_total\": int(y.sum()),\n    \"pos_rate\": float(y.mean()),\n    \"oof_auc\": oof_auc,\n    f\"oof_f1@{thr}\": float(f1_score(y, oof_yhat, zero_division=0)),\n    f\"oof_precision@{thr}\": float(precision_score(y, oof_yhat, zero_division=0)),\n    f\"oof_recall@{thr}\": float(recall_score(y, oof_yhat, zero_division=0)),\n    \"oof_logloss\": safe_logloss(y, oof_pred),\n}\n\ndf_rep = pd.DataFrame(fold_reports).sort_values(\"fold\").reset_index(drop=True)\nprint(\"\\nPer-fold report:\")\ndisplay(df_rep)\n\nprint(\"\\nOOF overall:\")\nprint(overall)\n\n# ----------------------------\n# 15) Train FULL model (fixed epochs = 70% of CV epochs)\n# ----------------------------\ndef train_full_fixed(X_full_raw, y_full, cfg):\n    mu, sig = fit_standardizer(X_full_raw)\n    X_full = apply_standardizer(X_full_raw, mu, sig)\n\n    ds_full = TabDataset(X_full, y_full)\n    dl_full = DataLoader(\n        ds_full, batch_size=int(cfg[\"batch_size\"]), shuffle=True,\n        num_workers=2, pin_memory=(device.type == \"cuda\"),\n        drop_last=False\n    )\n\n    model = MHCFTTransformer(\n        n_features=n_features,\n        d_model=int(cfg[\"d_model\"]),\n        n_heads=int(cfg[\"n_heads\"]),\n        n_layers=int(cfg[\"n_layers\"]),\n        ffn_mult=int(cfg[\"ffn_mult\"]),\n        dropout=float(cfg[\"dropout\"]),\n        attn_dropout=float(cfg[\"attn_dropout\"]),\n        n_streams=int(cfg[\"n_streams\"]),\n        sinkhorn_tmax=int(cfg[\"sinkhorn_tmax\"]),\n        alpha_init=float(cfg[\"alpha_init\"]),\n    ).to(device)\n\n    pos = int(y_full.sum())\n    neg = int(len(y_full) - pos)\n    pos_weight = float(neg / max(1, pos))\n    loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight], device=device))\n\n    opt = torch.optim.AdamW(\n        model.parameters(),\n        lr=float(cfg[\"lr\"]),\n        betas=tuple(cfg[\"betas\"]),\n        eps=float(cfg[\"eps\"]),\n        weight_decay=float(cfg[\"weight_decay\"]),\n    )\n\n    accum_steps = max(1, int(cfg.get(\"accum_steps\", 1)))\n    E_FULL = max(12, int(cfg[\"epochs\"] * 0.7))\n    optim_steps_per_epoch = int(math.ceil(len(dl_full) / accum_steps))\n    total_optim_steps = E_FULL * max(1, optim_steps_per_epoch)\n    warmup_steps = int(float(cfg[\"warmup_frac\"]) * total_optim_steps)\n\n    sch = make_warmup_step_scheduler(\n        opt,\n        total_steps=total_optim_steps,\n        warmup_steps=warmup_steps,\n        milestones_frac=cfg[\"lr_decay_milestones\"],\n        decay_values=cfg[\"lr_decay_values\"],\n    )\n\n    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n\n    print(f\"\\nTraining full mHC transformer for {E_FULL} epochs (fixed)...\")\n    for epoch in range(E_FULL):\n        model.train()\n        loss_sum = 0.0\n        n_sum = 0\n\n        opt.zero_grad(set_to_none=True)\n        micro_step = 0\n        for xb, yb in dl_full:\n            xb = xb.to(device, non_blocking=True)\n            yb = yb.to(device, non_blocking=True).float()\n\n            with torch.cuda.amp.autocast(enabled=use_amp):\n                logits = model(xb)\n                loss = loss_fn(logits, yb)\n                loss = loss / accum_steps\n\n            scaler.scale(loss).backward()\n            micro_step += 1\n\n            loss_sum += float(loss.item()) * xb.size(0) * accum_steps\n            n_sum += xb.size(0)\n\n            if (micro_step % accum_steps) == 0:\n                if cfg[\"grad_clip\"] and float(cfg[\"grad_clip\"]) > 0:\n                    scaler.unscale_(opt)\n                    torch.nn.utils.clip_grad_norm_(model.parameters(), float(cfg[\"grad_clip\"]))\n                scaler.step(opt)\n                scaler.update()\n                opt.zero_grad(set_to_none=True)\n                sch.step()\n\n        # flush last partial\n        if (micro_step % accum_steps) != 0:\n            if cfg[\"grad_clip\"] and float(cfg[\"grad_clip\"]) > 0:\n                scaler.unscale_(opt)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), float(cfg[\"grad_clip\"]))\n            scaler.step(opt)\n            scaler.update()\n            opt.zero_grad(set_to_none=True)\n            sch.step()\n\n        print(f\"  full epoch {epoch+1:03d}/{E_FULL} | loss={loss_sum/max(1,n_sum):.5f}\")\n\n        if device.type == \"cuda\":\n            torch.cuda.empty_cache()\n        gc.collect()\n\n    full_pack = {\n        \"state_dict\": {k: v.detach().cpu() for k, v in model.state_dict().items()},\n        \"mu\": mu,\n        \"sig\": sig,\n        \"cfg\": cfg,\n    }\n    return full_pack\n\nout_dir = Path(\"/kaggle/working/recodai_luc_gate_artifacts\")\nout_dir.mkdir(parents=True, exist_ok=True)\n\nfull_pack = train_full_fixed(X, y, CFG)\ntorch.save({\"pack\": full_pack, \"feature_cols\": FEATURE_COLS}, out_dir / \"baseline_mhc_transformer_model_full.pt\")\n\n# ----------------------------\n# 16) Save OOF + report\n# ----------------------------\ndf_oof = df_train_tabular[[\"uid\", \"case_id\", \"variant\", \"fold\", \"y\"]].copy()\ndf_oof[\"oof_pred_baseline_mhc_tf\"] = oof_pred\ndf_oof.to_csv(out_dir / \"oof_baseline_mhc_transformer.csv\", index=False)\n\nreport = {\n    \"model\": \"mHC-FTTransformer (numeric tabular) — baseline\",\n    \"cfg\": CFG,\n    \"feature_count\": int(len(FEATURE_COLS)),\n    \"fold_reports\": fold_reports,\n    \"overall\": overall,\n}\nwith open(out_dir / \"baseline_mhc_transformer_cv_report.json\", \"w\") as f:\n    json.dump(report, f, indent=2)\n\nprint(\"\\nSaved artifacts:\")\nprint(\"  fold models  ->\", models_dir)\nprint(\"  full model   ->\", out_dir / \"baseline_mhc_transformer_model_full.pt\")\nprint(\"  oof preds    ->\", out_dir / \"oof_baseline_mhc_transformer.csv\")\nprint(\"  cv report    ->\", out_dir / \"baseline_mhc_transformer_cv_report.json\")\n\n# Export globals\nOOF_PRED_BASELINE_MHC_TF = oof_pred\nBASELINE_MHC_TF_OVERALL = overall\nBASELINE_MHC_TF_FOLD_REPORTS = fold_reports\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:57:48.400236Z","iopub.execute_input":"2026-01-04T13:57:48.400525Z"}},"outputs":[{"name":"stdout","text":"Device: cpu | AMP: False | CFG: SAFE\nSetup:\n  rows      : 5176\n  folds     : 5 | [0, 1, 2, 3, 4]\n  pos%      : 54.07650695517774\n  n_features: 62\n\n[Fold 0]\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# Optimize Model & Hyperparameters (Iterative)","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# Step 4 — Optimize Model & Hyperparameters (Iterative) — TRANSFORMER ONLY (REVISI FULL v2, mHC-lite from PDF)\n# - FIX: predict_proba robust (batch can be xb or (xb,yb) or list/tuple) => NO ERROR\n# - Implementasi materi PDF (adapted, runtime-safe):\n#     * mHC-lite (multi-stream residual on CLS) with Sinkhorn-Knopp (tmax=20)\n#     * n_streams=4, alpha=0.01 (default)\n#     * AdamW betas=(0.9,0.95)\n#     * LR schedule: Warmup + Step decay at ratios [0.8,0.9] with rates [0.316, 0.1]\n# - Validasi: leakage-safe CV pakai `fold` by case_id\n# - Skor utama: OOF best F-beta (beta=0.5)\n#\n# Output:\n# - /kaggle/working/recodai_luc_gate_artifacts/opt_search/opt_results.csv\n# - /kaggle/working/recodai_luc_gate_artifacts/opt_search/opt_results.json\n# - /kaggle/working/recodai_luc_gate_artifacts/opt_search/opt_fold_details.csv\n# - /kaggle/working/recodai_luc_gate_artifacts/opt_search/oof_preds_<cfg_name>.csv (top configs)\n# - /kaggle/working/recodai_luc_gate_artifacts/best_gate_config.json\n# - /kaggle/working/recodai_luc_gate_artifacts/best_gate_model.pt\n#\n# REQUIRE:\n# - Step 2 sudah jalan: df_train_tabular, FEATURE_COLS\n# ============================================================\n\nimport os, json, gc, math, time, warnings, re\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\n\nwarnings.filterwarnings(\"ignore\")\n\nfrom IPython.display import display\nfrom sklearn.metrics import roc_auc_score, log_loss\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# ----------------------------\n# 0) Require data from Step 2\n# ----------------------------\nneed_vars = [\"df_train_tabular\", \"FEATURE_COLS\"]\nfor v in need_vars:\n    if v not in globals():\n        raise RuntimeError(f\"Missing `{v}`. Jalankan dulu Step 2 — Build Training Table (X, y, folds).\")\n\ndf_train_tabular = df_train_tabular.copy()\nFEATURE_COLS = list(FEATURE_COLS)\n\nX_all = df_train_tabular[FEATURE_COLS].to_numpy(dtype=np.float32, copy=True)\ny_all = df_train_tabular[\"y\"].to_numpy(dtype=np.int64, copy=True)\nfolds_all = df_train_tabular[\"fold\"].to_numpy(dtype=np.int64, copy=True)\nuids_all = df_train_tabular[\"uid\"].astype(str).to_numpy()\n\n# guard\nif not np.isfinite(X_all).all():\n    X_all = np.nan_to_num(X_all, nan=0.0, posinf=0.0, neginf=0.0)\n\nunique_folds = sorted(pd.Series(folds_all).unique().tolist())\nn = len(y_all)\npos_rate = float(y_all.mean())\nn_features = X_all.shape[1]\n\nprint(\"Optimize setup (Transformer only, mHC-lite):\")\nprint(f\"  rows={n} | folds={len(unique_folds)} | pos%={pos_rate*100:.2f} | n_features={n_features}\")\n\n# ----------------------------\n# 1) Global settings\n# ----------------------------\nSEED = 2025\nBETA = 0.5\nTHR_GRID = 201\n\n# runtime control (tanpa mengubah akurasi terlalu banyak)\nSTAGE1_FOLDS = min(3, len(unique_folds))         # stage-1 pakai subset fold (lebih cepat)\nSTAGE1_EPOCH_CAP = 40                            # stage-1 cap epoch\nSTAGE1_PAT_CAP = 6\n\nSTAGE2_TOPM = min(3, 5)                          # stage-2 full CV hanya top-M config\nREPORT_TOPK_OOF = 3\n\n# optional time budget (biar tidak kebablasan)\nTIME_BUDGET_SEC = 0\n# contoh: TIME_BUDGET_SEC = 2.5 * 60 * 60  # 2.5 jam\n# biarkan 0 jika tidak ingin dihentikan otomatis\n\ndef seed_everything(seed=2025):\n    import random\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = False\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(SEED)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nuse_amp = (device.type == \"cuda\")\nprint(\"Device:\", device, \"| AMP:\", use_amp)\n\ntry:\n    torch.set_float32_matmul_precision(\"high\")\nexcept Exception:\n    pass\n\n# ----------------------------\n# 2) Helpers: threshold search + safe metrics\n# ----------------------------\ndef best_fbeta_fast(y_true, p, beta=0.5, grid=201):\n    y = (np.asarray(y_true).astype(np.int32) == 1)\n    p = np.clip(np.asarray(p, dtype=np.float64), 1e-8, 1.0 - 1e-8)\n\n    thrs = np.linspace(0.01, 0.99, grid, dtype=np.float64)\n    pred = (p[:, None] >= thrs[None, :])\n\n    y1 = y[:, None]\n    tp = (pred & y1).sum(axis=0).astype(np.float64)\n    fp = (pred & (~y1)).sum(axis=0).astype(np.float64)\n    fn = (y.sum().astype(np.float64) - tp)\n\n    precision = np.divide(tp, tp + fp, out=np.zeros_like(tp), where=(tp + fp) > 0)\n    recall    = np.divide(tp, tp + fn, out=np.zeros_like(tp), where=(tp + fn) > 0)\n\n    b2 = beta * beta\n    denom = (b2 * precision + recall)\n    fbeta = np.divide((1.0 + b2) * precision * recall, denom, out=np.zeros_like(precision), where=denom > 0)\n\n    j = int(np.argmax(fbeta))\n    return {\n        \"fbeta\": float(fbeta[j]),\n        \"thr\": float(thrs[j]),\n        \"precision\": float(precision[j]),\n        \"recall\": float(recall[j]),\n    }\n\ndef safe_auc(y_true, p):\n    if len(np.unique(y_true)) < 2:\n        return None\n    return float(roc_auc_score(y_true, p))\n\ndef safe_logloss(y_true, p):\n    p = np.clip(np.asarray(p, dtype=np.float64), 1e-8, 1 - 1e-8)\n    return float(log_loss(y_true, p, labels=[0, 1]))\n\n# ----------------------------\n# 3) Dataset + Standardizer (fit only on train fold => no leakage)\n# ----------------------------\nclass TabDataset(Dataset):\n    def __init__(self, X, y=None):\n        self.X = torch.from_numpy(X.astype(np.float32))\n        self.y = None if y is None else torch.from_numpy(y.astype(np.int64))\n\n    def __len__(self): return self.X.shape[0]\n\n    def __getitem__(self, idx):\n        if self.y is None:\n            return self.X[idx]\n        return self.X[idx], self.y[idx]\n\ndef fit_standardizer(X_tr: np.ndarray):\n    mu = X_tr.mean(axis=0, dtype=np.float64)\n    sig = X_tr.std(axis=0, dtype=np.float64)\n    sig = np.where(sig < 1e-8, 1.0, sig)\n    return mu.astype(np.float32), sig.astype(np.float32)\n\ndef apply_standardizer(X_in: np.ndarray, mu: np.ndarray, sig: np.ndarray):\n    return ((X_in - mu) / sig).astype(np.float32)\n\n# ----------------------------\n# 4) PDF-inspired blocks: RMSNorm + Sinkhorn + mHC-lite on CLS streams\n# ----------------------------\nclass RMSNorm(nn.Module):\n    def __init__(self, d, eps=1e-8):\n        super().__init__()\n        self.eps = eps\n        self.weight = nn.Parameter(torch.ones(d))\n\n    def forward(self, x):\n        # x: (..., d)\n        rms = torch.mean(x * x, dim=-1, keepdim=True)\n        x = x * torch.rsqrt(rms + self.eps)\n        return x * self.weight\n\n@torch.no_grad()\ndef sinkhorn_knopp(P, tmax=20, eps=1e-12):\n    \"\"\"\n    P: (B, n, n) non-negative\n    output: doubly-stochastic approx via alternating row/col normalization\n    \"\"\"\n    M = P.clamp_min(eps)\n    for _ in range(int(tmax)):\n        M = M / (M.sum(dim=-1, keepdim=True).clamp_min(eps))  # row norm\n        M = M / (M.sum(dim=-2, keepdim=True).clamp_min(eps))  # col norm\n    return M\n\nclass MHCLite(nn.Module):\n    \"\"\"\n    Lightweight adaptation of mHC:\n    - maintain n_streams residual streams only for CLS embedding\n    - compute non-negative mixing matrix via softplus + Sinkhorn-Knopp\n    - inject current CLS back to each stream\n    \"\"\"\n    def __init__(self, d_model, n_streams=4, alpha=0.01, tmax=20, dropout=0.0):\n        super().__init__()\n        self.n = int(n_streams)\n        self.alpha = float(alpha)\n        self.tmax = int(tmax)\n        self.dropout = nn.Dropout(float(dropout))\n\n        # dynamic mapping from CLS -> n*n\n        # use RMSNorm to stabilize (PDF mentions RMSNorm in infra)\n        self.norm = RMSNorm(d_model, eps=1e-8)\n        self.mlp = nn.Sequential(\n            nn.Linear(d_model, d_model),\n            nn.GELU(),\n            nn.Linear(d_model, self.n * self.n),\n        )\n        self.softplus = nn.Softplus()\n\n    def forward(self, streams, cls_vec):\n        # streams: (B, n, D)\n        # cls_vec: (B, D)\n        B, n, D = streams.shape\n        h = self.norm(cls_vec)\n        logits = self.mlp(h).view(B, n, n) * self.alpha\n        P = self.softplus(logits)  # non-negative\n        M = sinkhorn_knopp(P, tmax=self.tmax)  # (B,n,n) doubly-stochastic approx\n\n        mixed = torch.einsum(\"bij,bjd->bid\", M, streams)       # mix streams\n        injected = mixed + cls_vec.unsqueeze(1)                # inject CLS\n        return self.dropout(injected)\n\nclass TransformerBlock(nn.Module):\n    \"\"\"\n    Custom transformer block with RMSNorm + separate attn_dropout support.\n    \"\"\"\n    def __init__(self, d_model, n_heads, ffn_mult=4, dropout=0.2, attn_dropout=0.1):\n        super().__init__()\n        self.norm1 = RMSNorm(d_model, eps=1e-8)\n        self.attn = nn.MultiheadAttention(\n            embed_dim=d_model, num_heads=int(n_heads),\n            dropout=float(attn_dropout), batch_first=True\n        )\n        self.drop1 = nn.Dropout(float(dropout))\n\n        self.norm2 = RMSNorm(d_model, eps=1e-8)\n        self.ffn = nn.Sequential(\n            nn.Linear(d_model, int(ffn_mult) * d_model),\n            nn.GELU(),\n            nn.Dropout(float(dropout)),\n            nn.Linear(int(ffn_mult) * d_model, d_model),\n        )\n        self.drop2 = nn.Dropout(float(dropout))\n\n    def forward(self, x):\n        # Pre-norm (norm_first)\n        h = self.norm1(x)\n        attn_out, _ = self.attn(h, h, h, need_weights=False)\n        x = x + self.drop1(attn_out)\n\n        h = self.norm2(x)\n        x = x + self.drop2(self.ffn(h))\n        return x\n\nclass FTTransformer_MHCLite(nn.Module):\n    \"\"\"\n    Numeric FT-Transformer + mHC-lite on CLS between blocks (runtime-safe).\n    \"\"\"\n    def __init__(self, n_features, d_model=384, n_heads=8, n_layers=8, ffn_mult=4,\n                 dropout=0.2, attn_dropout=0.1,\n                 n_streams=4, mhc_alpha=0.01, sinkhorn_tmax=20, mhc_dropout=0.0):\n        super().__init__()\n        self.n_features = int(n_features)\n        self.d_model = int(d_model)\n        self.n_layers = int(n_layers)\n\n        # per-feature linear tokenization\n        self.w = nn.Parameter(torch.randn(self.n_features, self.d_model) * 0.02)\n        self.b = nn.Parameter(torch.zeros(self.n_features, self.d_model))\n        self.feat_emb = nn.Parameter(torch.randn(self.n_features, self.d_model) * 0.02)\n\n        self.cls = nn.Parameter(torch.randn(1, 1, self.d_model) * 0.02)\n\n        self.token_dropout = nn.Dropout(float(attn_dropout))\n\n        self.blocks = nn.ModuleList([\n            TransformerBlock(\n                d_model=self.d_model,\n                n_heads=n_heads,\n                ffn_mult=ffn_mult,\n                dropout=dropout,\n                attn_dropout=attn_dropout\n            ) for _ in range(self.n_layers)\n        ])\n\n        self.mhc = nn.ModuleList([\n            MHCLite(\n                d_model=self.d_model,\n                n_streams=n_streams,\n                alpha=mhc_alpha,\n                tmax=sinkhorn_tmax,\n                dropout=mhc_dropout\n            ) for _ in range(self.n_layers)\n        ])\n\n        self.out_norm = RMSNorm(self.d_model, eps=1e-8)\n        self.head = nn.Sequential(\n            nn.Linear(self.d_model, self.d_model),\n            nn.GELU(),\n            nn.Dropout(float(dropout)),\n            nn.Linear(self.d_model, 1),\n        )\n\n    def forward(self, x):\n        # x: (B, F)\n        tok = x.unsqueeze(-1) * self.w.unsqueeze(0) + self.b.unsqueeze(0)\n        tok = tok + self.feat_emb.unsqueeze(0)\n        tok = self.token_dropout(tok)\n\n        B = tok.size(0)\n        cls = self.cls.expand(B, -1, -1)   # (B,1,D)\n        seq = torch.cat([cls, tok], dim=1) # (B,1+F,D)\n\n        # init streams from CLS\n        streams = seq[:, 0:1, :].expand(B, self.mhc[0].n, self.d_model).contiguous()\n\n        for l, blk in enumerate(self.blocks):\n            # inject mean-stream into CLS before block\n            seq[:, 0, :] = streams.mean(dim=1)\n\n            seq = blk(seq)\n            cls_vec = seq[:, 0, :]\n\n            # mHC-lite update streams using current CLS\n            streams = self.mhc[l](streams, cls_vec)\n\n        out = self.out_norm(streams.mean(dim=1))\n        logit = self.head(out).squeeze(-1)\n        return logit\n\n# ----------------------------\n# 5) LR schedule from PDF: warmup + step decay at ratios [0.8,0.9] with rates [0.316,0.1]\n# ----------------------------\ndef make_warmup_step_scheduler(optimizer, total_steps, warmup_steps, r1=0.8, r2=0.9, d1=0.316, d2=0.1):\n    m1 = int(r1 * total_steps)\n    m2 = int(r2 * total_steps)\n    def lr_lambda(step):\n        if warmup_steps > 0 and step < warmup_steps:\n            return float(step + 1) / float(max(1, warmup_steps))\n        mult = 1.0\n        if step >= m1:\n            mult *= float(d1)\n        if step >= m2:\n            mult *= float(d2)\n        return mult\n    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n\n# ----------------------------\n# 6) Predict helper (FIX: handle batch=(xb,yb) / list / tuple)\n# ----------------------------\n@torch.no_grad()\ndef predict_proba(model, loader):\n    model.eval()\n    probs = []\n    for batch in loader:\n        xb = batch[0] if isinstance(batch, (list, tuple)) else batch\n        xb = xb.to(device, non_blocking=True)\n        with torch.cuda.amp.autocast(enabled=use_amp):\n            logits = model(xb)\n            p = torch.sigmoid(logits)\n        probs.append(p.detach().cpu().numpy())\n    return np.concatenate(probs, axis=0).astype(np.float32)\n\n# ----------------------------\n# 7) Train one fold (AMP + early stopping)\n# ----------------------------\ndef train_one_fold_transformer(X_tr, y_tr, X_va, y_va, cfg):\n    mu, sig = fit_standardizer(X_tr)\n    X_trn = apply_standardizer(X_tr, mu, sig)\n    X_van = apply_standardizer(X_va, mu, sig)\n\n    ds_tr = TabDataset(X_trn, y_tr)\n    ds_va = TabDataset(X_van, y_va)\n\n    dl_tr = DataLoader(\n        ds_tr, batch_size=int(cfg[\"batch_size\"]), shuffle=True,\n        num_workers=2, pin_memory=(device.type==\"cuda\"), drop_last=False\n    )\n    dl_va = DataLoader(\n        ds_va, batch_size=int(cfg[\"batch_size\"]), shuffle=False,\n        num_workers=2, pin_memory=(device.type==\"cuda\"), drop_last=False\n    )\n\n    model = FTTransformer_MHCLite(\n        n_features=n_features,\n        d_model=int(cfg[\"d_model\"]),\n        n_heads=int(cfg[\"n_heads\"]),\n        n_layers=int(cfg[\"n_layers\"]),\n        ffn_mult=int(cfg[\"ffn_mult\"]),\n        dropout=float(cfg[\"dropout\"]),\n        attn_dropout=float(cfg[\"attn_dropout\"]),\n        n_streams=int(cfg[\"n_streams\"]),\n        mhc_alpha=float(cfg[\"mhc_alpha\"]),\n        sinkhorn_tmax=int(cfg[\"sinkhorn_tmax\"]),\n        mhc_dropout=float(cfg[\"mhc_dropout\"]),\n    ).to(device)\n\n    # imbalance -> pos_weight for BCEWithLogitsLoss\n    pos = int(y_tr.sum())\n    neg = int(len(y_tr) - pos)\n    pos_weight = float(neg / max(1, pos))\n    loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight], device=device))\n\n    # PDF-like AdamW betas\n    opt = torch.optim.AdamW(\n        model.parameters(),\n        lr=float(cfg[\"lr\"]),\n        weight_decay=float(cfg[\"weight_decay\"]),\n        betas=(float(cfg[\"beta1\"]), float(cfg[\"beta2\"])),\n        eps=float(cfg[\"adam_eps\"]),\n    )\n\n    total_steps = int(cfg[\"epochs\"]) * max(1, len(dl_tr))\n    warmup_steps = int(float(cfg[\"warmup_frac\"]) * total_steps)\n\n    sch = make_warmup_step_scheduler(\n        opt,\n        total_steps=total_steps,\n        warmup_steps=warmup_steps,\n        r1=float(cfg[\"lr_decay_ratio1\"]),\n        r2=float(cfg[\"lr_decay_ratio2\"]),\n        d1=float(cfg[\"lr_decay_rate1\"]),\n        d2=float(cfg[\"lr_decay_rate2\"]),\n    )\n\n    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n\n    best_val = 1e9\n    best_state = None\n    best_epoch = -1\n    bad = 0\n    step = 0\n\n    for epoch in range(int(cfg[\"epochs\"])):\n        model.train()\n        loss_sum = 0.0\n        n_sum = 0\n\n        for xb, yb in dl_tr:\n            xb = xb.to(device, non_blocking=True)\n            yb = yb.to(device, non_blocking=True).float()\n\n            opt.zero_grad(set_to_none=True)\n            with torch.cuda.amp.autocast(enabled=use_amp):\n                logits = model(xb)\n                loss = loss_fn(logits, yb)\n\n            scaler.scale(loss).backward()\n            if float(cfg[\"grad_clip\"]) and float(cfg[\"grad_clip\"]) > 0:\n                scaler.unscale_(opt)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), float(cfg[\"grad_clip\"]))\n            scaler.step(opt)\n            scaler.update()\n            sch.step()\n\n            loss_sum += float(loss.item()) * xb.size(0)\n            n_sum += xb.size(0)\n            step += 1\n\n        # val\n        p_va = predict_proba(model, dl_va)\n        vll = safe_logloss(y_va, p_va)\n\n        improved = (best_val - vll) > float(cfg[\"min_delta\"])\n        if improved:\n            best_val = float(vll)\n            best_epoch = int(epoch)\n            best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n            bad = 0\n        else:\n            bad += 1\n            if bad >= int(cfg[\"patience\"]):\n                break\n\n        gc.collect()\n\n    if best_state is not None:\n        model.load_state_dict(best_state, strict=True)\n\n    p_va = predict_proba(model, dl_va)\n\n    pack = {\n        \"state_dict\": {k: v.detach().cpu() for k, v in model.state_dict().items()},\n        \"mu\": mu,\n        \"sig\": sig,\n        \"cfg\": dict(cfg),\n        \"best_epoch\": int(best_epoch + 1),\n        \"best_val_logloss\": float(best_val),\n    }\n    return pack, p_va\n\n# ----------------------------\n# 8) CV evaluator for a config (optionally limited folds)\n# ----------------------------\ndef run_cv_config(cfg, cfg_name, folds_subset=None, beta=0.5, thr_grid=201):\n    oof = np.zeros(n, dtype=np.float32)\n    fold_rows = []\n    fold_packs = []\n\n    use_folds = unique_folds if folds_subset is None else list(folds_subset)\n\n    for f in use_folds:\n        tr = np.where(folds_all != f)[0]\n        va = np.where(folds_all == f)[0]\n\n        X_tr, y_tr = X_all[tr], y_all[tr]\n        X_va, y_va = X_all[va], y_all[va]\n\n        pack, p_va = train_one_fold_transformer(X_tr, y_tr, X_va, y_va, cfg)\n        oof[va] = p_va\n\n        fold_auc = safe_auc(y_va, p_va)\n        fold_ll  = safe_logloss(y_va, p_va)\n        best_fold = best_fbeta_fast(y_va, p_va, beta=beta, grid=max(51, thr_grid//2))\n\n        fold_rows.append({\n            \"cfg\": cfg_name,\n            \"fold\": int(f),\n            \"n_val\": int(len(va)),\n            \"pos_val\": int(y_va.sum()),\n            \"auc\": fold_auc,\n            \"logloss\": fold_ll,\n            \"best_fbeta\": best_fold[\"fbeta\"],\n            \"best_thr\": best_fold[\"thr\"],\n            \"best_prec\": best_fold[\"precision\"],\n            \"best_rec\": best_fold[\"recall\"],\n            \"best_val_logloss\": float(pack[\"best_val_logloss\"]),\n            \"best_epoch\": int(pack[\"best_epoch\"]),\n        })\n\n        fold_packs.append({\"fold\": int(f), \"pack\": pack})\n\n        del pack\n        gc.collect()\n        if device.type == \"cuda\":\n            torch.cuda.empty_cache()\n\n    # overall (on filled parts only)\n    # NOTE: ini tetap OOF \"full-length\", tapi fold yang tidak dihitung akan 0.\n    # Untuk stage-1 ranking, kita hitung metric hanya pada indeks fold subset.\n    if folds_subset is None:\n        idx_eval = np.arange(n)\n    else:\n        idx_eval = np.where(np.isin(folds_all, np.array(use_folds)))[0]\n\n    oof_eval = oof[idx_eval]\n    y_eval = y_all[idx_eval]\n\n    oof_auc = safe_auc(y_eval, oof_eval)\n    oof_ll  = safe_logloss(y_eval, oof_eval)\n    best_oof = best_fbeta_fast(y_eval, oof_eval, beta=beta, grid=thr_grid)\n\n    summary = {\n        \"cfg\": cfg_name,\n        \"stage\": \"full\" if folds_subset is None else f\"subset{len(use_folds)}\",\n        \"oof_auc\": oof_auc,\n        \"oof_logloss\": oof_ll,\n        \"oof_best_fbeta\": best_oof[\"fbeta\"],\n        \"oof_best_thr\": best_oof[\"thr\"],\n        \"oof_best_prec\": best_oof[\"precision\"],\n        \"oof_best_rec\": best_oof[\"recall\"],\n\n        # log cfg\n        \"d_model\": cfg[\"d_model\"],\n        \"n_layers\": cfg[\"n_layers\"],\n        \"n_heads\": cfg[\"n_heads\"],\n        \"ffn_mult\": cfg[\"ffn_mult\"],\n        \"dropout\": cfg[\"dropout\"],\n        \"attn_dropout\": cfg[\"attn_dropout\"],\n\n        # mHC-lite params (PDF)\n        \"n_streams\": cfg[\"n_streams\"],\n        \"mhc_alpha\": cfg[\"mhc_alpha\"],\n        \"sinkhorn_tmax\": cfg[\"sinkhorn_tmax\"],\n        \"mhc_dropout\": cfg[\"mhc_dropout\"],\n\n        # train params (PDF-ish)\n        \"batch_size\": cfg[\"batch_size\"],\n        \"epochs\": cfg[\"epochs\"],\n        \"lr\": cfg[\"lr\"],\n        \"weight_decay\": cfg[\"weight_decay\"],\n        \"warmup_frac\": cfg[\"warmup_frac\"],\n        \"beta1\": cfg[\"beta1\"],\n        \"beta2\": cfg[\"beta2\"],\n        \"adam_eps\": cfg[\"adam_eps\"],\n        \"lr_decay_ratio1\": cfg[\"lr_decay_ratio1\"],\n        \"lr_decay_ratio2\": cfg[\"lr_decay_ratio2\"],\n        \"lr_decay_rate1\": cfg[\"lr_decay_rate1\"],\n        \"lr_decay_rate2\": cfg[\"lr_decay_rate2\"],\n        \"patience\": cfg[\"patience\"],\n        \"min_delta\": cfg[\"min_delta\"],\n        \"grad_clip\": cfg[\"grad_clip\"],\n    }\n    return summary, fold_rows, oof, fold_packs\n\n# ----------------------------\n# 9) Define candidate configs (big but still Kaggle-safe)\n# ----------------------------\nBASE = dict(\n    # training\n    batch_size=512 if device.type==\"cuda\" else 256,\n    epochs=70 if device.type==\"cuda\" else 40,\n    lr=2e-4,\n    weight_decay=8e-3,          # tabular biasanya lebih kecil dari 0.1; tapi kita tetap grid\n    warmup_frac=0.10,\n    grad_clip=1.0,\n    patience=10,\n    min_delta=1e-4,\n\n    # optimizer (PDF)\n    beta1=0.9,\n    beta2=0.95,\n    adam_eps=1e-8,              # PDF table shows 1e-20; 1e-8 lebih aman di Kaggle float32/amp\n\n    # LR schedule (PDF)\n    lr_decay_ratio1=0.8,\n    lr_decay_ratio2=0.9,\n    lr_decay_rate1=0.316,\n    lr_decay_rate2=0.1,\n\n    # mHC-lite (PDF)\n    n_streams=4,\n    mhc_alpha=0.01,\n    sinkhorn_tmax=20,\n    mhc_dropout=0.0,\n)\n\ncandidates = []\n\n# Strong default (stabil)\ncandidates.append((\"mhc_384x8\", dict(BASE, d_model=384, n_layers=8,  n_heads=8,  ffn_mult=4, dropout=0.20, attn_dropout=0.10)))\n\n# Lebih kuat (sedikit lebih lambat; lebih regularized)\ncandidates.append((\"mhc_384x10_reg\", dict(BASE, d_model=384, n_layers=10, n_heads=8,  ffn_mult=4, dropout=0.25, attn_dropout=0.12,\n                                         lr=1.6e-4, weight_decay=1.2e-2, epochs=85 if device.type==\"cuda\" else 50, patience=12)))\n\n# FFN lebih kecil (kadang lebih tahan noise)\ncandidates.append((\"mhc_384x8_ffn2\", dict(BASE, d_model=384, n_layers=8,  n_heads=8,  ffn_mult=2, dropout=0.18, attn_dropout=0.10,\n                                         lr=2.2e-4, weight_decay=6e-3)))\n\n# Lebih cepat (buat pembanding)\ncandidates.append((\"mhc_256x6_fast\", dict(BASE, d_model=256, n_layers=6,  n_heads=8,  ffn_mult=4, dropout=0.18, attn_dropout=0.08,\n                                         lr=3e-4, weight_decay=4e-3, epochs=60 if device.type==\"cuda\" else 35, patience=9)))\n\n# Extreme (hanya kalau CUDA; kalau CPU skip otomatis)\nif device.type == \"cuda\":\n    candidates.append((\"mhc_512x10_big\", dict(BASE, d_model=512, n_layers=10, n_heads=16, ffn_mult=4, dropout=0.28, attn_dropout=0.15,\n                                             lr=1.2e-4, weight_decay=2e-2, epochs=90, patience=12,\n                                             mhc_dropout=0.05)))\n\nprint(f\"\\nTotal Transformer candidates: {len(candidates)}\")\nprint(\"Primary score: OOF best F-beta (beta=0.5)\")\n\n# ----------------------------\n# 10) Run 2-stage search (runtime-safe)\n# ----------------------------\nOUT_DIR = Path(\"/kaggle/working/recodai_luc_gate_artifacts\")\nOPT_DIR = OUT_DIR / \"opt_search\"\nOPT_DIR.mkdir(parents=True, exist_ok=True)\n\n# pick subset folds evenly spaced for stage-1\nif STAGE1_FOLDS >= len(unique_folds):\n    folds_subset = unique_folds\nelse:\n    stepk = max(1, len(unique_folds) // STAGE1_FOLDS)\n    folds_subset = unique_folds[::stepk][:STAGE1_FOLDS]\n\nprint(\"\\nStage-1 folds subset:\", folds_subset)\n\nt0 = time.time()\nstage1_rows = []\nstage1_fold_rows = []\nstage1_oof_store = {}\n\nfor i, (name, cfg) in enumerate(candidates, 1):\n    if TIME_BUDGET_SEC and (time.time() - t0) > TIME_BUDGET_SEC:\n        print(\"Time budget reached. Stop search.\")\n        break\n\n    cfg1 = dict(cfg)\n    cfg1[\"epochs\"] = int(min(int(cfg1[\"epochs\"]), int(STAGE1_EPOCH_CAP)))\n    cfg1[\"patience\"] = int(min(int(cfg1[\"patience\"]), int(STAGE1_PAT_CAP)))\n\n    print(f\"\\n[Stage-1 {i:02d}/{len(candidates)}] CV(subset) -> {name}\")\n    summ, fold_rows, oof, _ = run_cv_config(cfg1, name, folds_subset=folds_subset, beta=BETA, thr_grid=101)\n\n    stage1_rows.append(summ)\n    stage1_fold_rows.extend(fold_rows)\n    stage1_oof_store[name] = oof\n\n    print(f\"  stage1 best_fbeta: {summ['oof_best_fbeta']:.6f} | thr: {summ['oof_best_thr']:.3f}\"\n          f\" | logloss: {summ['oof_logloss']:.6f}\")\n\ndf_s1 = pd.DataFrame(stage1_rows).sort_values([\"oof_best_fbeta\",\"oof_logloss\"], ascending=[False, True]).reset_index(drop=True)\nprint(\"\\nStage-1 ranking (top):\")\ndisplay(df_s1.head(10))\n\n# pick top-M for stage-2 full CV\ntopM = min(int(STAGE2_TOPM), len(df_s1))\nstage2_names = df_s1[\"cfg\"].head(topM).tolist()\nprint(\"\\nStage-2 will run full CV for:\", stage2_names)\n\nall_summaries = []\nall_fold_rows = []\noof_store = {}\n\nfor j, nm in enumerate(stage2_names, 1):\n    if TIME_BUDGET_SEC and (time.time() - t0) > TIME_BUDGET_SEC:\n        print(\"Time budget reached. Stop stage-2.\")\n        break\n\n    cfg = None\n    for (nname, ccfg) in candidates:\n        if nname == nm:\n            cfg = ccfg\n            break\n    if cfg is None:\n        continue\n\n    print(f\"\\n[Stage-2 {j:02d}/{len(stage2_names)}] CV(full) -> {nm}\")\n    summ, fold_rows, oof, _ = run_cv_config(cfg, nm, folds_subset=None, beta=BETA, thr_grid=THR_GRID)\n\n    all_summaries.append(summ)\n    all_fold_rows.extend(fold_rows)\n    oof_store[nm] = oof\n\n    print(f\"  OOF best_fbeta: {summ['oof_best_fbeta']:.6f} | thr: {summ['oof_best_thr']:.3f}\"\n          f\" | auc: {(summ['oof_auc'] if summ['oof_auc'] is not None else float('nan')):.6f}\"\n          f\" | logloss: {summ['oof_logloss']:.6f}\")\n\ndf_sum = pd.DataFrame(all_summaries)\ndf_fold = pd.DataFrame(all_fold_rows)\n\ndf_sum = df_sum.sort_values([\"oof_best_fbeta\", \"oof_logloss\"], ascending=[False, True]).reset_index(drop=True)\n\nprint(\"\\nStage-2 top candidates (full CV):\")\ndisplay(df_sum)\n\n# save search results\ndf_sum.to_csv(OPT_DIR / \"opt_results.csv\", index=False)\nwith open(OPT_DIR / \"opt_results.json\", \"w\") as f:\n    json.dump(df_sum.to_dict(orient=\"records\"), f, indent=2)\ndf_fold.to_csv(OPT_DIR / \"opt_fold_details.csv\", index=False)\n\n# save OOF preds for top configs (debugging)\ntop_names = df_sum[\"cfg\"].head(min(REPORT_TOPK_OOF, len(df_sum))).tolist()\nfor nm in top_names:\n    df_o = pd.DataFrame({\n        \"uid\": uids_all,\n        \"y\": y_all,\n        \"fold\": folds_all,\n        f\"oof_pred_{nm}\": oof_store[nm]\n    })\n    df_o.to_csv(OPT_DIR / f\"oof_preds_{nm}.csv\", index=False)\n\n# ----------------------------\n# 11) Choose best config + retrain fold packs for best (full CV)\n# ----------------------------\nif len(df_sum) == 0:\n    raise RuntimeError(\"Stage-2 produced no results. Cek device/VRAM atau turunkan kandidat/epochs.\")\n\nbest_single = df_sum.iloc[0].to_dict()\nbest_cfg_name = best_single[\"cfg\"]\n\nbest_cfg = None\nfor nm, cfg in candidates:\n    if nm == best_cfg_name:\n        best_cfg = cfg\n        break\nif best_cfg is None:\n    raise RuntimeError(\"Best cfg not found in candidates list (unexpected).\")\n\nprint(\"\\nBest config:\", best_cfg_name)\nprint(best_single)\n\nprint(f\"\\nRe-train folds for best config -> {best_cfg_name}\")\nbest_fold_packs = []\nbest_oof = np.zeros(n, dtype=np.float32)\n\nfor f in unique_folds:\n    tr = np.where(folds_all != f)[0]\n    va = np.where(folds_all == f)[0]\n\n    X_tr, y_tr = X_all[tr], y_all[tr]\n    X_va, y_va = X_all[va], y_all[va]\n\n    pack, p_va = train_one_fold_transformer(X_tr, y_tr, X_va, y_va, best_cfg)\n    pack[\"fold\"] = int(f)\n    best_fold_packs.append(pack)\n    best_oof[va] = p_va\n\n    gc.collect()\n    if device.type == \"cuda\":\n        torch.cuda.empty_cache()\n\nbest_model_path = OUT_DIR / \"best_gate_model.pt\"\ntorch.save(\n    {\n        \"type\": \"mhc_lite_ft_transformer\",\n        \"feature_cols\": FEATURE_COLS,\n        \"fold_packs\": best_fold_packs,\n        \"cfg_name\": best_cfg_name,\n        \"cfg\": best_cfg,\n        \"seed\": SEED,\n    },\n    best_model_path\n)\n\nbest_oof_best = best_fbeta_fast(y_all, best_oof, beta=BETA, grid=THR_GRID)\n\nbest_bundle = {\n    # dibuat supaya Step 5 nanti gampang:\n    \"type\": \"mhc_lite_ft_transformer\",\n    \"model_name\": best_cfg_name,\n    \"members\": [best_cfg_name],\n    \"random_seed\": SEED,\n    \"beta_for_tuning\": BETA,\n\n    \"feature_cols\": FEATURE_COLS,\n    \"cfg\": best_cfg,\n\n    \"oof_best_thr\": best_oof_best[\"thr\"],\n    \"oof_best_fbeta\": best_oof_best[\"fbeta\"],\n    \"oof_best_prec\": best_oof_best[\"precision\"],\n    \"oof_best_rec\": best_oof_best[\"recall\"],\n    \"oof_auc\": safe_auc(y_all, best_oof),\n    \"oof_logloss\": safe_logloss(y_all, best_oof),\n\n    \"notes\": \"Best config from Step 4 (Transformer-only, mHC-lite PDF-inspired). Step 5 should train FULL model for inference.\",\n}\n\nwith open(OUT_DIR / \"best_gate_config.json\", \"w\") as f:\n    json.dump(best_bundle, f, indent=2)\n\nprint(\"\\nSaved best artifacts:\")\nprint(\"  best model (fold packs) ->\", best_model_path)\nprint(\"  best config             ->\", OUT_DIR / \"best_gate_config.json\")\nprint(\"  opt results             ->\", OPT_DIR / \"opt_results.csv\")\nprint(\"  fold detail             ->\", OPT_DIR / \"opt_fold_details.csv\")\n\n# Export globals for Step 5\nBEST_GATE_BUNDLE = best_bundle\nBEST_TF_CFG_NAME = best_cfg_name\nBEST_TF_CFG = best_cfg\nOPT_RESULTS_DF = df_sum\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Final Training (Train on Full Data)","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# Step 5 — Final Training (Train on Full Data) — TRANSFORMER ONLY (REVISI FULL v3)\n# - FIX: predict_proba aman untuk batch=(xb,yb)/list/tuple\n# - mHC-style training: AdamW betas(0.9,0.95) + Warmup + Step decay (0.8/0.9)\n# - Auto \"besar tapi muat\" berdasarkan VRAM (safe untuk runtime Kaggle)\n#\n# Output:\n#   /kaggle/working/recodai_luc_gate_artifacts/final_gate_model.pt\n#   /kaggle/working/recodai_luc_gate_artifacts/final_gate_bundle.json\n# ============================================================\n\nimport os, json, gc, math, time, warnings\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\n\nwarnings.filterwarnings(\"ignore\")\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom sklearn.metrics import log_loss, roc_auc_score\n\n# ----------------------------\n# 0) REQUIRE\n# ----------------------------\nif \"df_train_tabular\" not in globals():\n    raise RuntimeError(\"Missing `df_train_tabular`. Jalankan Step 2 dulu.\")\nif \"FEATURE_COLS\" not in globals():\n    raise RuntimeError(\"Missing `FEATURE_COLS`. Jalankan Step 2 dulu.\")\n\ndf_train_tabular = df_train_tabular.copy()\nFEATURE_COLS = list(FEATURE_COLS)\n\nneed_cols = {\"uid\",\"case_id\",\"fold\",\"y\"}\nmiss = [c for c in need_cols if c not in df_train_tabular.columns]\nif miss:\n    raise ValueError(f\"df_train_tabular missing columns: {miss}\")\n\nX_all = df_train_tabular[FEATURE_COLS].to_numpy(dtype=np.float32, copy=True)\ny_all = df_train_tabular[\"y\"].to_numpy(dtype=np.int64, copy=True)\n\nif not np.isfinite(X_all).all():\n    X_all = np.nan_to_num(X_all, nan=0.0, posinf=0.0, neginf=0.0)\n\nOUT_DIR = Path(\"/kaggle/working/recodai_luc_gate_artifacts\")\nOUT_DIR.mkdir(parents=True, exist_ok=True)\n\nprint(\"Final training data:\")\nprint(f\"  rows={len(y_all)} | pos%={float(y_all.mean())*100:.2f} | n_features={X_all.shape[1]}\")\n\n# ----------------------------\n# 1) Load best cfg (optional)\n#    - kompatibel: format lama transformer_ft, atau bundle apapun yang punya [\"cfg\"]\n# ----------------------------\ncfg_path = OUT_DIR / \"best_gate_config.json\"\nbest_bundle = None\nsource = None\n\nif \"BEST_GATE_BUNDLE\" in globals() and isinstance(BEST_GATE_BUNDLE, dict):\n    best_bundle = BEST_GATE_BUNDLE\n    source = \"memory(BEST_GATE_BUNDLE)\"\nelif cfg_path.exists():\n    best_bundle = json.loads(cfg_path.read_text())\n    source = str(cfg_path)\n\nif best_bundle is not None and isinstance(best_bundle, dict) and isinstance(best_bundle.get(\"cfg\", None), dict):\n    base_cfg = dict(best_bundle[\"cfg\"])\n    print(\"\\nLoaded cfg from:\", source)\nelse:\n    base_cfg = {}\n    print(\"\\nNo best_gate_config found. Using strong default cfg.\")\n\n# ----------------------------\n# 2) Device + seed\n# ----------------------------\nFINAL_SEED = int(best_bundle.get(\"seed\", 2025)) if isinstance(best_bundle, dict) else 2025\n\ndef seed_everything(seed: int):\n    import random\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = False\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(FINAL_SEED)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nuse_amp = (device.type == \"cuda\")\n\n# matmul perf (pytorch 2.x)\ntry:\n    torch.set_float32_matmul_precision(\"high\")\nexcept Exception:\n    pass\n\nvram_gb = None\nif device.type == \"cuda\":\n    vram_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n\nprint(\"\\nDevice:\", device, \"| AMP:\", use_amp, \"| VRAM_GB:\", (f\"{vram_gb:.1f}\" if vram_gb else \"CPU\"))\n\n# ----------------------------\n# 3) Runtime-safe \"big model\" policy\n#    - kamu minta model besar tersimpan => default ON jika CUDA\n#    - kalau CPU: otomatis dikecilkan supaya runtime tidak meledak\n# ----------------------------\nWANT_BIG_MODEL = True\nUSE_INTERNAL_VAL = True         # early stopping lebih aman\nVAL_FRAC_CASE = 0.08            # 8% case-level val (cukup stabil, tidak terlalu buang data)\nEARLY_STOP = True\n\n# multi-seed = lebih kuat tapi lebih lama; keep 1 untuk runtime Kaggle\nN_SEEDS = 1\n\n# default cfg kalau base_cfg kosong\nCFG = dict(\n    d_model=384,\n    n_layers=8,\n    n_heads=8,\n    ffn_mult=4,\n    dropout=0.20,\n    attn_dropout=0.10,\n\n    batch_size=512,\n    epochs=60,              # cukup, early stop akan potong\n    lr=2e-4,\n    weight_decay=1e-2,      # lebih dekat spirit AdamW (paper), tapi tidak seganas 0.1\n    warmup_frac=0.10,\n    grad_clip=1.0,\n\n    patience=10,\n    min_delta=1e-4,\n)\n\n# merge base_cfg -> CFG\nfor k,v in base_cfg.items():\n    if k in CFG:\n        CFG[k] = v\n\n# auto upscale (big) jika GPU\ndef autoscale_cfg_for_device(cfg: dict):\n    cfg = dict(cfg)\n    if device.type != \"cuda\":\n        # CPU fallback: lebih kecil biar feasible\n        cfg[\"d_model\"] = min(int(cfg.get(\"d_model\", 384)), 256)\n        cfg[\"n_layers\"] = min(int(cfg.get(\"n_layers\", 8)), 6)\n        cfg[\"n_heads\"]  = min(int(cfg.get(\"n_heads\", 8)), 8)\n        cfg[\"batch_size\"] = min(int(cfg.get(\"batch_size\", 512)), 256)\n        cfg[\"epochs\"] = min(int(cfg.get(\"epochs\", 60)), 35)\n        cfg[\"lr\"] = float(cfg.get(\"lr\", 2e-4))\n        cfg[\"weight_decay\"] = float(cfg.get(\"weight_decay\", 1e-2))\n        return cfg\n\n    # CUDA\n    if not WANT_BIG_MODEL:\n        return cfg\n\n    # pilih \"besar tapi aman\" berdasar VRAM\n    if vram_gb is None:\n        return cfg\n\n    if vram_gb >= 24:\n        cfg.update(dict(d_model=max(int(cfg[\"d_model\"]), 512),\n                        n_layers=max(int(cfg[\"n_layers\"]), 12),\n                        n_heads=max(int(cfg[\"n_heads\"]), 16),\n                        ffn_mult=max(int(cfg[\"ffn_mult\"]), 4),\n                        dropout=max(float(cfg[\"dropout\"]), 0.25),\n                        attn_dropout=max(float(cfg[\"attn_dropout\"]), 0.12),\n                        lr=min(float(cfg[\"lr\"]), 1.5e-4),\n                        weight_decay=max(float(cfg[\"weight_decay\"]), 2e-2),\n                        batch_size=min(int(cfg[\"batch_size\"]), 512),\n                        epochs=max(int(cfg[\"epochs\"]), 70),\n                        patience=max(int(cfg[\"patience\"]), 12)))\n    elif vram_gb >= 16:\n        cfg.update(dict(d_model=max(int(cfg[\"d_model\"]), 448),\n                        n_layers=max(int(cfg[\"n_layers\"]), 10),\n                        n_heads=max(int(cfg[\"n_heads\"]), 8),\n                        ffn_mult=max(int(cfg[\"ffn_mult\"]), 4),\n                        dropout=max(float(cfg[\"dropout\"]), 0.24),\n                        attn_dropout=max(float(cfg[\"attn_dropout\"]), 0.12),\n                        lr=min(float(cfg[\"lr\"]), 1.8e-4),\n                        weight_decay=max(float(cfg[\"weight_decay\"]), 1.5e-2),\n                        batch_size=min(int(cfg[\"batch_size\"]), 512),\n                        epochs=max(int(cfg[\"epochs\"]), 65),\n                        patience=max(int(cfg[\"patience\"]), 11)))\n    else:\n        # 8–12GB (umum Kaggle)\n        cfg.update(dict(d_model=max(int(cfg[\"d_model\"]), 384),\n                        n_layers=max(int(cfg[\"n_layers\"]), 8),\n                        n_heads=max(int(cfg[\"n_heads\"]), 8),\n                        ffn_mult=max(int(cfg[\"ffn_mult\"]), 4),\n                        dropout=max(float(cfg[\"dropout\"]), 0.22),\n                        attn_dropout=max(float(cfg[\"attn_dropout\"]), 0.10),\n                        lr=min(float(cfg[\"lr\"]), 2e-4),\n                        weight_decay=max(float(cfg[\"weight_decay\"]), 1e-2),\n                        batch_size=min(int(cfg[\"batch_size\"]), 384),   # jaga OOM\n                        epochs=max(int(cfg[\"epochs\"]), 60),\n                        patience=max(int(cfg[\"patience\"]), 10)))\n    return cfg\n\nCFG = autoscale_cfg_for_device(CFG)\n\n# mHC paper: AdamW betas (0.9,0.95); eps kecil (tetap aman)\nADAM_BETAS = (0.9, 0.95)\nADAM_EPS   = 1e-8  # paper pakai eps sangat kecil; 1e-8 lebih aman numerik untuk tabular\n\n# Step decay ratios (paper): 0.8 & 0.9 epoch fractions\nSTEP_RATIOS = (0.8, 0.9)\nSTEP_GAMMAS = (0.316, 0.1)\n\nprint(\"\\nCFG (final):\")\nfor k in [\"d_model\",\"n_layers\",\"n_heads\",\"ffn_mult\",\"dropout\",\"attn_dropout\",\"batch_size\",\"epochs\",\"lr\",\"weight_decay\",\"warmup_frac\",\"patience\"]:\n    print(f\"  {k}: {CFG[k]}\")\n\n# effective batch via grad accumulation (biar tetap stabil walau batch diturunin)\nTARGET_EFF_BATCH = 1024 if device.type==\"cuda\" else 256\nGRAD_ACCUM = max(1, int(math.ceil(TARGET_EFF_BATCH / int(CFG[\"batch_size\"]))))\n\nprint(f\"\\nGradAccum: {GRAD_ACCUM} (target_eff_batch={TARGET_EFF_BATCH})\")\n\n# ----------------------------\n# 4) Dataset + Standardizer\n# ----------------------------\nclass TabDataset(Dataset):\n    def __init__(self, X, y=None):\n        self.X = torch.from_numpy(X.astype(np.float32))\n        self.y = None if y is None else torch.from_numpy(y.astype(np.int64))\n    def __len__(self): return self.X.shape[0]\n    def __getitem__(self, idx):\n        if self.y is None:\n            return self.X[idx]\n        return self.X[idx], self.y[idx]\n\ndef fit_standardizer(X_tr: np.ndarray):\n    mu = X_tr.mean(axis=0, dtype=np.float64)\n    sig = X_tr.std(axis=0, dtype=np.float64)\n    sig = np.where(sig < 1e-8, 1.0, sig)\n    return mu.astype(np.float32), sig.astype(np.float32)\n\ndef apply_standardizer(X_in: np.ndarray, mu: np.ndarray, sig: np.ndarray):\n    return ((X_in - mu) / sig).astype(np.float32)\n\n# ----------------------------\n# 5) Model (FT-Transformer numeric) + DeepNorm-like scaling (mHC spirit)\n# ----------------------------\nclass RMSNorm(nn.Module):\n    def __init__(self, d, eps=1e-6):\n        super().__init__()\n        self.eps = eps\n        self.scale = nn.Parameter(torch.ones(d))\n    def forward(self, x):\n        # x: (..., d)\n        rms = x.pow(2).mean(dim=-1, keepdim=True).add(self.eps).sqrt()\n        return (x / rms) * self.scale\n\nclass TransformerBlock(nn.Module):\n    def __init__(self, d_model, n_heads, ffn_mult=4, dropout=0.2, attn_dropout=0.1, deepnorm_alpha=1.0):\n        super().__init__()\n        self.alpha = float(deepnorm_alpha)\n\n        self.norm1 = RMSNorm(d_model)\n        self.attn = nn.MultiheadAttention(d_model, n_heads, dropout=attn_dropout, batch_first=True)\n        self.drop1 = nn.Dropout(dropout)\n\n        self.norm2 = RMSNorm(d_model)\n        hidden = int(ffn_mult * d_model)\n        self.ffn = nn.Sequential(\n            nn.Linear(d_model, hidden),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden, d_model),\n        )\n        self.drop2 = nn.Dropout(dropout)\n\n    def forward(self, x):\n        # Pre-norm + DeepNorm residual scaling\n        h = self.norm1(x)\n        attn_out, _ = self.attn(h, h, h, need_weights=False)\n        x = (x * self.alpha) + self.drop1(attn_out)\n\n        h = self.norm2(x)\n        ffn_out = self.ffn(h)\n        x = (x * self.alpha) + self.drop2(ffn_out)\n        return x\n\nclass FTTransformerBig(nn.Module):\n    def __init__(self, n_features, d_model=384, n_heads=8, n_layers=8, ffn_mult=4, dropout=0.2, attn_dropout=0.1):\n        super().__init__()\n        self.n_features = n_features\n        self.d_model = d_model\n\n        # per-feature tokenization (numeric-only)\n        self.w = nn.Parameter(torch.randn(n_features, d_model) * 0.02)\n        self.b = nn.Parameter(torch.zeros(n_features, d_model))\n        self.feat_emb = nn.Parameter(torch.randn(n_features, d_model) * 0.02)\n\n        self.cls = nn.Parameter(torch.randn(1, 1, d_model) * 0.02)\n\n        # DeepNorm alpha (paper spirit): alpha ~ (2L)^(1/4)\n        alpha = (2.0 * n_layers) ** 0.25\n\n        self.token_dropout = nn.Dropout(attn_dropout)\n        self.blocks = nn.ModuleList([\n            TransformerBlock(d_model, n_heads, ffn_mult=ffn_mult, dropout=dropout, attn_dropout=attn_dropout, deepnorm_alpha=alpha)\n            for _ in range(n_layers)\n        ])\n        self.final_norm = RMSNorm(d_model)\n\n        self.head = nn.Sequential(\n            nn.Linear(d_model, d_model),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_model, 1),\n        )\n\n    def forward(self, x):\n        # x: (B,F)\n        tok = x.unsqueeze(-1) * self.w.unsqueeze(0) + self.b.unsqueeze(0)  # (B,F,D)\n        tok = tok + self.feat_emb.unsqueeze(0)\n        tok = self.token_dropout(tok)\n\n        B = tok.size(0)\n        cls = self.cls.expand(B, -1, -1)          # (B,1,D)\n        seq = torch.cat([cls, tok], dim=1)        # (B,1+F,D)\n\n        for blk in self.blocks:\n            seq = blk(seq)\n\n        z = self.final_norm(seq[:, 0])            # CLS\n        logit = self.head(z).squeeze(-1)\n        return logit\n\n# ----------------------------\n# 6) Schedulers (Warmup + Step decay @ 0.8/0.9 epochs)\n# ----------------------------\ndef make_warmup_then_step_scheduler(optimizer, total_steps, warmup_steps, step_milestones, gammas):\n    \"\"\"\n    warmup linear -> base lr\n    then multiply lr by gammas at given milestone steps (cumulative)\n    \"\"\"\n    step_milestones = list(step_milestones)\n    gammas = list(gammas)\n\n    def lr_lambda(step):\n        if step < warmup_steps:\n            return float(step + 1) / float(max(1, warmup_steps))\n\n        mult = 1.0\n        for ms, g in zip(step_milestones, gammas):\n            if step >= ms:\n                mult *= g\n        return mult\n\n    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n\n# ----------------------------\n# 7) Predict helper (anti tuple-batch error)\n# ----------------------------\n@torch.no_grad()\ndef predict_proba(model, loader):\n    model.eval()\n    ps = []\n    for batch in loader:\n        xb = batch[0] if isinstance(batch, (list, tuple)) else batch\n        xb = xb.to(device, non_blocking=True)\n        with torch.cuda.amp.autocast(enabled=use_amp):\n            logits = model(xb)\n            p = torch.sigmoid(logits)\n        ps.append(p.detach().cpu().numpy())\n    return np.concatenate(ps, axis=0).astype(np.float32)\n\ndef safe_logloss(y_true, p):\n    p = np.clip(np.asarray(p, dtype=np.float64), 1e-8, 1-1e-8)\n    return float(log_loss(y_true, p, labels=[0,1]))\n\ndef safe_auc(y_true, p):\n    if len(np.unique(y_true)) < 2:\n        return None\n    return float(roc_auc_score(y_true, p))\n\n# ----------------------------\n# 8) Internal val split (group-safe by case_id)\n# ----------------------------\ndef make_case_split(df: pd.DataFrame, val_frac=0.08, seed=2025):\n    g = df.groupby(\"case_id\")[\"y\"].max().reset_index().rename(columns={\"y\":\"case_y\"})\n    pos_cases = g.loc[g[\"case_y\"] == 1, \"case_id\"].to_numpy()\n    neg_cases = g.loc[g[\"case_y\"] == 0, \"case_id\"].to_numpy()\n\n    rng = np.random.RandomState(seed)\n    rng.shuffle(pos_cases)\n    rng.shuffle(neg_cases)\n\n    n_val_pos = max(1, int(len(pos_cases) * val_frac)) if len(pos_cases) else 0\n    n_val_neg = max(1, int(len(neg_cases) * val_frac)) if len(neg_cases) else 0\n\n    val_cases = np.concatenate([pos_cases[:n_val_pos], neg_cases[:n_val_neg]])\n    val_set = set(map(int, val_cases.tolist()))\n    is_val = df[\"case_id\"].astype(int).map(lambda x: int(x) in val_set).to_numpy(dtype=bool)\n    return is_val\n\n# ----------------------------\n# 9) Train once (full-data with optional internal val)\n# ----------------------------\ndef train_full_once(seed_offset=0):\n    seed_everything(FINAL_SEED + seed_offset)\n\n    if USE_INTERNAL_VAL:\n        is_val = make_case_split(df_train_tabular, val_frac=float(VAL_FRAC_CASE), seed=FINAL_SEED + seed_offset)\n        tr_idx = np.where(~is_val)[0]\n        va_idx = np.where(is_val)[0]\n        X_tr, y_tr = X_all[tr_idx], y_all[tr_idx]\n        X_va, y_va = X_all[va_idx], y_all[va_idx]\n        print(f\"  internal split: train={len(tr_idx)} | val={len(va_idx)} | val_pos%={float(y_va.mean())*100:.2f}\")\n    else:\n        X_tr, y_tr = X_all, y_all\n        X_va = y_va = None\n\n    mu, sig = fit_standardizer(X_tr)\n    X_trn = apply_standardizer(X_tr, mu, sig)\n\n    ds_tr = TabDataset(X_trn, y_tr)\n    dl_tr = DataLoader(\n        ds_tr,\n        batch_size=int(CFG[\"batch_size\"]),\n        shuffle=True,\n        num_workers=2,\n        pin_memory=(device.type==\"cuda\"),\n        drop_last=False\n    )\n\n    if USE_INTERNAL_VAL:\n        X_van = apply_standardizer(X_va, mu, sig)\n        ds_va = TabDataset(X_van, y_va)\n        dl_va = DataLoader(\n            ds_va,\n            batch_size=int(CFG[\"batch_size\"]),\n            shuffle=False,\n            num_workers=2,\n            pin_memory=(device.type==\"cuda\"),\n            drop_last=False\n        )\n    else:\n        dl_va = None\n\n    model = FTTransformerBig(\n        n_features=X_all.shape[1],\n        d_model=int(CFG[\"d_model\"]),\n        n_heads=int(CFG[\"n_heads\"]),\n        n_layers=int(CFG[\"n_layers\"]),\n        ffn_mult=int(CFG[\"ffn_mult\"]),\n        dropout=float(CFG[\"dropout\"]),\n        attn_dropout=float(CFG[\"attn_dropout\"]),\n    ).to(device)\n\n    # imbalance pos_weight (from TRAIN split)\n    pos = int(y_tr.sum())\n    neg = int(len(y_tr) - pos)\n    pos_weight = float(neg / max(1, pos))\n    loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight], device=device))\n\n    opt = torch.optim.AdamW(\n        model.parameters(),\n        lr=float(CFG[\"lr\"]),\n        weight_decay=float(CFG[\"weight_decay\"]),\n        betas=ADAM_BETAS,\n        eps=ADAM_EPS,\n    )\n\n    steps_per_epoch = max(1, len(dl_tr))\n    total_steps = int(CFG[\"epochs\"]) * steps_per_epoch\n    warmup_steps = int(float(CFG[\"warmup_frac\"]) * total_steps)\n\n    ms1 = int(STEP_RATIOS[0] * total_steps)\n    ms2 = int(STEP_RATIOS[1] * total_steps)\n    sch = make_warmup_then_step_scheduler(opt, total_steps, warmup_steps, [ms1, ms2], list(STEP_GAMMAS))\n\n    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n\n    best_val = 1e18\n    best_state = None\n    best_epoch = -1\n    bad = 0\n\n    t0 = time.time()\n    for epoch in range(int(CFG[\"epochs\"])):\n        model.train()\n        loss_sum = 0.0\n        n_sum = 0\n\n        opt.zero_grad(set_to_none=True)\n        for it, (xb, yb) in enumerate(dl_tr, 1):\n            xb = xb.to(device, non_blocking=True)\n            yb = yb.to(device, non_blocking=True).float()\n\n            with torch.cuda.amp.autocast(enabled=use_amp):\n                logits = model(xb)\n                loss = loss_fn(logits, yb)\n                loss = loss / float(GRAD_ACCUM)\n\n            scaler.scale(loss).backward()\n\n            if (it % GRAD_ACCUM) == 0 or it == len(dl_tr):\n                if float(CFG.get(\"grad_clip\", 1.0)) > 0:\n                    scaler.unscale_(opt)\n                    torch.nn.utils.clip_grad_norm_(model.parameters(), float(CFG.get(\"grad_clip\", 1.0)))\n\n                scaler.step(opt)\n                scaler.update()\n                opt.zero_grad(set_to_none=True)\n                sch.step()\n\n            loss_sum += float(loss.item()) * xb.size(0) * float(GRAD_ACCUM)\n            n_sum += xb.size(0)\n\n        tr_loss = loss_sum / max(1, n_sum)\n\n        if dl_va is not None:\n            p_va = predict_proba(model, dl_va)\n            vll = safe_logloss(y_va, p_va)\n            vauc = safe_auc(y_va, p_va)\n\n            improved = (best_val - vll) > float(CFG[\"min_delta\"])\n            if improved:\n                best_val = float(vll)\n                best_epoch = int(epoch)\n                best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n                bad = 0\n            else:\n                bad += 1\n\n            print(f\"  epoch {epoch+1:03d}/{int(CFG['epochs'])} | tr_loss={tr_loss:.5f} | val_ll={vll:.5f} | val_auc={(vauc if vauc is not None else float('nan')):.5f} | bad={bad}\")\n            if EARLY_STOP and bad >= int(CFG[\"patience\"]):\n                print(f\"  early stop at epoch {epoch+1}, best_epoch={best_epoch+1}, best_val_ll={best_val:.5f}\")\n                break\n        else:\n            print(f\"  epoch {epoch+1:03d}/{int(CFG['epochs'])} | tr_loss={tr_loss:.5f}\")\n\n        gc.collect()\n\n    # restore best weights\n    if best_state is not None:\n        model.load_state_dict(best_state, strict=True)\n\n    pack = {\n        \"type\": \"ft_transformer_big_full\",\n        \"state_dict\": {k: v.detach().cpu() for k, v in model.state_dict().items()},\n        \"mu\": mu,\n        \"sig\": sig,\n        \"cfg\": dict(CFG),\n        \"seed\": int(FINAL_SEED + seed_offset),\n        \"pos_weight\": float(pos_weight),\n        \"train_rows\": int(len(y_tr)),\n        \"val_rows\": int(len(y_va)) if USE_INTERNAL_VAL else 0,\n        \"best_epoch\": int(best_epoch + 1) if best_epoch >= 0 else None,\n        \"best_val_logloss\": float(best_val) if best_state is not None else None,\n        \"train_time_s\": float(time.time() - t0),\n        \"grad_accum\": int(GRAD_ACCUM),\n        \"adam_betas\": list(ADAM_BETAS),\n        \"step_ratios\": list(STEP_RATIOS),\n        \"step_gammas\": list(STEP_GAMMAS),\n    }\n    return pack\n\n# ----------------------------\n# 10) Train final model(s) with OOM-safe fallback\n# ----------------------------\nfinal_packs = []\nfor s in range(int(N_SEEDS)):\n    print(f\"\\n[Final Train] seed_offset={s}\")\n    try:\n        pack = train_full_once(seed_offset=s)\n    except RuntimeError as e:\n        # OOM fallback: reduce batch_size then d_model/layers\n        msg = str(e).lower()\n        if (\"out of memory\" in msg) and device.type == \"cuda\":\n            print(\"  OOM detected. Applying fallback: batch_size -> half, d_model/layers -> downshift\")\n            torch.cuda.empty_cache()\n\n            CFG[\"batch_size\"] = max(128, int(CFG[\"batch_size\"]) // 2)\n            CFG[\"d_model\"] = max(256, int(CFG[\"d_model\"]) - 64)\n            CFG[\"n_layers\"] = max(6, int(CFG[\"n_layers\"]) - 2)\n            TARGET_EFF_BATCH = 768\n            GRAD_ACCUM = max(1, int(math.ceil(TARGET_EFF_BATCH / int(CFG[\"batch_size\"]))))\n\n            print(\"  New CFG:\")\n            for k in [\"d_model\",\"n_layers\",\"n_heads\",\"batch_size\",\"epochs\"]:\n                print(f\"    {k}: {CFG[k]}\")\n            print(f\"  New GradAccum: {GRAD_ACCUM}\")\n\n            pack = train_full_once(seed_offset=s)\n        else:\n            raise\n    final_packs.append(pack)\n    gc.collect()\n\n# ----------------------------\n# 11) Save artifacts\n# ----------------------------\nfinal_model_path = OUT_DIR / \"final_gate_model.pt\"\ntorch.save(\n    {\n        \"feature_cols\": FEATURE_COLS,\n        \"packs\": final_packs,  # list, even if 1 seed\n        \"bundle_source\": source,\n    },\n    final_model_path\n)\n\nfinal_bundle = {\n    \"type\": \"ft_transformer_big_full\",\n    \"n_seeds\": int(N_SEEDS),\n    \"seeds\": [int(p[\"seed\"]) for p in final_packs],\n    \"feature_cols\": FEATURE_COLS,\n    \"cfg\": dict(CFG),\n    \"use_internal_val\": bool(USE_INTERNAL_VAL),\n    \"val_frac_case\": float(VAL_FRAC_CASE) if USE_INTERNAL_VAL else 0.0,\n    \"early_stop\": bool(EARLY_STOP) if USE_INTERNAL_VAL else False,\n    \"train_rows\": int(len(y_all)),\n    \"pos_rate\": float(y_all.mean()),\n    \"notes\": \"Final model = BIG tabular transformer head over DINOv2-Large-derived features. Save this for inference loading.\",\n    \"ref_best_bundle\": (best_bundle.get(\"selection\", {}) if isinstance(best_bundle, dict) else {}),\n}\n\nfinal_bundle_path = OUT_DIR / \"final_gate_bundle.json\"\nfinal_bundle_path.write_text(json.dumps(final_bundle, indent=2))\n\nprint(\"\\nSaved final training artifacts:\")\nprint(\"  model  ->\", final_model_path)\nprint(\"  bundle ->\", final_bundle_path)\n\n# Export globals\nFINAL_GATE_MODEL_PT = str(final_model_path)\nFINAL_GATE_BUNDLE = final_bundle\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Finalize & Save Model Bundle (Reproducible)","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# Step 6 — Finalize & Save Model Bundle (Reproducible) — REVISI FULL v3 (TRANSFORMER COMPAT)\n# - Fokus: bundle artefak penting (Transformer .pt) + threshold placeholder + manifest + ZIP portable\n# - Tidak ada submission di sini\n#\n# REQUIRE:\n# - Step 2: feature_cols.json\n# - Step 5: final_gate_model.pt + final_gate_bundle.json\n# ============================================================\n\nimport os, json, time, platform, warnings, zipfile\nfrom pathlib import Path\n\nwarnings.filterwarnings(\"ignore\")\n\nOUT_DIR = Path(\"/kaggle/working/recodai_luc_gate_artifacts\")\nOUT_DIR.mkdir(parents=True, exist_ok=True)\n\n# ----------------------------\n# Helpers\n# ----------------------------\ndef read_json_safe(p: Path, default=None):\n    try:\n        return json.loads(p.read_text())\n    except Exception:\n        return default\n\ndef pick_first_existing(paths):\n    for p in paths:\n        if p is None:\n            continue\n        p = Path(p)\n        if p.exists() and p.is_file():\n            return p\n    return None\n\ndef safe_add(zf: zipfile.ZipFile, p: Path, arcname: str):\n    if p is None:\n        return\n    p = Path(p)\n    if p.exists() and p.is_file():\n        zf.write(p, arcname=arcname)\n\n# ----------------------------\n# 0) Locate required artifacts\n# ----------------------------\nfinal_model_pt = OUT_DIR / \"final_gate_model.pt\"\nfinal_bundle_path = OUT_DIR / \"final_gate_bundle.json\"\nfeature_cols_path = OUT_DIR / \"feature_cols.json\"\n\nif not feature_cols_path.exists():\n    raise FileNotFoundError(f\"Missing feature_cols: {feature_cols_path} (jalankan Step 2 dulu)\")\nif not final_model_pt.exists():\n    raise FileNotFoundError(f\"Missing final model: {final_model_pt} (jalankan Step 5 dulu)\")\n\n# Optional / legacy (hanya untuk kompat)\nfinal_model_joblib = OUT_DIR / \"final_gate_model.joblib\"  # legacy fallback jika suatu saat ada\nmodel_format = \"torch_pt\"\nfinal_model_path = final_model_pt\n\n# Optional artifacts (gunakan nama yang benar sesuai Step 3/4 kamu)\nbaseline_report_path = pick_first_existing([\n    OUT_DIR / \"baseline_transformer_cv_report.json\",   # paling mungkin (dari Step 3 kamu)\n    OUT_DIR / \"baseline_transformer_cv_report_v2.json\",\n    OUT_DIR / \"baseline_cv_report.json\",               # legacy\n])\n\nopt_config_path = pick_first_existing([\n    OUT_DIR / \"best_gate_config.json\",                 # dari Step 4\n])\n\nopt_results_csv = pick_first_existing([\n    OUT_DIR / \"opt_search\" / \"opt_results.csv\",\n])\n\nopt_fold_csv = pick_first_existing([\n    OUT_DIR / \"opt_search\" / \"opt_fold_details.csv\",\n])\n\noof_tf_baseline_csv = pick_first_existing([\n    OUT_DIR / \"oof_baseline_transformer.csv\",\n])\n\n# ini optional dan sering tidak ada (jangan bikin error)\noof_baseline_csv = pick_first_existing([\n    OUT_DIR / \"oof_baseline.csv\",\n])\n\nprint(\"Found artifacts:\")\nprint(\"  final_model  :\", final_model_path, f\"(format={model_format})\")\nprint(\"  final_bundle :\", final_bundle_path if final_bundle_path.exists() else \"(missing/skip)\")\nprint(\"  feature_cols :\", feature_cols_path)\nprint(\"  baseline_report :\", baseline_report_path if baseline_report_path else \"(missing/skip)\")\nprint(\"  best_gate_config :\", opt_config_path if opt_config_path else \"(missing/skip)\")\n\n# ----------------------------\n# 1) Load metadata\n# ----------------------------\nfeature_cols = read_json_safe(feature_cols_path, default=[])\nif not isinstance(feature_cols, list) or len(feature_cols) == 0:\n    raise ValueError(\"feature_cols.json invalid / empty\")\n\nfinal_bundle = read_json_safe(final_bundle_path, default={}) if final_bundle_path.exists() else {}\nbaseline_report = read_json_safe(baseline_report_path, default=None) if baseline_report_path else None\nopt_config = read_json_safe(opt_config_path, default=None) if opt_config_path else None\n\n# ----------------------------\n# 2) Threshold placeholders (Transformer)\n# - PRIORITY:\n#   (a) thresholds.json (kalau sudah ada)\n#   (b) best_gate_config.json -> selection.oof_best_thr (Step 4)\n#   (c) fallback 0.5\n# ----------------------------\nthresholds_path = OUT_DIR / \"thresholds.json\"\n\nif thresholds_path.exists():\n    thresholds = read_json_safe(thresholds_path, default={})\nelse:\n    T_gate = None\n\n    # (b) Step 4 selection\n    if isinstance(opt_config, dict):\n        sel = opt_config.get(\"selection\", {})\n        if isinstance(sel, dict):\n            T_gate = sel.get(\"oof_best_thr\", None)\n\n    # fallback\n    if T_gate is None:\n        T_gate = 0.5\n\n    thresholds = {\n        \"T_gate\": float(T_gate),\n        \"beta_for_tuning\": 0.5,\n        \"guards\": {\n            \"min_area_frac\": None,\n            \"max_area_frac\": None,\n            \"max_components\": None\n        },\n        \"notes\": \"Placeholder. Update after calibration/threshold tuning on OOF or validation set.\"\n    }\n    thresholds_path.write_text(json.dumps(thresholds, indent=2))\n\n# ----------------------------\n# 3) Capture dataset/cfg metadata (if available)\n# ----------------------------\ncfg_meta = {}\nif \"PATHS\" in globals() and isinstance(PATHS, dict):\n    cfg_meta = {\n        \"COMP_ROOT\": PATHS.get(\"COMP_ROOT\", None),\n        \"OUT_DS_ROOT\": PATHS.get(\"OUT_DS_ROOT\", None),\n        \"OUT_ROOT\": PATHS.get(\"OUT_ROOT\", None),\n        \"MATCH_CFG_DIR\": PATHS.get(\"MATCH_CFG_DIR\", None),\n        \"PRED_CFG_DIR\": PATHS.get(\"PRED_CFG_DIR\", None),\n        \"DINO_CFG_DIR\": PATHS.get(\"DINO_CFG_DIR\", None),\n        \"DINO_LARGE_DIR\": PATHS.get(\"DINO_LARGE_DIR\", None),\n        \"PRED_FEAT_TRAIN\": PATHS.get(\"PRED_FEAT_TRAIN\", None),\n        \"MATCH_FEAT_TRAIN\": PATHS.get(\"MATCH_FEAT_TRAIN\", None),\n        \"DF_TRAIN_ALL\": PATHS.get(\"DF_TRAIN_ALL\", None),\n        \"CV_CASE_FOLDS\": PATHS.get(\"CV_CASE_FOLDS\", None),\n        \"IMG_PROFILE_TRAIN\": PATHS.get(\"IMG_PROFILE_TRAIN\", None),\n    }\n\n# ----------------------------\n# 4) Manifest (reproducible)\n# ----------------------------\ntask_str = \"Recod.ai/LUC — Gate Model (authentic vs forged) — DINOv2 features + Transformer gate (.pt)\"\n\nmanifest = {\n    \"created_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n    \"python\": platform.python_version(),\n    \"platform\": platform.platform(),\n    \"bundle_version\": \"v3\",\n    \"task\": task_str,\n    \"model_format\": model_format,\n    \"artifacts\": {\n        \"final_model\": str(final_model_path),\n        \"final_bundle\": str(final_bundle_path) if final_bundle_path.exists() else None,\n        \"feature_cols\": str(feature_cols_path),\n        \"thresholds\": str(thresholds_path),\n        \"baseline_report\": str(baseline_report_path) if baseline_report_path else None,\n        \"best_gate_config\": str(opt_config_path) if opt_config_path else None,\n        \"opt_results_csv\": str(opt_results_csv) if opt_results_csv else None,\n        \"opt_fold_details_csv\": str(opt_fold_csv) if opt_fold_csv else None,\n        \"oof_baseline_csv\": str(oof_baseline_csv) if oof_baseline_csv else None,\n        \"oof_baseline_transformer_csv\": str(oof_tf_baseline_csv) if oof_tf_baseline_csv else None,\n    },\n    \"cfg_meta\": cfg_meta,\n    \"model_summary\": {\n        \"type\": (final_bundle.get(\"type\") if isinstance(final_bundle, dict) else None),\n        \"n_seeds\": (final_bundle.get(\"n_seeds\") if isinstance(final_bundle, dict) else None),\n        \"seeds\": (final_bundle.get(\"seeds\") if isinstance(final_bundle, dict) else None),\n        \"train_rows\": (final_bundle.get(\"train_rows\") if isinstance(final_bundle, dict) else None),\n        \"pos_rate\": (final_bundle.get(\"pos_rate\") if isinstance(final_bundle, dict) else None),\n        \"feature_count\": int(len(feature_cols)),\n        \"T_gate\": float(thresholds.get(\"T_gate\", 0.5)),\n    },\n    \"baseline_summary\": (baseline_report.get(\"overall\") if isinstance(baseline_report, dict) else None),\n    \"opt_summary\": (opt_config.get(\"selection\") if isinstance(opt_config, dict) else None),\n}\n\nmanifest_path = OUT_DIR / \"model_bundle_manifest.json\"\nmanifest_path.write_text(json.dumps(manifest, indent=2))\n\n# ----------------------------\n# 5) Bundle pack (JSON portable) + optional joblib\n# ----------------------------\nbundle_pack = {\n    \"model_format\": model_format,\n    \"final_model_path\": str(final_model_path),\n    \"final_bundle\": final_bundle,\n    \"feature_cols\": feature_cols,\n    \"thresholds\": thresholds,\n    \"cfg_meta\": cfg_meta,\n    \"manifest\": manifest,\n}\n\nbundle_pack_json = OUT_DIR / \"model_bundle_pack.json\"\nbundle_pack_json.write_text(json.dumps(bundle_pack, indent=2))\n\nbundle_pack_joblib = OUT_DIR / \"model_bundle_pack.joblib\"\njoblib_ok = False\ntry:\n    import joblib\n    joblib.dump(bundle_pack, bundle_pack_joblib)\n    joblib_ok = True\nexcept Exception:\n    joblib_ok = False\n\n# ----------------------------\n# 6) Create portable ZIP\n# ----------------------------\nzip_path = OUT_DIR / \"model_bundle_v3.zip\"\n\nwith zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n    safe_add(zf, final_model_path, final_model_path.name)\n    safe_add(zf, final_bundle_path, final_bundle_path.name)\n    safe_add(zf, feature_cols_path, feature_cols_path.name)\n    safe_add(zf, thresholds_path, thresholds_path.name)\n    safe_add(zf, manifest_path, manifest_path.name)\n    safe_add(zf, bundle_pack_json, bundle_pack_json.name)\n    if joblib_ok:\n        safe_add(zf, bundle_pack_joblib, bundle_pack_joblib.name)\n\n    # optional extras\n    safe_add(zf, baseline_report_path, baseline_report_path.name if baseline_report_path else \"baseline_report.json\")\n    safe_add(zf, opt_config_path, opt_config_path.name if opt_config_path else \"best_gate_config.json\")\n\n    if opt_results_csv:\n        safe_add(zf, opt_results_csv, f\"opt_search/{opt_results_csv.name}\")\n    if opt_fold_csv:\n        safe_add(zf, opt_fold_csv, f\"opt_search/{opt_fold_csv.name}\")\n\n    if oof_baseline_csv:\n        safe_add(zf, oof_baseline_csv, oof_baseline_csv.name)\n    if oof_tf_baseline_csv:\n        safe_add(zf, oof_tf_baseline_csv, oof_tf_baseline_csv.name)\n\nprint(\"\\nOK — Model bundle finalized\")\nprint(\"  manifest     ->\", manifest_path)\nprint(\"  pack (json)  ->\", bundle_pack_json)\nprint(\"  pack (joblib)->\", (bundle_pack_joblib if joblib_ok else \"(skip; joblib not available)\"))\nprint(\"  thresholds   ->\", thresholds_path)\nprint(\"  zip          ->\", zip_path)\n\nprint(\"\\nBundle summary:\")\nprint(\"  model_format :\", model_format)\nprint(\"  feature_cnt  :\", len(feature_cols))\nprint(\"  T_gate       :\", thresholds.get(\"T_gate\"))\nprint(\"  task         :\", task_str)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}